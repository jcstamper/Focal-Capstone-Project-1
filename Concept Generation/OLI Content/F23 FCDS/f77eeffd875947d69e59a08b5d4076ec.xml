<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="f77eeffd875947d69e59a08b5d4076ec"><head><title>Overview</title><objref idref="d97c7a0d3b5544ab803713818aaa9f60" /><objref idref="fb91d7452cca428ebc8f86c4062f67ff" /><objref idref="d651478ba3e84c03851885b895caea97" /><objref idref="e31e837cfea64decae6c39ec99b181d9" /><objref idref="a1dd8edc91d54a498e896685273b78c3" /></head><body><p id="ffa793ac65ab488296341fab81dfe51f">When you studied feature engineering, you learned about creating features from raw data to facilitate model building. You also read about the Principal Component Analysis technique, this is a first step to modeling in the data science lifecycle. Now, we will start exploring the model understanding phase of the lifecycle, starting with establishing terminology and concepts that will be used going forward. Some of this terminology is used in articles you have read in your free time and in previous Units. You will now tie those concepts into the practice of model building.</p><p id="cb950743b9e2446cbca7ab42495c368c">If you have followed the steps in business and data understanding, you are ready to proceed to model building. Keep in mind that you have been developing your analytic solution right from the moment you defined your analytic objectives! Those objectives will ensure that you meet the needs of your client and help them to get actionable insights from their solution. </p><p id="cd898cb6f9d44b7baac2ee5d5aa820ac">Now that you will be building models, there are many questions and considerations that must be taken into account throughout this process. You will develop models, evaluate its performance and deploy it for use (maintenance happens throughout this process as well). When you build models, you <em style="italic">train </em>them using the data that you have gathered and prepared. </p><p id="b67d9244d7144400896bda470d2c538f"><em style="italic">Model Training. </em>During the model training process, you will <em style="italic">partition </em>or <em style="italic">split</em> your data into a training and test data set. Depending on the tool you are using for model training, you might split your model into training, validation and testing sets. The training set is used to initially build the models and then the models are validated using the test set. You will then select the best model to meet your analytic objective by comparing some metrics. </p><p id="b63c168e1f764f6b8053d093971e7177">During the model building phase, you will interact with different algorithms to uncover trends and patterns and identify relationships in data. When learning about data science, you will classify these algorithms under three categories:</p><p id="d729a1de3bea4544abbf341f75f26da1"><em style="italic">Supervised Learning Techniques</em> are used to predict the outcome of a response or dependent variable based on a set of independent or predictor variables. We will study common supervised learning techniques including k-Nearest Neighbors, Classification and Regression Trees among others. The supervised learning techniques will be have classification and regression patterns. <em style="italic">Unsupervised learning techniques </em>are different from the supervised learning technique in that the response variable is unknown. We learned about a dimension reduction technique in the last unit, and that technique can be considered an unsupervised learning technique. Unsupervised techniques will also uncover patterns in a dataset using cluster analysis and association rules. </p><p id="c7cdd8624ea04424bc55e5909c152a75">This unit will also explore the performance of models that are built using the algorithms that are mentioned. Models need to be evaluated to ensure that the output is useful to the analytic objectives that were set. We use the goodness of fit measures to assess the fit of a regression model to the data. Keep in mind that a model that fits the dataset well could have issues leading to <em style="italic">overfitting. </em>This phenomena occurs when the model has learned all the details in the training set and is not able to generalize to new data, the opposite of this is <em style="italic">Underfitting </em>which also occurs when the model does not suit the dataset. It is easier to fix underfitting by using other algorithms for your task. Overfitting is detected by partitioning your data as mentioned above and also performing cross-validation. </p><p id="bf03aa04418b4cfc9c211e2a8801900c">Classification models are assessed using a confusion matrix. The confusion matrix will show how well data was classified in its right class. You want your data to be classified in the <em style="italic">True Positive (TP) and True Negative (TN) </em>Classes. You do not want your data to be classified in the <em style="italic">False Negative (FN) and False Positive(FP) </em>Classes. </p><table id="b1afd047176a4feca6ae1d6ce8cd9f9d" summary="" rowstyle="plain"><cite id="ia3edc9ef92744735bceba83c9e0809fb" /><caption><p id="f8bee3546b4c4670b1ac0047370166e4" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="fcba95dcb5fb46459655633f77670d67"><em>Class</em></p></td><td colspan="1" rowspan="1" align="left"><p id="ce55d918edc44b39ab6d84b6032c144e"><em>Predicted Class 1</em></p></td><td colspan="1" rowspan="1" align="left"><p id="b538da90a566460f9d2a9588316dea55"><em>Predicted Class 0</em></p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ce485abcc35a411c9f17366d0ad7ce29">Class 1</p></td><td colspan="1" rowspan="1" align="left"><p id="c8fa4a7fd53f40a3b421513fec581a4c">TP</p></td><td colspan="1" rowspan="1" align="left"><p id="b07128c4abc04e9a90a7496a4a66582f">FN</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="bdc6e50e732b4753b2ca1873055fbb25">Class 0</p></td><td colspan="1" rowspan="1" align="left"><p id="b5d44c708c2f4af9b8303f64d0f23d51">FP</p></td><td colspan="1" rowspan="1" align="left"><p id="de9bf21ef9b74e048a12ef00f69037bf">FP</p></td></tr></table><p id="c2b34cf1e11b466eaa759e92ff989ba6">The performance of classification models can be measured by the <em style="italic">misclassification rate </em>or <em style="italic">error rate</em>. This is the proportion of observations in your dataset that are classified incorrectly. The <em style="italic">accuracy rate </em> is the proportion of observations that are classified correctly. The <em style="italic">Sensitivity or recall </em>is the proportion of your target class that is classified correctly. <em style="italic">Precision </em>is the proportion of the predicted target class observations that belong to the target class and finally, <em style="italic">Specificity. Specificity </em>is proportion of non target class observations that are classified correctly. When you learn about the different techniques used for classification problems, we will apply the performance measures to examples for better clarity. </p><p id="c904dafe5565462ab09ee7a3e4e9d00f">Classification models can also be assessed using charts, all the charts used for performance assessment have a lift curve and a baseline. A good model is one that has a greater area between the lift curve and baseline. The most popular metric for classification performance is the <em style="italic">Area under the Curve and  ROC-Receiver Operating Characteristic Curve (AUC-ROC). Lift Charts </em>are also used. Lift is defined as the effectiveness of a predictive model calculated as the ratio between the results gotten with and without the model. Performance measures for prediction models include the <em style="italic">Root Mean Square Error, Mean Error, Mean Absolute Deviation, Mean Percentage Error </em>and <em style="italic">Mean Absolute Percentage Error. </em>We will explore these metrics throughout this model.</p></body></workbook_page>
