<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="b7ceae5042564a13b7868f95bddacfcb"><head><title>Summary and Quiz 10</title></head><body><ul id="fe1cd705e3f84d43b7b1e0c9bb95fe3e"><li><p id="d64561c12a9d45a4a33a6b017c976172">There is a tradeoff between model accuracy and model interpretation. Models that are easily interpretable tend to be less accurate and models that are highly accurate tend to be less interpretable. We want to be able to explain a model to a human being to ensure there is better decision making for your client and their end users.</p></li><li><p id="e6e3950c03444265aabc0e10735396ab">Interpretability is important in the model building process as we want to know why models produce the results they have produced. Understanding the why behind results will lead to early bias detection (and prevention for future challenges), better acceptance, model debugging, and to satisfy human curiosity. </p></li></ul><p id="fed550b6b62d4580a039483fe871ae9c"><em>Ensure you complete Module 16 before starting Quiz 10!</em></p><activity idref="newc6e7e55ccdab4390831b3ad6b677956f" purpose="checkpoint" /></body></workbook_page>
