<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="c5a0b993dba046cab079b5dfeedaf908"><head><title>Classification</title><objref idref="d651478ba3e84c03851885b895caea97" /></head><body><p id="d585f2adb67848ada175248d1aa5116b">Let us assume that you have a medical dataset that contains observations with features including patient age, weight, height, sex, and race; you have been presented with the task of identifying the category of diagnosis for these observations in your dataset (the category would be diabetic or not). It would take a long time for you to research each observation and compare their features and symptoms to classical symptoms of diabetes. Using a data science approach, you can assign a diagnosis to each observation based on the historical data for that diagnosis. You would be answering a classification problem. <em style="italic">Classification </em>works with an existing dataset that has labeled outcomes and seeks to label the outcomes of a new dataset. Below, you will find the different types of classification problems. Then later in the course, we will explore methods that can be used to solve classification problems.</p><p id="ac46f34c1f9a401ea2d1319cf309f22d"><em>Binary Classification</em></p><p id="e23b053ee4a54e54a36ac07729961b23">Classification tasks that are binary will classify observations in a dataset into two defined categories. The observations are grouped based on the presence of characteristics unique to one of the two categories. Examples can include a decision on a credit card application (i.e. approve/deny). </p><p id="e1549e15feaf44a496c6d1c25aec6db1"><em>Multi-Class Classification</em></p><p id="f3d8a00d47ae4ee79e7fe3fc742c3f13">Also referred to as multinomial classification,  classes in a classification task are three or more; observations can be classified into one of the three or more classes. Each observation can only be classified as one of the multiple classes, an observation can not be labeled to multiple classes at once. If a fruit image dataset is presented as a classification task, a valid assumption would be that the observations will be labeled as one type of fruit from the multiple classes. If the labels are orange, pineapple, peach, and mango, then each observation can only be classified as one type of fruit.</p><p id="b82eede11fe44c4cb60a97be5e285f7a"><em>Multi-Label Classification</em></p><p id="d3c404528e8f40609e06928b78e6ec7d">You want to be careful not to confuse multi-label classification and multi-class classification to have the same meaning. Unlike multi class classification that has an assumption of observations having one class out of the multiple classes; the multi-label classification allows for observations to be classified under multiple classes hence the term, <em style="italic">multi-label </em>classification. </p><table id="b197cf59369349d8a071241f8baa2726" summary="" rowstyle="plain"><cite id="i2dbc4eca00024042926c518ad540a8c2" /><caption><p id="de24dd1615354461b30736fcad440d23" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="aba75676e36d4be28116fb7453bddb31"><em>A quick thought: </em>Can you think about a scenario were observations can belong to multiple classes at once (thereby leading them to be labeled under those classes)?</p></td></tr></table><p id="b5cf3a175c54412cb5ce77416cf82839">Multi-label classification can be applied to classifying textual data. If you watch movies, you know that some movies can belong to multiple genres e.g. Romantic Comedy, Romantic Drama, Thriller Comedy. </p><p id="d5a40ad41d1c4dcc8e373f54465f1f52">Let us stick with this example and conceptually define how a multi-label classification task would pan out.</p><p id="b53b9f20a1fa408fbc75bba7eba4a13a">You are tasked to classify movies based on their plot. We can assume that we have defined our analytic objective, defined our requirements, and we have gathered and prepared our data. When you classify the observations in this dataset, you might find Movie A will belong to Romance and Comedy. Let us see the different multi-label classification techniques and how they can handle problems with multi-labels without causing a dimensionality issue to your dataset, and jeopardize the performance of your model.</p><p id="e4b65f2acf49464ba6aa12866a8077a1"><em style="italic">Multi-label Classification Techniques</em></p><ul id="e16a8bd757f94e1e8b9df198b4d6203e"><li><p id="a243491838824fafa5b3b89ec78fb9b0">Multi-label classification does not have constraints on the labels that an observation can have and this makes it difficult to learn. Using the <em style="italic">OneVsRest </em>Technique, your classifier makes the assumption that labels are mutually exclusive and there is no consideration for correlations between classes. </p></li><li><p id="a3efb5ba34fe41a0b92b4c78d63ee2d3">Similar to OneVsRest, the <em style="italic">Binary Relevance </em>technique trains a single label binary classifier for each class i.e. for each class, an observation will either be predicted as belonging to that class or not. This technique ignores any correlation between classes. </p></li><li><p id="e287c031feb1425290b1d5a96ef1a79d">The algorithm for your classification task can also adapt the algorithm to perform multi-label classification. A popular example is using a multi-label version of the k-Nearest Neighbors (a supervised learning technique that makes the assumption that similar data points are always close together).</p><p id="ef8df6ec7189441c8134a37754a06a7b"><em>Example: </em><link href="http://scikit.ml/api/skmultilearn.adapt.mlknn.html" target="new" internal="false"><em>scikit-multilearn for MLkNN</em></link><em>.</em></p></li><li><p id="cd18300bbc824b3dbb0fd0d6fb29c464">You can transform your task into a multi-class task by training all unique class combinations on one multi-class classifier. </p><table id="f28887f80f364a2c9b56e36d25705b56" summary="" rowstyle="plain"><cite id="i8a973f8a316941e5982a726dba801de8" /><caption><p id="fc5d900b5dc145ba93d6ae782eb200a7" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="b05128bd13734d938a04778f96a853a2">X</p></td><td colspan="1" rowspan="1" align="left"><p id="b2fbe78ed75a4f958c79733b8e2466ac">Y<sub>1</sub></p></td><td colspan="1" rowspan="1" align="left"><p id="d8e2d7d35dfb435cac49e2b0730ef0fc">Y<sub>2</sub></p></td><td colspan="1" rowspan="1" align="left"><p id="a32938619e0845d9802f9389cac1f8a0">Y<sub>3</sub></p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="d2e9dd0a85e84695951a3b030dded0d9">X1</p></td><td colspan="1" rowspan="1" align="left"><p id="c4e7143876254eeb8e6b89a03960124c">0</p></td><td colspan="1" rowspan="1" align="left"><p id="a95c8df536c34d54b35ebc1d03d46b2c">1</p></td><td colspan="1" rowspan="1" align="left"><p id="c91f0116c74f45ab85182861ae5b679d">1</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fd04af12ec7e460a9b77b2bc95dda30f">X2</p></td><td colspan="1" rowspan="1" align="left"><p id="eabc9036af5740dc97b2cfd06d0128ac">1</p></td><td colspan="1" rowspan="1" align="left"><p id="de4f0e7479fd49febf18c3b5da68f3f4">1</p></td><td colspan="1" rowspan="1" align="left"><p id="a5a644ff78964c9bbe60d2318f789783">0</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e30ebc2a383443c9a8e9f9f180c5bc99">X3</p></td><td colspan="1" rowspan="1" align="left"><p id="d6101035d0d645d898aea96d6e927f22">1</p></td><td colspan="1" rowspan="1" align="left"><p id="fe353729ee7f4eada9d8802afb6df1e0">1</p></td><td colspan="1" rowspan="1" align="left"><p id="d3ddb5bd569d4ab2a77533c3d38f6ac0">0</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="c24dc09d50d345b69bb62c1a420df8dc">X4</p></td><td colspan="1" rowspan="1" align="left"><p id="cf17b34c63334a668d12d50dcd7bda4f">1</p></td><td colspan="1" rowspan="1" align="left"><p id="f0dc160a625f4994bbce33451c3fd978">0</p></td><td colspan="1" rowspan="1" align="left"><p id="b7d24e75b84747408fba350b693ecab5">1</p></td></tr></table><p id="d1fb0bbb77194b62ba7ace4b5059ebcb">Here we see that observations X2 and X3 belong to the same classes. This technique will transform our task into a single multi class task and give a unique class to all possible combinations in your training data set.</p><table id="b89ed54620a9471fbb97ef0f649b15cf" summary="" rowstyle="plain"><cite id="i0359762e5000470f9c631c9cc23850ae" /><caption><p id="d7039c1e3dd04680a863acb7f0706255" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="f1bd6e7b821b40f39f87ad0b5465af79">X</p></td><td colspan="1" rowspan="1" align="left"><p id="c6d0ae8072b4484186823b7c5520e1b8">Y<sub>1</sub></p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="b289cfbe531f4a86acb742d024d9a13d">X1</p></td><td colspan="1" rowspan="1" align="left"><p id="e5801f7ea1544e5ca4f5cbff31c8f124">1</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fb9a257c2f8f436b9b864566792ea8ea">X2</p></td><td colspan="1" rowspan="1" align="left"><p id="b26471dcd2e34ef8a90b87cf85fd08fa">2</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="d2f28860102c4ba9a29449e92ef85f33">X3</p></td><td colspan="1" rowspan="1" align="left"><p id="ec2b40bb1de54310bd756659d1409602">2</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="dba2dbbc930d43f6bfca1a64940045b7">X4</p></td><td colspan="1" rowspan="1" align="left"><p id="dca408912d0a459cabe69953b681637c">3</p></td></tr></table></li><li><p id="b939b56bf4b14be09808173f161891c1">So far we have seen that OneVsRest, Binary Relevance and Label Powerset techniques do not consider correlations between classes. The <em style="italic">Classifier Chains </em>technique will build a chain of binary classifiers to take into account any correlations between classes. The classifiers that are constructed equal the number of classes i.e. if we have classes: comedy, drama, and romance, we will have three classifiers as well C1:C3. </p></li></ul><p id="cfeed6f28e6645228a45ff0e08290f11">We should mention <link href="https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf" target="new" internal="false"><em>Logistic Regression</em></link> in this section because it is an important classification technique. You will learn more about it in the next module. Logistic regression uses a logistic function to model the probability of a class or event. Will you pass or fail a course, will you develop high blood pressure based on certain attributes, will 18-35 year old college educated men from Georgia vote for the democratic or republican presidential candidate in the 2020 presidential elections. The logistic regression model can have independent variables that are of diverse data types but the response is categorical. </p><wb:inline idref="newf401198eca2c4f50a70f4c3b1df5e9d0" purpose="didigetthis" /></body></workbook_page>
