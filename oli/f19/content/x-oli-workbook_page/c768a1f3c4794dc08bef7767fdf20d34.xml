<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="c768a1f3c4794dc08bef7767fdf20d34"><head><title>Data Wrangling:Transforming Data</title><objref idref="f122331e8f6e401e91d1104f81b3eeea" /><objref idref="e60bb990b74547a2852f56be166c7ce8" /></head><body><p id="c1c00606c5934498a6655dba31328c05">The data gathering process looks different for each data related project and is dependent on your business and analytic objectives, as well as your data source(s). The data that you acquire during the data gathering process will almost always need to be transformed into a usable format. This means it will have variables that contain incorrect or missing values due to data entry errors. Data might need to be transformed to a different structure to meet the requirements of a data science task. </p><p id="b61745ee3e9b45148de218dde3f74bbf"><em>Handling Missing Values</em></p><p id="cd2da701196249f1bc442aaebed02512">One of the most common data quality issues is missing values in your dataset. This can happen due to human error, or system issues during data collection. As you have inspected your data and identified missing values, it is important to determine why the dataset has missing values. Please note that a dataset that was extracted from an external source might not provide context on the reason behind the missing values. When met with such a situation, a data scientist or data analyst should still investigate the missing values. The reasons behind the missing values will determine the techniques used to handle those values.</p><p id="ed46951fa1fe41c8aa283cf01a768f44">One of the most notable statisticians classified missing data into three categories. Those categories explain the likelihood of missing data.</p><p id="fb87cda7fd164c5b9d797162253604da"><em style="italic">Missing completely at random (MCAR) </em>implies that missing data is not related to the data. The probability of data being missing is the same for all observations. </p><p id="a85e552ae24741d8bd7ea6881c5b6154"><em style="italic">Missing at random (MAR) </em>is the probability that the missing data is the same within certain groups. </p><p id="aed9710cce3849818e7127f13d70725b">Data that is <em style="italic">not missing at random (NMAR)</em> means that the probability of data being missing varies for reasons that are unknown. </p><p id="cea0fccbff214521a437b8eb83ad8f72"><em>Imputation</em></p><p id="cc35dad4283645449d0b56132b3e0f3c">The common strategies that are employed in handling missing values are imputation and omission. <em style="italic">Imputation </em>replaces missing values in the dataset with other values. The replacement values are not random. You can replace missing values with the mean value, e.g. If you have missing values in the age variable, you can replace the missing values with the mean age across all observations. This method will work if the group is homogeneous. As you know, your dataset will not always contain homogeneous groups, in this case you will use other imputation techniques that we will discuss in the feature engineering unit. Those techniques include <em style="italic">hot and cold deck imputation, regression imputation, and interpolation and extrapolation.</em></p><p id="a660679a481d43a29ee004f69cbccb2b"><em>Omission</em></p><p id="cde649fc5d714a42871d23237e11bedf"><em style="italic">Omission </em>is often the go to technique when there are missing values. omission involves excluding the missing values from the dataset. <em>Remember: </em>You might suffer loss of data if you exclude values instead of finding other missing value handling techniques. Omission can be done when the amount of missing values is small. <em style="italic">Pairwise deletion </em>is a type of omission, it means performing your analysis on just the available values. Keep in mind that sample sizes will vary with this technique. <em style="italic">Listwise deletion</em> removes all data for an observation that has one or more missing values. This would mean your dataset would have observations with values for all variables. </p><p id="decb98c4d6914e19b5ca4eaf02b93b31">You can also omit variables with missing values. That variable needs to be one with little to no importance to your dataset and overall objective. Example, I am predicting social media usage habits and my dataset includes a shoe size variable with missing values. I can omit that variable.</p><p id="d5db01f24ac44e6e81f0397f4db87700"><em>Subsetting. </em>This process involves extracting portions of a dataset that are relevant to your model or analysis. It is a process that is used in data wrangling to prepare data for exploratory data analysis. It is a technique that can be used to remove observations with missing values. Subsetting can also involve excluding variables instead of observations. An example is looking at summary measures of three subsets of medical records for diabetes treatments were one subset is for successful treatments, another is for unsuccessful treatments and the last is for inconclusive treatments. </p><p id="dde5a60a26574b979acd0188d2be25cb"><em>Outliers</em></p><p id="a315b7d2bc8846d1b4279668c3c8052e">When you were inspecting your data, there was mention of visualizing the data to identify <em style="italic">outliers. </em>Outliers are unusual values in the dataset. The values is unusual because it &quot;lies at an abnormal distance from other values in your dataset&quot;. We discuss using exploratory data analysis techniques to identify outliers in a future unit. You should not immediately remove outlier values as they often times can contribute valuable insights to your solution. Investigating the reason behind the outlier value is your first step in handling it. </p><p id="c64429823b6a4241844297cd8e95e6aa">As you learnt previously, there are different types of data and those types of data have specific data transformation techniques that accommodate them. </p><p id="a4bea15aef9c40a89cc29e72a8c18ec7"><em>Transforming: Categorical Data</em></p><p id="dafb888b956043d4bd045f01432ad764">Categorical data is divided into groups or nominal category based on a qualitative characteristic. Gender, race, and eye color might be variables in a dataset that are useful in predicting a health challenge and due to their low levels of measurement, there is a need to transform the data into a numeric format. There are techniques that are employed to transform categorical variables.</p><ul id="eded69829f56485492c9cd2dd67c92dc"><li><p id="a68dfe35d2d44e6eb37b00b76fccc834"><em style="italic">Category Reduction. </em>Categorical variables can have many categories or levels. A variable with levels that are not useful can negatively affect your analysis and model. Some categorical variables will have levels that do not occur, it will be difficult to capture the interactions within those levels. A technique to handle these variables can include collapsing some of the categories or creating an &quot;other&quot; category for the categories with few occurrences. </p></li><li><p id="d5154ec1752440fd81b793a0c363377f"><em style="italic">Creating Category Scores. </em>Ordinal data would need to transformed into numeric values for certain statistical techniques. Ranked values are an example. A dataset containing student evaluations would have responses that are ranked by different levels. You can transform that data by assuming equal increments between category scores. Responses to the question:The instructor provided out of class support for the course could be: Always, Most Times, Sometimes, Hardly, Never. You can assign a score of 1-5, 1 being the highest and 5 being the lowest or vice versa. The categorical variable can now hold numeric values. </p></li></ul><ul id="a205d886028440808dba90629912cd1a"><li><p id="f854080c15934c4eabc3679ec7f608b5"><em style="italic">Creating Dummy Variables. </em>Dummy variables are often referred to as binary variables. This technique allows for categorical data to be transformed to 0s and 1s. A dataset containing customer spending data with a categorical variable-gender with two categories, male and female. The gender variable can be converted to binary variables. Please note that there is no order of ranking. </p><p id="a2678772a4004ec882f6c32012424331"><em style="italic">Creating Dummy Variables for more than one category.</em><em><em style="italic"> </em></em>What happens when you have a categorical variable containing more than one category? Consider a dataset with the variable hair color with data represented as brown, brunette, black, gray, and blonde. The hair color variable can still be transformed into dummy variables using the following steps.</p><ul id="a670b06076304324ad0fed22dd4ed12a"><li><p id="e45a5aa282304f5da7c2e1213adcff75">Determine the number of variables (k-1), where k is the number of categories of the variable.</p></li><li><p id="a0ddf98373f34ef9a9378068d6fae59c">You will create 4 dummy variables (5-1).</p></li><li><p id="fc9174d27ab64fb7bc56cf859dfd2fff">You will then create variables for each category. In our example, we will create black, brown , brunette, and gray variables. </p></li><li><p id="ee9c0b54accd42498807f25a1aa98ab9">Assign 0 or 1 to each category, for example the black variable would see values of 0, if an observation does not have black hair and 1 if the observation has black hair.</p></li><li><p id="a9d671ea50fd49b3b83b4e00a75e8e34">Keep in mind that the category that was not included in the creation of dummy variables still exists in the dataset.  In this example, a dummy variable for blonde was not created. This simply means that all other categories will be compared to this category. Usually, you select the category with the largest occurrences as the category that will not transformed into a dummy variable. </p></li></ul></li></ul><p id="e76d333be35746f78cc452d10445393a"><em>Transforming: Numeric Data</em></p><p id="c95a9d3f543f4c95b3d48de4c346c9e5">Categorical data is transformed to numeric data so the data can be used for specific statistical techniques.  Why would we need to transform numeric data? If you remember, when data is gathered it is usually noisy with missing values, and sometimes needs to be converted to a structure that fits the data science task; this will ensure that you do not lose data or lose information during the analysis phase. You will encounter numeric data that needs to be transformed to allow you glean insights and use the data for the appropriate statistical techniques. </p><p id="efe9d86ede3d41409714e43b298e0962"><em style="italic">Example </em>of a popular numeric transformation scenario is converting date of birth to age.</p><p id="be1039fc666645d9ac59911260468f9a">Numeric transformations are also explored when performing feature engineering.  You will extract features from the numeric data and transform them into formats that can be used by a machine learning model. We will explore those techniques in depth. Right now, let us take a look at the techniques for converting numeric data during data wrangling.</p><ul id="e094ec2ddb9d4743b23d3ef599e5f834"><li><p id="e27e7a63a2cd4cc78cf8b3d064c240e8"><em style="italic">Binning</em>. This technique will transform a numeric variable into a categorical variable. As mentioned above, age can be grouped into intervals in the event that that age group has similar occurrences in the other variables in a dataset. If you decide to bin the age variable and create the following groups: 15-19, 20-24, 25-29 and 30-34, you can reduce redundancy in your dataset, and capture outliers. Binning can also be done using equal intervals. </p></li><li><p id="a0114f55dd2049669dd1fca763788d19"><em style="italic">Using Mathematics. </em>You can create new variables using mathematical transformation of existing variables, you can use techniques such as standardization, min-max scaling, and logarithmic transformation. We explore these mathematical transformation techniques in a future unit. </p></li></ul><wb:inline idref="newf7598a469d0f402a95351991c04c5d2b" purpose="learnbydoing" /></body></workbook_page>
