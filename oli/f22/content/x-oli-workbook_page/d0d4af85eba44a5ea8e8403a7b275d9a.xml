b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="d0d4af85eba44a5ea8e8403a7b275d9a"><head><title>Conceptual Complexity and the Bias/Variance Tradeoff</title><objref idref="d91bef22c971477182e174d62a6953f2" /><objref idref="b03eaf48f73641ba9295941995a16ade" /><objref idref="b11bf6ab7a1e40daaea14e4293195b25" /><objref idref="bb14f70db2104d05b72da1aa9be0eeb9" /><objref idref="b897ee78f8d64857a6fd3f9807f85ef8" /></head><body><p id="adaffb20fdb3432d9fba01e137effa6f">For selected units in this course, we will have paper reading modules that provide exposure to foundational research papers. The goal of these modules is to familiarize you with the styles of data science literature and the contexts in which advances in data science are introduced. We understand that reading technical papers can be challenging and time-consuming if you don\xe2\x80\x99t have prior experience. To facilitate your learning, we have included both the original paper and our synthesis of the paper\xe2\x80\x99s key points below. Our expectation is that you can acquire a good understanding of the paper\xe2\x80\x99s message by skimming through the original article and then reading our synthesis.</p><p id="aa199582227344caafe4654381fece44">Beyond the specific content of each paper, we also encourage you to pay attention to the synthesis structure introduced below, which contains key questions that one should ask while reading through a scientific publication. You may find this outline useful in a future seminar course or in your own research projects.</p><table id="c062d45e52fb4d99a97d010162adf515" summary="" rowstyle="plain"><cite id="i49b032fc337c4941943593a7ca60530f" /><caption><p id="befb219e6bdf4b99838a670f5433705d" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="adbb3496c03044f4800a1dc95ba1ae5c"><em>[Required Reading] Paper: </em><link href="https://cmu.primo.exlibrisgroup.com/permalink/01CMU_INST/8lb6it/cdi_proquest_miscellaneous_820795036" target="new" internal="false">Briscoe, E., &amp; Feldman, J. (2011). Conceptual complexity and the bias/variance tradeoff. <em style="italic">Cognition</em>, <em style="italic">118</em>(1), 2-16.</link> (Requires CMU credentials to access)</p></td></tr></table><p id="e9d61283981b43f0b2aa31397320e0a4"><em>Who are the paper&apos;s authors? Why are they qualified to write this paper?</em></p><p id="dc43d26f651d4fb9b69dd79693adb86d">The first author is currently a Senior Research Scientist and the Chief Scientist of the Aerospace, Transportation, and Advanced Systems Laboratory with the Georgia Tech Research Institute. She conducts research and development projects that focus on behavioral and data science/analytics applications in various problem spaces, including computational social science, technology emergence and prediction, social network analysis, insider threat detection, terrorism and radicalization, business intelligence, and psychological profiling. She received a Ph.D. in cognitive psychology from Rutgers University in 2008. </p><p id="fbea632071904427bec89eb79a5f1de8">The second author received his Ph.D. in 1992 from the M.I.T. Dept. of Brain and Cognitive Sciences and has been at Rutgers ever since. His main research interests are in visual perception, especially perceptual organization and shape, and in categorization and concept learning. In both these general areas, his focus is on mathematical and computational models of human mental function. In categorization and concept learning, he is similarly interested in how the mind organizes groups of objects into coherent collections and hierarchies. In experimental work, he has found that human learners, given a set of objects to be learned, tend to form categories that are as simple as possible. This idea opens up an enormous set of research questions about what perceptual features form the basis for categorization, how these features are selected in order to reduce representational complexity, and how these goals relate to the structure of the natural world.</p><p id="e49e6907e8c049659f6d9b6bb51e43e5"><em>Who is the audience of the paper?</em></p><p id="f529bb3f51694463afbab973cf00fbc7">The paper is targeting machine learning researchers and practitioners who build machine learning systems that interact with the end-user. </p><p id="a1164e07565b4788a876a39ada28d617"><em>Why is the paper\xe2\x80\x99s topic relevant at the time of its writing?</em></p><p id="dc8467b4e0f448439130b2a1c57dcda0">There are two popular psychological theories on how humans perform categorization. <em style="italic">Exemplar theory</em> states that people store the attributes of observed examples, called exemplars, along with their category labels in memory, and categorize a new object with the label of the most similar exemplar. For example, people would categorize an object as a bird if it\xe2\x80\x99s similar to any type of bird that they have come across, e.g., parrot, sparrow, penguin. In contrast, prototype theory states that there is a central representation of each category, and people compare a new object against these central tendencies to determine its category. With the same bird classification task above, based on the prototype theory, one would label an object as a bird if it possesses the common, \xe2\x80\x9caverage\xe2\x80\x9d features of a bird, e.g., two legs, two wings, and lay eggs. Overall, the key difference between the two theories is whether a new object is compared to real instances (exemplars) or an abstract central representation (prototype) of a category.</p><p id="a065f209e73e4c139618fe1f89418804">While prior researchers have often regarded these theories as fundamentally disparate, the authors instead suggest that they can be viewed as two extremes on the same continuum of bias-variance and that the way humans actually perform categorization lies somewhere in the middle of this continuum. Their attempt to connect psychological theories of human cognition to statistical machine learning concepts of bias and variance presented a novel perspective at the time of the paper\xe2\x80\x99s writing (keep in mind that back in 2010, statistical ML was not as popular as it is nowadays, especially to those in non-technical areas such as psychologists).</p><p id="f46940ba9b2449fcba033a2bfd2067b2"><em>What is the paper\xe2\x80\x99s contribution? Which research gap is it trying to address?</em></p><p id="aa0ee46b60ef4f6d8bc601741ef3920a">The paper presents a number of conceptual and empirical contributions:</p><ul id="fb08c8658c7c4f8893bc7331693f7105"><li><p id="a7a52d6ada794fcb8f965299dfbbfce2">The characterization of exemplar theory as the low bias, high variance extreme, and prototype theory as the high bias, low variance extreme on the bias-variance continuum.</p></li><li><p id="d98956946c4e4c1e988c8921ea37f3f2">A class of experiments to evaluate human learners\xe2\x80\x99 position on this continuum when the complexity of the training data varies has not been systematically attempted before.</p></li><li><p id="a354397c8f6b4b8ca5aafb7016003ee7">The proposal of a locally regularized model that had the best fit for human performance and therefore constitutes a reasonable explanation for how humans perform categorization.</p></li></ul><p id="ce62ce13560543899c3d21c85212e928"><em>Summary of the paper\xe2\x80\x99s experiments and findings.</em></p><p id="e0dffb5e674c4c69aa7604a24de56664">The experiment reported in the paper has the following phases:</p><ol id="f1535b74e7d941fa8faa90bea82c50c6"><li><p id="b1f6b813fb9142a4a798cad4b69b752e"><em>Generate data at different levels of complexity</em>.  The authors first constructed five bivariate Gaussian mixtures, p<sub>1</sub>(x, y), p<sub>2</sub>(x, y), \xe2\x80\xa6, p<sub>5</sub>(x, y), where p<sub>K</sub>(x, y) consists of K components (Equation 1). In this way, K ranges from 1 to 5 and denotes the complexity of the underlying distribution. For each K, the authors then generated ship flag images, each with a pre-defined label \xe2\x80\x93 either belonging to a pirate ship (positive) or a friendly ship (negative) \xe2\x80\x93 and having two quasi-continuous features, the width of the inner black rectangle and the orientation of the sword (Figure 4). These two features were generated from either the distribution with pdf p<sub>K</sub>(x, y) for positive images or 1 - p<sub>K</sub>(x, y) for negative images.</p></li><li><p id="bb478149d91c4efc9552eb34867487d1"><em>Obtain human categorization of the generated data</em>. 13 undergraduate students were recruited for the study. Subjects were shown a sequence of flags that may belong to either a pirate ship or a friendly ship, and the flag features were sampled from one of the five Gaussian distributions in step 1. They were then asked to learn the categorization by first attempting to classify each flag on their own, then seeing feedback on the correctness of their answer, and then repeating these steps with the next flag.</p></li><li><p id="be0e0a2b9a334a52bb345a7001f9ccac"><em>Build models that represent the exemplar approach, prototype approach, and locally regularized context approach</em>. The exemplar model is called GCM and is denoted in Equation 5. The prototype model is denoted in equations 6 and 7. The locally regularized model assumes the same functional form as the exemplar model, but the sensitivity parameter <em style="italic">c</em> (whose high value corresponds to more \xe2\x80\x9cexemplar-like\xe2\x80\x9d and the low value corresponds to more \xe2\x80\x9cprototype-like\xe2\x80\x9d) is modulated locally, i.e., its value is set independently at each partition of the feature space.</p></li><li><p id="bc0ad8bf291a4056b7931d172afac930"><em>Fit the models to subject data</em>. The fitted parameters are optimized to fit the ensemble of each subject\xe2\x80\x99s responses. This helps answer the question: as the complexity K varies, which models best reflect the human performance in this flag classification task?</p></li><li><p id="a3197a5cc4e4465f87b0daed8c1395e4"><em>Fit the models to concept data</em>. The fitted parameters are optimized to maximize the likelihood of the training examples observed so far at each point in the experiment. In other words, the ground truth labels of the flags are used in this process instead of the human classifications like in the previous step. This helps answer the question: as the complexity K varies, which model\xe2\x80\x99s performance is more closely correlated to human performance?</p></li></ol><p id="fe5f1a0ec8944adb8d4ac53a2cc83df0">The important findings from the experiment are as follows:</p><ol id="c1f4689540be43ef84e30fe2ff181cd8"><li><p id="ce6e8e112b7c48b09ed63cfd7c2e2583">Human subjects are proficient at categorizing simple concepts (K = 1), but their performance declines as the complexity of K increases, approaching random guessing at K = 4 or K = 5.</p></li><li><p id="bd6b22d56e9a4a49884bf08861c5a122">When fitting models to subject data, the exemplar model has a better fit than the prototype model across all complexity levels. At larger complexity levels (K = 4 or K = 5), the two models converge in performance, largely because they were fitted on human categorizations that were just random guesses.</p></li><li><p id="babc0d90f69b4dd78aeca8f33d0956f9">When fitting models to concept data, the prototype model\xe2\x80\x99s performance decreases much faster than human performance, whereas the exemplar model\xe2\x80\x99s performance does not decrease fast enough to match human performance at higher complexity levels.</p></li><li><p id="bc2e4bf6f4624bac8c55264c991be4d7">The locally regularized model, which represents a middle point in the bias-variance continuum, consistently fitted subject data better than the exemplar (low bias, high variance) and the prototype (high bias, low variance) model.</p></li></ol><p id="f4482137d9e348e58fdceeb859c69ec9">Circling back to the question of whether humans perform categorization by the prototype approach (compare a new object to an abstract prototype of each candidate category) or the exemplar approach (compare a new object to existing instances of each candidate category stored in memory), this paper\xe2\x80\x99s finding suggests that humans adopt a middle ground. Humans don\xe2\x80\x99t assume there is only a single prototype for each concept but do not keep in memory a large number of exemplars for each candidate prototype either. Instead, they treat concepts as mixtures of several sub-concepts, each represented by a partition of the feature space with its own localized sensitivity parameter <em style="italic">c</em>.</p><p id="d36cd0fa986b4565ba61706e4ce12103"><em>What are the implications of the paper\xe2\x80\x99s findings?</em></p><p id="b417df697a2047ac8c19ee29478fad95">From a cognitive standpoint, the paper shows that evaluation of human learning should be conducted at different levels of conceptual complexity. While theoretically disparate models, such as the exemplar model and prototype model, may have a similar fit with human learning on simple data, they quickly diverge at higher levels of complexity. Complexity should be systematically varied over a range of levels to reflect a comprehensive picture of general human learning.</p><p id="b82893c776534e1da82bb76456fd9086">From a machine learning standpoint, there remains the open question of whether machine learning should follow the process of human learning. While there have been attempts to connect the two, for example, with neural networks that replicate the neural structure of the brain, the similarities are shallow at best. Deep neural networks typically require a very large amount of training data, which is very different from how humans learn. In recent years, however, more attention has been paid to making machine learning more human-like, for example, by learning from a limited number of samples (few-shot learning and no-shot learning) or by increasing robustness to adversarial attacks. This paper shows yet another way that human learning can be connected to machine learning \xe2\x80\x93 while the bias/variance trade-off originates from statistical learning, it can also be used to explain the way humans perform categorization by balancing the performance accuracy and the number of sub-concepts that they can reasonably hold in memory.</p></body></workbook_page>\n'