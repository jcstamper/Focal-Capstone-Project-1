b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="f0b1f52b9c484fb7b70bbcafcaf64e3d"><head><title>Model Selection for Inference</title><objref idref="fc8171c21545480a80174095c242779a" /></head><body><section id="a529659ee77f41c7b982e6399b83ef4a"><title> </title><body><p id="e5a107d4c38b433b93ffb8e628ee0123">In inference, models are trained on the entire dataset to derive the relationships between independent and dependent variables. Thus, there is no longer the notion of a train-test split. Instead, model selection is based on probabilistic metrics that reward goodness of fit but also penalize model complexity, with the goal of acquiring the most reasonable model that is sufficiently simple/interpretable. We introduce a number of popular metrics below.</p><p id="e548abb1f13e47dc939fb02e0936f44c"><em>Akaike Information Criterion (AIC)</em>. Derived from frequentist statistics, the AIC score of a model <em style="italic">M</em> is computed as</p><p id="a79ae16300ce43eab07069ebbaa786db">\\[ AIC(M)=(2K_{h}-2LL(M))/N \\]</p><p id="aad4539478614d00a07c9434e36002d5">where K<sub>M</sub> is the number of parameters in <em style="italic">h</em>, <em style="italic">LL(M)</em> is the maximum log-likelihood of <em style="italic">M</em> on the dataset, and <em style="italic">N</em> is the size of the dataset. For regression, <em style="italic">LL(M)</em> is the mean squared error, and for binary classification, <em style="italic">LL(M)</em> is the logistic loss. A model with a smaller AIC value is considered better for inference.</p><p id="f278b1595b1b47eda29ac25442b40792"><em>Bayesian Information Criterion (BIC)</em>. Derived from Bayesian statistics, the BIC score of a model <em style="italic">h</em> is computed as</p><p id="d18c27f25d2b4c3ea9bc1f96b743f02f">\\[ BIC(M)=K_{M}\\times logN-2LL(M) \\]</p><p id="f99ce456d1464700b155b10f8eb1eed4">where the variables <em style="italic">K</em><em style="italic"><sub>M</sub></em><em style="italic">, N,</em> and <em style="italic">LL(M)</em> are defined similarly as in AIC. A model with a smaller BIC value is considered better for inference. It can be shown that BIC is proportional to AIC, although the former penalizes complex models more heavily. For small training datasets, it may select models that are too simple.</p><p id="a079aae836ae4f3a889f383032fbab9c"><em>Minimum Description Length (MDL)</em>. Derived from information theory, the MDL score of a model <em style="italic">M</em> is computed as</p><p id="d6254fb0984445ed829af6336403e6eb">\\[ MDL =L(M)+L(D|H) \\]</p><p id="dff25728ddb842c4839d4195f6a15283">Where <em style="italic">L(M)</em> is the number of bits required to represent the model h, and <em style="italic">L(D|M)</em> is the number of bits required to represent the model predictions on the dataset. A model with a smaller MDL value is considered better for inference.</p></body></section></body></workbook_page>\n'