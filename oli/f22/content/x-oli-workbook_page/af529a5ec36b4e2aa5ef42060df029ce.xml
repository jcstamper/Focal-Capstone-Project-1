b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="af529a5ec36b4e2aa5ef42060df029ce"><head><title>Cluster Analysis</title></head><body><p id="e6c9adc0db1a4096af34c5bd1e0632ae">When we want to study the hidden structure of data and identify different groups within that structure, we use the <em style="italic">Cluster Analysis</em> technique. Once groups are constructed, it is safe to assume that data points within each group have similar features and are very dissimilar to data points in other groups. Cluster analysis is looking to define structure within a dataset.</p><p id="f0604509de79472e87cc053ce1c4692d">There are different types of clustering techniques. We will briefly define the general idea at this point and fully explore it in an upcoming module.</p><p id="c61d7d448407449abef16b1aa8a07497"><em style="italic">K-means clustering</em> is a widely used clustering technique that computes the distance between data points in a group and the center of the group. The number of clusters (k) is decided before the process begins, and <em style="italic">K-means</em> clustering can only be applied to numerical variables. This is because it solely uses <em style="italic">Euclidean distance</em> as a similarity measure to form clusters.</p><p id="ca14c17e1f31415c87826ff8d8074fb0">It is not uncommon to begin by randomly selecting a number of observations from the data as the initial cluster center, the remaining observations will then be assigned to the nearest cluster center. The algorithm continues to assign and reassign observations to their closest clusters by computing the cluster centroids (the middle of a cluster). The reassignment is done to minimize dispersion within clusters.</p><p id="cbdab700ac014e73afc5fe8321b5dac1"><em style="italic">Hierarchical clustering</em> connects data points to form clusters based on their distance and is also known as connectivity-based clustering. Each data point is considered its own cluster at the start of the process, and then the algorithm groups clusters based on similarity until true clusters are formed. This is also known as <em style="italic">agglomerative clustering</em>. </p><p id="da4140c2a57f44469031267d414b5437">There is another approach of hierarchical clustering that puts all data points in one cluster and then separates them based on dissimilarity until different clusters are formed. This is called <em style="italic">divisive clustering</em>. </p><p id="a3c68bc9f3614be1adc53265adb5d7b5"><em style="italic">Hierarchical clusters</em> are formed and represented using a <em style="italic">dendrogram</em> (shown below). The <em style="italic">y-axis</em> of a dendrogram marks the distance where clusters merge, and data points are placed on the <em style="italic">x-axis</em>.</p><image id="c1a608373e0d40ec8930f2bc4331dd2a" src="../webcontent/Dendogram.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="b55d233bd83a4c2e9f36a51dafdf65dc"><em style="italic">Example of a Dendrogram. (Source: Mathlab).</em></p></caption><popout enable="false"></popout></image><p id="ea5c5b5c29da49e7b36a7f93c4b6f193">Similar to regression and classification techniques, clustering output should be evaluated. Evaluation methods differ based on the kind of clustering technique used to meet your analytic objective. The next sections will focus on the different types of clustering techniques and the evaluation techniques that apply to each technique.</p><table id="bf0e16ebeb284fd680ecb44490849a35" summary="" rowstyle="plain"><cite id="i09c26293539144c88d378c100c150f1d" /><caption><p id="bc453c7cb2084be9b3e0abd586a08ba8" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="c651c52ab2c34194ace5fd694d575250"><em>Reading: </em><link href="https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html" target="new" internal="false">Evaluating Clustering Results</link></p></td></tr></table></body></workbook_page>\n'