b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE assessment PUBLIC "-//Carnegie Mellon University//DTD Assessment MathML 2.4//EN" "http://oli.web.cmu.edu/dtd/oli_assessment_mathml_2_4.dtd"><assessment xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" id="newd3754c59039849b5b758b248531e26ff" recommended_attempts="1" max_attempts="1"><title>Quiz 8</title><page id="f4db25355b4d4f7492b317a2d038b78b"><multiple_choice id="newd3754c59039849b5b758b248531e26ff_1a" grading="automatic" select="single"><body><p id="da05ba867e3b434ab31b7e3615364962">Consider a single-dimensional Python list that contains the elements of a matrix in row order (i.e., the elements of the first row from left to right, followed by the elements of the second row, followed by elements of the third row, etc.). For a student project, you need to re-implement <code><![CDATA[np.sum() ]]></code>for a 2d matrix with this underlying structure. You have two separate ways to implement this:</p><ul id="c966b7f125984105a2434420214bf830"><li><p id="a70d7d003cf445d797ad69d3ab1bcbab">Way 1:</p><codeblock id="d512fbacd098474ead511faf8b0feb82" syntax="text" highlight="" number="false" start=""><![CDATA[sum = 0\nfor index1 in range(numRows):\n   for index2 in range(numCols):\n     sum += array[index1*numCols +index2]\nreturn sum\n]]></codeblock></li><li><p id="c7febb5a63d74ecebc733b3d85173125">Way 2:</p><codeblock id="e971c75eac0b4c3399a39980c03e58ba" syntax="text" highlight="" number="false" start=""><![CDATA[sum = 0\nfor index1 in range(numCols):\n   for index2 in range(numRows):\n     sum += array[index2*numCols +index1]\nreturn sum\n]]></codeblock></li></ul><p id="f3b393c9e8424ff09453ff2de9125320">Which method is more time-efficient, if any?</p></body><input shuffle="true" id="ans" labels="false"><choice value="yes">Way 1 is more time efficient, as it exploits spatial locality.</choice><choice value="no">Way 2 is more time efficient, as it exploits spatial locality.</choice><choice value="db65eb7fe6d74b72ab879b0b2fedf824">Neither way is more time efficient, as lists are implemented as linked lists in Python and thus cannot reliably handle time-efficient caching.</choice><choice value="b66b3c18891c44a7a41bdd112e58e07f">Both ways are equally efficient, as they both exploit temporal locality well.</choice><choice value="fd655d9ac9af4fbf800e72a1f6e8aed5">Both ways are equally efficient, as Way 1 and Way 2 both iterate over the same elements and thus have the same time complexity.</choice></input><part id="f919135a9afb4e44848359dab8f3ba66"><response match="yes" score="10"><feedback><p id="c9edca6641c4461b951821c23e1d2605">Correct. As our matrix is row-ordered, we know that way 1 operates on the elements in order and thus is more time efficient.</p></feedback></response><response match="no" score="0"><feedback><p id="f159e5a78a5a4b57a91dead2718618ae">Incorrect. Way 2 accesses elements along the columns and is not a clear solution to this problem. Way 1, on the other hand, operates on the elements in order as the matrix is row-ordered and thus is more time efficient.</p></feedback></response><response match="db65eb7fe6d74b72ab879b0b2fedf824" score="0"><feedback><p id="dd36bc8ba1db4f01a3d33b7a9b13f3ed">Incorrect. Lists are implemented in Python using vectors / array-like semantics and thus will benefit from this optimization. Way 1 operates on the elements in order as the matrix is row-ordered and thus is more time efficient.</p></feedback></response><response match="b66b3c18891c44a7a41bdd112e58e07f" score="0"><feedback><p id="a3c37fe7f35146d7bffcc107b92420e3">Incorrect. As we do not iterate over the same elements at any point, the temporal locality is less exploitable here. Way 1 operates on the elements in order as the matrix is row-ordered and thus is more time efficient.</p></feedback></response><response match="fd655d9ac9af4fbf800e72a1f6e8aed5" score="0"><feedback><p id="c03fff109a0e4e58b1d0692a84b65689">Incorrect. Remember that algorithms with better time complexity do not necessarily have better performance. Way 1 operates on the elements in order as the matrix is row-ordered and thus is more time efficient.</p></feedback></response></part></multiple_choice></page><page id="b8bc579a34fd4a809fd95fd6f07d4f22"><multiple_choice id="e652ffeac187415da3e9e5a7c613cb99" grading="automatic" select="single"><body><p id="df51c22393a1436ebd95467a434967b6">You are building a web dashboard for data analytics and are tasked with improving the UI of the dashboard for incoming analysts. You make a change to the development server\xe2\x80\x99s copy of the code and go to view the development dashboard but realize that you cannot see your changes. In its place is the version of the dashboard you had been working on an hour ago.</p><p id="c2584309ea704ba3bbeb7b63df5aec76">Given what you know about the memory hierarchy and locality, what could explain this problem?</p></body><input shuffle="true" id="b09e527f2a054ec6b3c90341387b0cde" labels="false"><choice value="a13b4cf1da334f8a866a22f7dbf5066b">This is likely a problem introduced by the inherent temporal locality of memory. Visiting the page earlier kept the older version of the website in memory, and the cache needs to be cleared.</choice><choice value="b89c219983a142418bb3b15c1981326d">This is likely a problem introduced by the inherent spatial locality of memory. Visiting the pages around the website keeps a cache of that website in memory, and the cache needs to be cleared.</choice><choice value="c0803218fd9e477f901f140e60106dea">This is likely a problem with the amount of RAM on your laptop. As increasing the amount of RAM on your computer should increase the higher tiers of the memory hierarchy, you will be able to store the new code and thus access it faster.</choice><choice value="d88e7aaf5f324d329649691e53d32744">This is likely a problem with the amount of hard-disk space on your laptop. As increasing the size of that drive should increase the lower tiers of the memory hierarchy, you will be able to store all of your code in a single place and thus prevent problems.</choice><choice value="e1662e1c58934e689b61d0c9d1c97ecc">This is likely an unfixable problem, as this indicates a problem in your build system.</choice></input><part id="f056d596d7b14c05bf14212ccfa092d9"><response match="a13b4cf1da334f8a866a22f7dbf5066b" score="10"><feedback><p id="c1359d543bb842c7b4812e5bd9921a3d">Correct. As you have visited the dashboard before, the older version of the code is what is kept in cache. Clearing it should fix the problem.</p></feedback></response><response match="b89c219983a142418bb3b15c1981326d" score="0"><feedback><p id="b546010a309d45e789eaad3d9fc24de4">Incorrect. While it is definitely a cache problem, accessing links will not immediately cache the links around that website (imagine if you visited a large-scale archive site with such a feature). As you have visited the dashboard before, the temporal locality is at play instead. </p></feedback></response><response match="c0803218fd9e477f901f140e60106dea" score="0"><feedback><p id="f87956e8c2a1419e9d1592bce07d41e0">Incorrect. While increasing the size of any level of the hierarchy could help performance, it is likely not to do so, as the cached copy still exists. As you have visited the dashboard before, the temporal locality is at play instead, and if you clear the cache, the newer dashboard should come up.</p></feedback></response><response match="d88e7aaf5f324d329649691e53d32744" score="0"><feedback><p id="abd1a33edd2044ed847db415f6c07188">Incorrect. While increasing the size of any level of the hierarchy could help performance, it is likely not to do so, as the cached copy still exists. As you have visited the dashboard before, the temporal locality is at play instead, and if you clear the cache, the newer dashboard should come up.</p></feedback></response><response match="e1662e1c58934e689b61d0c9d1c97ecc" score="0"><feedback><p id="a4112206643a4040948a16c2cf1900fd">Incorrect. While it could be the problem of a weird build system, it is far more likely due to a problem with the temporal locality. As you have visited the dashboard before, the newer dashboard should come up.</p></feedback></response></part></multiple_choice></page><page id="a82679667fb842ba8f17d397e48af062"><multiple_choice id="dca39c3afd4246e7b09eeb9e5b69af09" grading="automatic" select="multiple"><body><p id="bb5fd7adeeb345e0bbb57e5bcf36e4c6">Consider a representation for matrices in Python using single-dimensional Python lists.  These lists store the elements of a matrix in row-major order (i.e., the elements of the first row from left to right, followed by the elements of the second row, followed by elements of the third row, and so on). Now we have two lists, A and B. List A holds a matrix with dimensions (m,n) and List B holds a vector of size n (actually a matrix of the dimensions (n,1)). You are tasked to re-implement the method <code><![CDATA[np.dot()]]></code> for matrix-vector multiplication efficiently with this underlying structure. You have two separate ways to implement this:</p><ol id="ade281abdb8f4c7cbb9db222b7b1fbce"><li><p id="c3ddb4eee7ae495981bf5ad2121209e9">Implementation 1:</p><codeblock id="f5f2cb5dd4e74a7cb38da2522c30c25d" syntax="text" highlight="" number="false" start=""><![CDATA[prod = [0 for i in range(m)]\nfor index1 in range(m):\n   for index2 in range(n):\n      prod[index1] += A[index1*n + index2] * B[index2]\nreturn prod]]></codeblock></li><li><p id="f54c21758cdb4b788866e1ea0b5c5b27">Implementation 2:</p><codeblock id="b862a879a8fa4445bc4139e233cc1f42" syntax="text" highlight="" number="false" start=""><![CDATA[prod = [0 for i in range(m)] \nfor index1 in range(n):\n   rowx = 0\n   for index2 in range(m):\n      prod[index2] += A[rowx +index1] * B[index1]\n      rowx+=n\nreturn prod]]></codeblock></li></ol><p id="cffd157a22144cdaa0eb490cffa2082d">Which of the observations below are correct when accessing lists A &amp; B?</p></body><input shuffle="false" id="f548acb3dbb54134af3a0722db171551" labels="false"><choice value="A">Implementation 1 exploits the spatial locality of A and the temporal locality of B.</choice><choice value="B">Implementation 1 exploits the spatial locality of A and B.</choice><choice value="C">Implementation 2 exploits both the temporal and spatial locality of B.</choice><choice value="D">Implementation 2 exploits both the temporal and spatial locality of A.</choice><choice value="E">Since lists are implemented as linked lists in Python, there is no locality that can be exploited.</choice><choice value="F">Both implementation 1 and implementation 2 exploit the temporal locality of A and B.</choice></input><part id="b6cf73057a704420a3cefde796a4f75e"><response match="B,C" score="10"><feedback><p id="b979b554f92f4374acacf567253a4055">A is incorrect.</p><p id="c5b068e768924ab4b20e498111a13a8c">Implementation 1 exploits the spatial locality of both A and B. Since the lists A and B are both accessed in order of the elements stored (row-major order). It does not exploit the temporal locality of either.</p><p id="aa94fdda9f764fbe945f10ada234d17c">B is correct.</p><p id="ab5a116da0524474a25f002c1931fe75">In implementation 1, the lists A and B are both accessed in the order of the elements stored (row-major order). Hence, it exploits spatial locality for both A and B. No temporal locality can be exploited.</p><p id="e7418da6d09346f7a1e7e1f6acbadef5">C is correct.</p><p id="b8be4dab3888419ca474db8dd6a35958">In implementation 2, the list A is accessed along the column and is not sequential to the order in which elements are stored in memory - hence spatial locality is not exploited. Matrix B is accessed sequentially (row-major order), exploiting spatial locality. The list B also exploits temporal locality by accessing the last used element again (by ensuring all operations involving the 1st element in B are completed before moving to the 2nd element, and so on). Thus, implementation 2 exploits both temporal and spatial locality for matrix B.</p><p id="b5cbab828a244feba5c390d33269fcec">D is incorrect.</p><p id="d5a7d45adf3749df9cbe2872215ad0ae">Implementation 2 does not exploit any locality of A. Since elements of A are accessed in column-major order, contrary to how they are stored - spatial locality is not exploited. Since elements in A are accessed only once and not revisited again - the temporal locality of A is not exploited.</p><p id="d1392b0d366d495190ff5a01292f78d6">E is incorrect.</p><p id="be82b616b7414194bf4e626da7668fa2">Lists are implemented in Python using vectors / array-like semantics and thus will benefit from locality-based optimizations.</p><p id="c7dd2efca48c42c78544897f4f1201b9">F is incorrect. </p><p id="b72dff50293741afad5254268d612a4e">Only Implementation 2 exploits the temporal locality of B. Note that elements of A are accessed only once and not revisited again. Hence, none of the above implementations exploit the temporal locality of A.</p></feedback></response><response match="B" score="5"><feedback><p id="df0d0d145b8b4fa1a43ef408895ac910">A is incorrect.</p><p id="f64347e3e1e740f89874f9180db3c739">Implementation 1 exploits the spatial locality of both A and B. Since the lists A and B are both accessed in order of the elements stored (row-major order). It does not exploit the temporal locality of either.</p><p id="a83e2a3b7b88484db03dd05596e721ee">B is correct.</p><p id="fc5f329fbcf2498bac1d1cba1a1e3773">In implementation 1, the lists A and B are both accessed in the order of the elements stored (row-major order). Hence, it exploits spatial locality for both A and B. No temporal locality can be exploited.</p><p id="b15e6dc0d4d84820af0eea39d9b88b4e">C is correct.</p><p id="c69849ffab4b450894b5cc899efbbde1">In implementation 2, the list A is accessed along the column and is not sequential to the order in which elements are stored in memory - hence spatial locality is not exploited. Matrix B is accessed sequentially (row-major order), exploiting spatial locality. The list B also exploits temporal locality by accessing the last used element again (by ensuring all operations involving the 1st element in B are completed before moving to the 2nd element, and so on). Thus, implementation 2 exploits both temporal and spatial locality for matrix B.</p><p id="d4f4a0b141e545dd809825e66bdf302d">D is incorrect.</p><p id="c8c8a5854ecf40f398b7a68249af019c">Implementation 2 does not exploit any locality of A. Since elements of A are accessed in column-major order, contrary to how they are stored - spatial locality is not exploited. Since elements in A are accessed only once and not revisited again - the temporal locality of A is not exploited.</p><p id="d00168a612ab472dab31ec721d841f6e">E is incorrect.</p><p id="d9ab07c9af3d4abaa4dd34dd28ea0544">Lists are implemented in Python using vectors / array-like semantics and thus will benefit from locality-based optimizations.</p><p id="b9201adc2b0d4fd990f98a984f17364f">F is incorrect. </p><p id="d97759b2845e401bb97035cab6dc2332">Only Implementation 2 exploits the temporal locality of B. Note that elements of A are accessed only once and not revisited again. Hence, none of the above implementations exploit the temporal locality of A.</p></feedback></response><response match="C" score="5"><feedback><p id="cd9264ff3a994eaf84772d5634366c0f">A is incorrect.</p><p id="d030ca2fb179453284c9a4b239378b9b">Implementation 1 exploits the spatial locality of both A and B. Since the lists A and B are both accessed in order of the elements stored (row-major order). It does not exploit the temporal locality of either.</p><p id="dc872e0176434b9bb2fd30211d8e1e45">B is correct.</p><p id="ee6a18c663cc45519c85b5e34152980a">In implementation 1, the lists A and B are both accessed in the order of the elements stored (row-major order). Hence, it exploits spatial locality for both A and B. No temporal locality can be exploited.</p><p id="a243d93aff3b4e8eb8db8438a3343dab">C is correct.</p><p id="f55a4749436b48ab96f2b8c5b27ffc66">In implementation 2, the list A is accessed along the column and is not sequential to the order in which elements are stored in memory - hence spatial locality is not exploited. Matrix B is accessed sequentially (row-major order), exploiting spatial locality. The list B also exploits temporal locality by accessing the last used element again (by ensuring all operations involving the 1st element in B are completed before moving to the 2nd element, and so on). Thus, implementation 2 exploits both temporal and spatial locality for matrix B.</p><p id="cf5082d4c7414e99bc14c86ec6106212">D is incorrect.</p><p id="bd119e5c8f024ecead58fdd0a7ba6570">Implementation 2 does not exploit any locality of A. Since elements of A are accessed in column-major order, contrary to how they are stored - spatial locality is not exploited. Since elements in A are accessed only once and not revisited again - the temporal locality of A is not exploited.</p><p id="f39d7ca3f134482492d8910be4ed7fa2">E is incorrect.</p><p id="af8e58e253be4dfa85a6e2cad1614f0b">Lists are implemented in Python using vectors / array-like semantics and thus will benefit from locality-based optimizations.</p><p id="a86c3427038448c8abdf0da3126dbfe6">F is incorrect. </p><p id="fc7ac02d0aba46ee9ead529324ac58ee">Only Implementation 2 exploits the temporal locality of B. Note that elements of A are accessed only once and not revisited again. Hence, none of the above implementations exploit the temporal locality of A.</p></feedback></response><response match="*" name="AUTOGEN_*" score="0"><feedback><p id="e7bf7346faf5440d863f081053df9ec3">A is incorrect.</p><p id="b0d6f50fa0f940eb90f74447f743adcd">Implementation 1 exploits the spatial locality of both A and B. Since the lists A and B are both accessed in order of the elements stored (row-major order). It does not exploit the temporal locality of either.</p><p id="b0bf130ea485480c9f7fa6b2cecea6ab">B is correct.</p><p id="f7b8cc6ea8314288a3f0f4f71ca622c9">In implementation 1, the lists A and B are both accessed in the order of the elements stored (row-major order). Hence, it exploits spatial locality for both A and B. No temporal locality can be exploited.</p><p id="a3caee4528764c9e9ca14a6fade25d0f">C is correct.</p><p id="e5adeb6d0c2b403ebe7bb759b70bfcba">In implementation 2, the list A is accessed along the column and is not sequential to the order in which elements are stored in memory - hence spatial locality is not exploited. Matrix B is accessed sequentially (row-major order), exploiting spatial locality. The list B also exploits temporal locality by accessing the last used element again (by ensuring all operations involving the 1st element in B are completed before moving to the 2nd element, and so on). Thus, implementation 2 exploits both temporal and spatial locality for matrix B.</p><p id="fe49db0aa2324ed6848af9e3a677d19d">D is incorrect.</p><p id="ef0de603ae614e289100fcc4587d0f9e">Implementation 2 does not exploit any locality of A. Since elements of A are accessed in column-major order, contrary to how they are stored - spatial locality is not exploited. Since elements in A are accessed only once and not revisited again - the temporal locality of A is not exploited.</p><p id="c30a4b77e05d4f469293ec495733b060">E is incorrect.</p><p id="dce448dcef254ec48c510b4bb55fac2b">Lists are implemented in Python using vectors / array-like semantics and thus will benefit from locality-based optimizations.</p><p id="cf29b198384b4c84aa92b9c6d8078eca">F is incorrect. </p><p id="bb22f6c6f3704b3e825113fd79d5f9d7">Only Implementation 2 exploits the temporal locality of B. Note that elements of A are accessed only once and not revisited again. Hence, none of the above implementations exploit the temporal locality of A.</p></feedback></response></part></multiple_choice></page><page id="d3951657db8c42e9a156010213abadf1"><multiple_choice id="aeca3e25b37a4ea291b599ea40f1f09d" grading="automatic" select="single"><body><p id="caee6a65e46e4329b2522f953c8ac808">You are working with sklearn to build predictive models on customer data to predict customer behavior for a large fortune 500 company. You are getting frustrated due to the slow performance of sklearn on your laptop and want to get better results as quickly as possible.</p><p id="cd9cb764ca0348ad89a0b115c5d7a318">Of the following, what is your best course of action to get better results, given time and money?</p></body><input shuffle="true" id="c60554d54df641b1843b28fe146323d3" labels="false"><choice value="cf0b0c22f005448eb5e8decfae20472a">Get yourself a new laptop with the fastest available consumer-grade CPU and the largest  RAM. This will cost $1500 and take 8 hours to properly set it up for your task at hand.</choice><choice value="f86c765e85b94c4d9c362b35d3e54926">Get yourself access to a TPU cluster, and apply your code there. This will cost about $4.3 per hour of computing time and will also take 8 hours or so to set up properly.</choice><choice value="fcb28e7d9ef548caa665b7067f4e6276">Get yourself access to Colab Pro Plus and apply your code there on a GPU device. This will cost about $50 a month but will only take 2-4 hours to set up, and you will not have to worry about computing time costs.</choice><choice value="d564b51a461149f7b7b59e7dab1861fe">Re-write the entire codebase to use MapReduce instead. This will take a significant amount of time (&gt; 100 hours) and require $5 per hour to run due to the custom nature of your job but it will allow you to scale to high amounts of data.</choice><choice value="c30ee34608384f4daf293f9769d4477c">Find a library other than sklearn to use.</choice></input><part id="a99ec6b6bc854166add6fc6ab61f0d54"><response match="cf0b0c22f005448eb5e8decfae20472a" score="0"><feedback><p id="b4804fea0845463cab18b95833c67efe">Incorrect. This is the costliest option, and yet it will only offer marginally better results. While Moore\xe2\x80\x99s Law might have led to this option before, performance requires better software nowadays rather than waiting a couple of years for better hardware.</p></feedback></response><response match="f86c765e85b94c4d9c362b35d3e54926" score="0"><feedback><p id="a4112b5926134767a44cfcb55c9b1878">Incorrect. While a TPU cluster might offer better results, sklearn is a purely CPU-based package and will not use the hardware allocated to the best extent. As a result, you are probably better off finding a better library.</p></feedback></response><response match="fcb28e7d9ef548caa665b7067f4e6276" score="0"><feedback><p id="e26f1a36ec3944b0b81de068bc257752">Incorrect. While Colab Pro might offer marginally better results, sklearn is a purely CPU-based system. As a result, you are probably better off finding a better library.</p></feedback></response><response match="d564b51a461149f7b7b59e7dab1861fe" score="0"><feedback><p id="d8b0b8d0daa74dc39a4900221203d568">Incorrect. While re-writing the codebase might be a strategy, rewriting code from sklearn to MapReduce is incredibly costly technically and still requires more computing power than using Colab or a TPU. Instead, it\xe2\x80\x99s likely best to find a replacement library and try to get it working instead.</p></feedback></response><response match="c30ee34608384f4daf293f9769d4477c" score="10"><feedback><p id="ccae214fa507424695c832ceba9395a7">Correct. While you could get marginally better results with a better CPU or better hardware, it is likely that you will need to use some sklearn replacement or use another software stack to improve performance much more. An example could be \xe2\x80\x98scikit-learn-intelex.\xe2\x80\x99</p></feedback></response></part></multiple_choice></page><page id="e4b6f8d6f1414e6b8305ffb186c066d9"><multiple_choice id="b3fee5a04ed546cba240ff0c3696d4dc" grading="automatic" select="single"><body><p id="c1c5b09cfe7049dd8beffb713217f8c5">You\xe2\x80\x99re actively working on a codebase that runs small ML jobs on the cloud and wanting to store and write the processed data as you actively work on the system. Now you want to start processing much larger ML jobs. What is the best option for cloud storage, assuming you are already working on a cloud instance?</p></body><input shuffle="true" id="a843ec39b1f04cae8d94dbb9b20e52dc" labels="false"><choice value="feafcea737814ce0818a954ae3e59f00">Block-based storage, like AWS\xe2\x80\x99s Elastic Block Storage.</choice><choice value="b81dd1245c38474bb4ce3283025e0c77">Object-based storage, like AWS\xe2\x80\x99s S3.</choice><choice value="cf012227a5c747abb85d700aea4b3692">A relational database, like AWS\xe2\x80\x99s RDS.</choice><choice value="db78c4d789ca408faba10843101dd81c">A No-SQL database.</choice><choice value="ce4f8661c69142c4a896a9b3faa53fdd">A personal data cloud system, like Google Drive.</choice></input><part id="c57ac3c4dc424064a5a7f510dfd76408"><response match="feafcea737814ce0818a954ae3e59f00" score="10"><feedback><p id="f23c7eec4c2f4b878e8f6ac9180b6c2d">Correct. Block storage is as close to a local drive you can work with as possible, so thus, this is the best choice for something akin to that on the cloud.</p></feedback></response><response match="b81dd1245c38474bb4ce3283025e0c77" score="0"><feedback><p id="f4f58d391ee745a18322493f18a4d6f3">Incorrect. Object-based storage happens to be a poor choice, namely as it tends to be slow in writing and editing but fast in reading. Block storage is as close to a local drive you can work with as possible and, thus, is the best choice for something akin to that on the cloud.</p></feedback></response><response match="cf012227a5c747abb85d700aea4b3692" score="0"><feedback><p id="ccd2162202604cab9a31b6b7a66bfd73">Incorrect. As our data is a bunch of files, we would need to perform significant work to change them into the structure required for a database. Block storage is as close to a local drive you can work with as possible and, thus, is the best choice for something akin to that on the cloud.</p></feedback></response><response match="db78c4d789ca408faba10843101dd81c" score="0"><feedback><p id="f3a7c6d4bf6a4024aa46c71c7412f1f9">Incorrect. As our data is a bunch of files, we would need to perform significant work to change them into the structure required for a database. Block storage is as close to a local drive you can work with as possible and, thus, is the best choice for something akin to that on the cloud.</p></feedback></response><response match="ce4f8661c69142c4a896a9b3faa53fdd" score="0"><feedback><p id="b9c5f9583f2c4a828cf36e4b502da6c4">Incorrect. While Google Drive is a decent solution for global file storage and is used in some git-like systems, it is slower to write compared to block storage.</p></feedback></response></part></multiple_choice></page><page id="e309d8aa46f54bf8ab60827fb3bae7ca"><multiple_choice id="efd3a5b9f0c8401688678ca20e4f5e59" grading="automatic" select="single"><body><p id="d04655e1af0348b98d08aa1a62e6c326">You\xe2\x80\x99re actively working on a codebase that runs small ML jobs on the cloud, and want to store large model checkpoints. You will not need to edit them at any point, but downloading them should be quick. What is the best option for cloud storage, assuming you are already working on a cloud instance?</p></body><input shuffle="true" id="ef4be41e28604f9eb773c59b3a582c25" labels="false"><choice value="df23d1b10a154a8b9e64d62dbe6c4369">Block-based storage, like AWS\xe2\x80\x99s Elastic Block Storage.</choice><choice value="b64279fdf2a74b1cb112c144cd39018e">Object-based storage, like AWS\xe2\x80\x99s S3.</choice><choice value="c2411198165547d09291fce20ee5d1e7">A relational database, like AWS\xe2\x80\x99s RDS.</choice><choice value="c2ec3d1c410844afa7509116b7b2761b">A No-SQL database.</choice><choice value="a655601fedac47539868264c8379f7f2">A personal data cloud system, like Google Drive.</choice></input><part id="ce5a476f54034a19aaa8bca29a0c5351"><response match="df23d1b10a154a8b9e64d62dbe6c4369" score="0"><feedback><p id="e226aacfed1d462382d54332b1cfb2c0">Incorrect. While block-storage can handle this problem, it can be difficult to access this data later on. Additionally, as the files are large, it will cost a lost more than object storage, which is the right choice for large binary files that will not change.</p></feedback></response><response match="b64279fdf2a74b1cb112c144cd39018e" score="10"><feedback><p id="b209da8872f64ea594828a33cccb4ec2">Correct.</p></feedback></response><response match="c2411198165547d09291fce20ee5d1e7" score="0"><feedback><p id="a96a6255ac544f9ba8ae807ba919e80d">Incorrect. As our data is a bunch of files, we would need to perform significant work to change them into the structure required for a database.</p></feedback></response><response match="c2ec3d1c410844afa7509116b7b2761b" score="0"><feedback><p id="ff9e952492144d06a7c3c036fec80e7d">Incorrect. As our data is a bunch of files, we would need to perform significant work to change them into the structure required for a database.</p></feedback></response><response match="a655601fedac47539868264c8379f7f2" score="0"><feedback><p id="bd1ec0c89b1c49268899cd23fce786bc">Incorrect. While Google Drive is a decent solution for global file storage, it does not scale that well to uploading and handling large binary files. In fact - there is no easy way to upload files to Google Drive in comparison to S3.</p></feedback></response></part></multiple_choice></page><page id="ac1498d088d04c6d87cb8821f166f9f4"><multiple_choice id="b45a3efbc022411288badea983123e59" grading="automatic" select="single"><body><p id="b19635cf252e4a2cae470eddfd7782fe">You\xe2\x80\x99re actively working on a codebase that handles highly structured tabular data, specifically client records. This data neatly fits into a CSV file but will be updated constantly. What is the best option to store this file on the cloud?</p></body><input shuffle="true" id="ee69401b516b43bfb3b9412d7daed4c5" labels="false"><choice value="dafd15f59518466fa0b3412f70a0d0b1">Block-based storage, like AWS\xe2\x80\x99s Elastic Block Storage.</choice><choice value="e01e3929f8004ff7abfcf0ddce18483c">Object-based storage, like AWS\xe2\x80\x99s S3.</choice><choice value="ca42d7d5b1dc47e882b7783934324101">A relational database, like AWS\xe2\x80\x99s RDS.</choice><choice value="f6e875aed3e04113b80bf98f94628825">A No-SQL database.</choice><choice value="b41c779dc83845a580ac2cab59e48bfd">A personal data cloud system, like Google Drive.</choice></input><part id="eb97901812654dbdab59d08e6245639e"><response match="dafd15f59518466fa0b3412f70a0d0b1" score="0"><feedback><p id="d12e498c84ae40f0a14a1cb5a96df6db">Incorrect. While you can use this system to handle this, constant edits to a local file are much much slower compared to using a relational database, where the edits are atomic, and multiple edits can happen simultaneously.</p></feedback></response><response match="e01e3929f8004ff7abfcf0ddce18483c" score="0"><feedback><p id="fd40db1721e841ea9b548c78984178c7">Incorrect. While you can use this system to handle this, constant edits to a local file are much much slower compared to using a relational database, where the edits are atomic, and multiple edits can happen simultaneously.</p></feedback></response><response match="ca42d7d5b1dc47e882b7783934324101" score="10"><feedback><p id="a0d7e5c2c4334f4b90ec4c1892d3cf4b">Correct.</p></feedback></response><response match="f6e875aed3e04113b80bf98f94628825" score="0"><feedback><p id="c67e5b4290714653a1930fe4badd84f6">Incorrect. As our data is incredibly structured, we can use a relational database instead of a NoSQL database for this problem, which will likely be faster given the constant update operations.</p></feedback></response><response match="b41c779dc83845a580ac2cab59e48bfd" score="0"><feedback><p id="a6f903d8467a48d9af922cb22ac88489">Incorrect. While you can use this system to handle this, constant edits to a local file are much much slower compared to using a relational database, where the edits are atomic, and multiple edits can happen simultaneously.</p></feedback></response></part></multiple_choice></page><page id="b7b2f8bc10cd4b0394a6a60b257bf946"><multiple_choice id="ddcd03bb81834d86bde374d05dda5863" grading="automatic" select="single"><body><p id="a234d60fa7d74088ab543b48cb79f57f">Assume you are working on a large numerical algebra codebase, where every operation is handled by looping through each element of each array, and handling the associated operations one by one, <em>in Python</em>. Given what you know about practical data science optimization, what is the best tool to start optimizing the codebase\xe2\x80\x99s performance?</p></body><input shuffle="true" id="e11eb8cb06ef45e5a78e8cd2df7e26ae" labels="false"><choice value="b74f5e847e054c3f8e41f744c0ada355">Re-write the code to use vectorization.</choice><choice value="beb25ad31656441eaaac8c76cf8b2c10">Re-write the code using C++, or another compiled programming language.</choice><choice value="a7b1fe9df97648e684f8b48ce3129be8">Use multi-threading to split up jobs into smaller parts, and work on them each independently in a custom way.</choice><choice value="e9264dc98a60431b8940a8175ad61eaa">Profile the code first, and then re-write the codebase using C++.</choice><choice value="b5be3bf5a76d41bb9b8c80885ccfdcbf">Profile the code first, and then re-write the codebase using vectorization.</choice></input><part id="e08fc02473be4686847197406f3b61ba"><response match="b74f5e847e054c3f8e41f744c0ada355" score="0"><feedback><p id="c6484372057741418e63d70eb5e03181">Incorrect. While this is a good answer, remember to profile before optimizing. If a majority of the codebase does not need to be optimized for the job you wish to run, then it\xe2\x80\x99s likely that you do not need to touch it at first.</p></feedback></response><response match="beb25ad31656441eaaac8c76cf8b2c10" score="0"><feedback><p id="bb4de74b4991487cb4d5b376cf718840">Incorrect. While this is a reasonable answer, re-writing code into another language can be incredibly taxing and require tons of language-specific knowledge. It\xe2\x80\x99s usually a better alternative to use a tool like vectorization and to start by profiling to see where the problem is first.</p></feedback></response><response match="a7b1fe9df97648e684f8b48ce3129be8" score="0"><feedback><p id="f8adfc08d6d148e0b52f272f7c8699b3">Incorrect. While multithreading is used to speed up jobs, you want to profile the code first to make sure that you are optimizing the slowest code first. Additionally, most vectorization/matrix processing libraries automatically handle this for you to some degree, making this a challenging and potentially useless endeavor in practice.</p></feedback></response><response match="e9264dc98a60431b8940a8175ad61eaa" score="0"><feedback><p id="c87cfc398e15433e85cf6e52985bb9eb">Incorrect. While this is a reasonable answer, re-writing code into another language can be incredibly taxing and require tons of language-specific knowledge. It\xe2\x80\x99s usually a better alternative to use a tool like vectorization and to start by profiling to see where the problem is first.</p></feedback></response><response match="b5be3bf5a76d41bb9b8c80885ccfdcbf" score="10"><feedback><p id="efc88593fd3a4abbb80db214464754af">Correct.</p></feedback></response></part></multiple_choice></page><page id="ab8339607f4c44c295d1976ad2c4f7ea"><multiple_choice id="e3c9834f8d7d4ef7b3af3a70b9c4524c" grading="automatic" select="single"><body><p id="f998a03c81654a4fbfb80e295b0cac55">You are tasked with making a hardware choice for the end-to-end training of a model. The training procedure for this model uses matrix computations and frequently retrieves data from a database service on the cloud. What would be the correct hardware choice to accelerate the overall training procedure?</p></body><input shuffle="true" id="fa1ec81dc8fb4aaa8f6913b5a21b7251" labels="false"><choice value="a262e3042bdb4cbe811f89ebe0b79286">GPU to handle training and multiple CPUs to handle network reads.</choice><choice value="e47b8a4610bf49d48d0c87db585bb674">Multiple GPUs to handle training and network reads.</choice><choice value="f863e50019eb4c48ae2a65e3ab309c57">Multiple TPUs to handle training and network reads.</choice><choice value="e80439d9a86d46f4be613f07d291f93b">A single GPU to handle the entire training procedure.</choice><choice value="dd041614111f4764ae4c96be0e4ce0a3">Choice of hardware does not matter in this case as the training characteristics would mean a similar performance across all hardware choices.</choice></input><part id="a4001db1e8a94546a5b2144aa21b1528"><response match="a262e3042bdb4cbe811f89ebe0b79286" score="10"><feedback><p id="ccdaadb5bedd434682e8ee17ce4d4a2c">Correct. Since there is a heavy interaction between the model and the network (for reading from the cloud), using accelerators such as GPUs and TPUs may not yield the desired speed-up as opposed to using just the CPU.</p></feedback></response><response match="e47b8a4610bf49d48d0c87db585bb674" score="0"><feedback><p id="aa680af543bb4323903365036a00d7d7">Incorrect. GPUs are not the appropriate choice to perform network reads.</p></feedback></response><response match="f863e50019eb4c48ae2a65e3ab309c57" score="0"><feedback><p id="b860e327d51e4f6eae06bbbc7a592ffb">Incorrect. TPUs are not the appropriate choice to perform network reads.</p></feedback></response><response match="e80439d9a86d46f4be613f07d291f93b" score="0"><feedback><p id="bf16d4d7b2ed414baa9779414bf75ae9">Incorrect. GPUs are not the appropriate choice to perform network reads.</p></feedback></response><response match="dd041614111f4764ae4c96be0e4ce0a3" score="0"><feedback><p id="ffc79fe9b870497ab7cacb7edc81aa52">Incorrect. Chaining multiple CPUs to handle the network reads paired with the speed-up from parallel matrix computations in the GPU will yield better performance than the other choices.</p></feedback></response></part></multiple_choice></page><page id="dbe4a46d2e5b4cbdaa900bb417bff342"><multiple_choice id="fc880a54a71549dcaf65189631f372ff" grading="automatic" select="single"><body><p id="ac1b62fb328b463bac3017814999ef4b">You are tasked with making a hardware choice between CPU, GPU, and TPU (a domain-specific architecture) for training a model. The model training has the following characteristics:</p><p id="a9d7cdc2fa4748e6a4952b3d9087142e">- The model is a complex neural network to learn face recognition.</p><p id="e6132942a2144ce8bfadc558389c4d61">- The model size is medium to large, having a few hundred million parameters</p><p id="e5c0546b742e4bac8937d5eb1c480bbc">- The model uses large batch sizes for training.</p><p id="bcaf8e58eff540b788afe346347ddb74">- Training cost (the money it takes to run the chosen hardware) is not a concern.</p><p id="bb39bfae70a041d0abf8840ded1aaaa4">What would be the correct hardware choice in this scenario?</p></body><input shuffle="true" id="eefa19cc0c1e42858c4bcbdb7ec27f8c" labels="false"><choice value="a8a40d58ff75470892f577ee2d14e203">CPU</choice><choice value="e19ecde6a6d2471f9b5462c6e82dc3c0">GPU</choice><choice value="a1695d1ea989478d8235a79a7ba0d815">TPU</choice><choice value="fc72bb24f6a54c69a2a764b178772b69">Either CPU or GPU.</choice><choice value="b2d6b8a7021543fa989d89e80fda820b">Choice of hardware does not matter in this case as the training characteristics would mean a similar performance across all hardware choices.</choice></input><part id="a1d9c4b673dc42879f88a58435142238"><response match="a8a40d58ff75470892f577ee2d14e203" score="0"><feedback><p id="f9e9928d99fe47c4aef0cd8f99acb6c8">Incorrect. CPUs are more suited for training smaller models with small, effective batch sizes.</p></feedback></response><response match="e19ecde6a6d2471f9b5462c6e82dc3c0" score="0"><feedback><p id="f689471b945d4ef18500d0e767c3e2d9">Incorrect. TPUs are more suitable than GPUs for training large-sized neural networks with large batch sizes.</p></feedback></response><response match="a1695d1ea989478d8235a79a7ba0d815" score="10"><feedback><p id="ccb94aaf9d1a45c58d849470c567f02f">Correct. TPUs are custom-built to perform more optimally with neural networks and work well with large batch sizes.</p></feedback></response><response match="fc72bb24f6a54c69a2a764b178772b69" score="0"><feedback><p id="fc826840aa31427cb42709278f16f30a">Incorrect. When training cost is not a concern, TPUs are more suited for this use case than CPUs and GPUs.</p></feedback></response><response match="b2d6b8a7021543fa989d89e80fda820b" score="0"><feedback><p id="a6e817e82a5e44c1a0059893951e981b">Incorrect. The specific nature of training makes TPUs highly suitable for training and would outperform CPUs and GPUs.</p></feedback></response></part></multiple_choice></page></assessment>\n'