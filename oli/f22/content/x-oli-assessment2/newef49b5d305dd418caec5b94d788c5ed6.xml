b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE assessment PUBLIC "-//Carnegie Mellon University//DTD Assessment MathML 2.4//EN" "http://oli.web.cmu.edu/dtd/oli_assessment_mathml_2_4.dtd"><assessment xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" id="newef49b5d305dd418caec5b94d788c5ed6" recommended_attempts="1" max_attempts="1"><title>Quiz 5</title><page id="c32c83a6748743338ef5961cbd030ade"><multiple_choice id="fac1ad5fa2ca4920a33f3404db188670" grading="automatic" select="single"><body><p id="a66a831c4cc34638b05f30a8701c01c3">Suppose the gold standard Named Entity (NE) tags for a news text are as follows where [...] indicate NE spans (types of the NEs are not shown)</p><quote>[Microsoft Corp.] CEO [Steve Ballmer] announced the release of [Windows 7] today</quote><p id="b704791e18d64d8cb4c344a7ab77f834">Your named-entity recognizer, however, outputs:</p><quote>[Microsoft Corp.] [CEO] [Steve] Ballmer announced the release of Windows 7 [today]</quote><p id="b2e1f67b750441a1a40518ce8122e407">What is the recall of your named-entity recognizer?</p></body><input shuffle="true" id="d6f197b29db4435e8aaefad836c13a29" labels="false"><choice value="afeac21ddc2548fab3be3a4e1d461c6a">1/4</choice><choice value="f0bc815caf9d4734b3e3dd86bc748853">3/4</choice><choice value="b2fcb8106baf409191f69aaac7c0e7c8">1/3</choice><choice value="d1ea068a4ce24714ad008c742591c833">2/3</choice></input><part id="c9b987d54e9447d08cfa5f692b1e502c"><response match="afeac21ddc2548fab3be3a4e1d461c6a" score="0"><feedback><p id="baddf4ff22d4463a9e14dca5c1759b95">Recall is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it should have recognized (3, as given in the gold standard).  So the recall is 1/3 (option 3). The other options are incorrect.</p></feedback></response><response match="f0bc815caf9d4734b3e3dd86bc748853" score="0"><feedback><p id="a1556b09c9c04cf78774be9d9f74e4cc">Recall is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it should have recognized (3, as given in the gold standard).  So the recall is 1/3 (option 3). The other options are incorrect.</p></feedback></response><response match="b2fcb8106baf409191f69aaac7c0e7c8" score="10"><feedback><p id="b5982617f417483192b25e10f2c467d7">Recall is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it should have recognized (3, as given in the gold standard).  So the recall is 1/3 (option 3). The other options are incorrect.</p></feedback></response><response match="d1ea068a4ce24714ad008c742591c833" score="0"><feedback><p id="dc5bced14df2496190250765fa34ffe8">Recall is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it should have recognized (3, as given in the gold standard).  So the recall is 1/3 (option 3). The other options are incorrect.</p></feedback></response></part></multiple_choice></page><page id="e2044c83d10d4d148a7d35d14d1b6621"><multiple_choice id="e30dcc1cedf346569ad900cc4667d649" grading="automatic" select="single"><body><p id="c7f4d7a90dd94bd3a7dd35f17572e3c4">You have the same Named Entity (NE) recognizer and the input sentence in Question 1. What is the precision of your named-entity recognizer?</p></body><input shuffle="true" id="de38af98f8a844e39117db1a3eeda2b3" labels="false"><choice value="f65730ffdb0f48f4b2b54d8cb8976b94">1/4</choice><choice value="c22facb43f8f456484b34c1f35088dd8">3/4</choice><choice value="d16310e61b834a1e86fe108ee8e6bd67">1/3</choice><choice value="bdfe4500ecfa4b51a2394b80631f4830">2/3</choice></input><part id="fefca0f5f2d84125993c89be9b9ebaee"><response match="f65730ffdb0f48f4b2b54d8cb8976b94" score="10"><feedback><p id="bb7f42c2914848748a212cad49d0adcd">Precision is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it has recognized (4, as given in the output).  So the precision is 1/4 (option 1). The other options are incorrect.</p></feedback></response><response match="c22facb43f8f456484b34c1f35088dd8" score="0"><feedback><p id="c3b8dc55fadb402db5de22104b2b41f2">Precision is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it has recognized (4, as given in the output).  So the precision is 1/4 (option 1). The other options are incorrect.</p></feedback></response><response match="d16310e61b834a1e86fe108ee8e6bd67" score="0"><feedback><p id="d7b68584df214706a8c6ef77af318caa">Precision is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it has recognized (4, as given in the output).  So the precision is 1/4 (option 1). The other options are incorrect.</p></feedback></response><response match="bdfe4500ecfa4b51a2394b80631f4830" score="0"><feedback><p id="f0ec50cc287748fdb7763dc15ce4808e">Precision is the ratio of the number of named entities that your named-entity recognizer correctly recognizes correctly (1 in this case) to the number of named -entities it has recognized (4, as given in the output).  So the precision is 1/4 (option 1). The other options are incorrect.</p></feedback></response></part></multiple_choice></page><page id="be2e85d7be504afb9f4a46076031c1db"><multiple_choice id="ae75d2b780ee4734aec2220323d0079b" grading="automatic" select="single"><body><p id="c94e6c8135094cd3a98dfc8504b14852">Consider the following statements:</p><p id="e8460cb5816940a08d446e6e6062cf35">A. The main goal of stemming is to reduce the words to a base form which is not the goal for lemmatization.</p><p id="e0471b96b92846fcbe4bb288367881cd">B. Stemming generally uses a crude heuristic process that chops off the ends of words, while lemmatization depends on morphological analysis of the words.</p><p id="cb2ac255954e4354b37ac84c8042a2a0">C. Named Entity Recognition (NER) must be performed before performing Part of Speech (PoS) tagging.</p><p id="be5c16b6b528496eada247ba89c468ad">D. Tokenization is used to generate a more efficient representation of text data.</p><p id="ec34b358ffc24dc0bb94b08222e07138">E. Stopword removal is the process of removing frequently occurring words that are not relevant for a Language Processing task.</p><p id="a66c0d5bf16c4a4ebe7d11ae4b8a4fbd">Which is (are) true about Language Processing Tasks?</p></body><input shuffle="true" id="eea4cbfee3a445ebadcc1a3a39fce221" labels="false"><choice value="e31de31170d942b78c0faf1be8bbea3a">B and E</choice><choice value="fb62e2dea0854796b6f21de2fe8356f0">B only</choice><choice value="c6fba2f0574b4181a0579546f8915d4c">A and D</choice><choice value="d9dfb015e4b141aab2470502fccbfe36">C and E</choice><choice value="fa2d7c9be92448008dbc1444b3d260b6">C and D</choice><choice value="af46b91c30e64b81a1ed7754090235ab">A, B, and E</choice></input><part id="a792d7db524d45bb860641ab3992b5f2"><response match="e31de31170d942b78c0faf1be8bbea3a" score="10"><feedback><p id="a9b9ca4c223f4991bb617fb48ee293b3">Correct. </p><p id="d90a52f2248e41c3baa5a154b4de562c">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="dfdd451af9f34f76925fba4eb512b5db">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="f9235a0c5e9f40d384924306aeb8866d">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="a74fdecfce1e4fa6877d06f7b80283e7">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="d2f499b4201744ecb6a31014d6c299b0">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response><response match="fb62e2dea0854796b6f21de2fe8356f0" score="0"><feedback><p id="b5d6ef7c66254755854341bcfb67321b">Incorrect. </p><p id="cd87a55cab8146eabb457cf26c924278">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="f5df719a52c64c23a834cd1381df8c9d">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="ea2915fe6e6d43d7bf44358275a31911">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="f5630192fce14440b1c8a53178b02f5d">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="fd205c07e3fd4b0fbed6b48670269d8c">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response><response match="c6fba2f0574b4181a0579546f8915d4c" score="0"><feedback><p id="fda996633202446ca48262846bfedd04">Incorrect. </p><p id="b225582db68c48e6a540268dd7770efe">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="be667f40cc92489ca2a20e9583f8847f">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="c046ac3b4efd498c89a1717e9cc9f240">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="ebfe798128df4079a1c6a5b89511400d">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="bdf3c2477eff44bc9f7447afce92b9bf">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response><response match="d9dfb015e4b141aab2470502fccbfe36" score="0"><feedback><p id="ec14470dfa364e689be767c7b8fe8a20">Incorrect. </p><p id="d252c0e23b4940c887a62ddfd179e84b">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="b016d166967947898fe8ced9f2e723a4">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="ecb56cc4ec234780b60045834f6608aa">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="c6e5c9a394344a3f849f743be440682c">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="bda587b6d5ad4c24b7f8974c57750cd4">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response><response match="fa2d7c9be92448008dbc1444b3d260b6" score="0"><feedback><p id="d43ff7c172a140a584c01b7c3d787b26">Incorrect. </p><p id="c0a487a4308741b5b3b70180f763d070">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="efdee38c338349fc8bbedacc5e36f9f7">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="d260c6d3d33e47adb807d77f4ff972f5">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="f4f377aee8984df8a36e4aea49391963">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="f31903c13ce54c4ab65c93595c6ea70f">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response><response match="af46b91c30e64b81a1ed7754090235ab" score="0"><feedback><p id="af17a14a96ce4eb482fc200688b75159">Incorrect. </p><p id="d3a32fc9718d4735a9d278d15dd72c1f">A is incorrect. The main goal of both lemmatization and stemming is to reduce a word to a base form. </p><p id="f4bc18707d494119b24717c3c067c748">B is correct. Stemming often uses a crude heuristic to chop off the word ends to reduce it to a base form, but lemmatization requires morphological analysis to get the base form of the word.</p><p id="d7ace77677dd4da6956603363946f1e0">C is incorrect. PoS and NER recognition can both be performed independently.</p><p id="c39d48455fc84d6f9643e77c4c90021a">D is incorrect. Tokenization is done to analyze the smaller components(tokens) of text data, and efficient representation is not its primary goal of it.</p><p id="eed0514650724cefba85c260e99d55ea">E is correct. Stopword removal is the process of filtering out words that are not inherently meaningful and hence, are not relevant to the task.</p></feedback></response></part></multiple_choice></page><page id="aa2decb345c24ae79b4da97f8e6e37d6"><ordering id="f1457f267f8b4b75833694a09e35cdce" grading="automatic"><body><p id="aab23ce1a9134b368c2eeb9ee8cf5f6f">HBO wants to come up with a product that can take movie reviews and come up with useful information with it. Identify which NLP Task/Application the input-output combination most likely falls under and select the option that has the right ordering for NLP Task/Application.</p><ol id="f28db553c04b4b50ac4a2c62283d21b4"><li><p id="d98aad58796748f9967881daf7762371">Input: List of Movie Reviews by various reviewers.</p><p id="af26e88fdba441b688d3197ef14e64a3">Output: Finding whether the movie was good, bad, or average by looking at the reviews.</p></li><li><p id="df3b1096dfc54894a047227b46d2f8de">Input: Movie reviews of the movie \xe2\x80\x9cParasite\xe2\x80\x9d in Korean.</p><p id="c7b328b3328a44a79b384cf5de3c9f65">Output: The same movie reviews of the movie \xe2\x80\x9cParasite\xe2\x80\x9d in English.</p></li><li><p id="d58ff735f7a947e483b988c3070b9850">Input: Collection of all Movie reviews for the movie \xe2\x80\x9cLa La Land.\xe2\x80\x9d</p><p id="d7a0aca9dd4c497b987e4a766fc84104">Output: Finding specific parts of the movie that the viewers liked the most.</p></li><li><p id="ea1c09918b3d46ec83850bd1354ed9f9">Input: Movie reviews of several movies in the years 2000-2022</p><p id="b166117e47454322921c483452ea7f37">Output: Genre-wise classification of the movie reviews (Superhero movies, Romance movies, Thrillers, Horror movies, etc.)</p></li></ol></body><input shuffle="true" id="a96363fae34a44479b59cf886498b009"><choice value="A">Sentiment Analysis</choice><choice value="B">Machine Translation</choice><choice value="C">Information Extraction</choice><choice value="D">Topic Modeling</choice></input><part id="ba37b923876d4bf780fbeb2346b04f7e"><response match="A,B,C,D" score="10"><feedback><p id="e17f864704824f52b89ea2e764d0c5fa">Correct. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="A,B,D,C" name="AUTOGEN_{A,B,D,C}" score="0"><feedback><p id="f89d73d675d342ccb900269ec8740e24">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="A,C,B,D" name="AUTOGEN_{A,C,B,D}" score="0"><feedback><p id="e550965c178b469c9ced0f178711d66d">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="A,C,D,B" name="AUTOGEN_{A,C,D,B}" score="0"><feedback><p id="caf2d267ee924fa2bd8375d5eb97b153">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="A,D,B,C" name="AUTOGEN_{A,D,B,C}" score="0"><feedback><p id="e814607b7f0c4e8d8e6063afe00d745a">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="A,D,C,B" name="AUTOGEN_{A,D,C,B}" score="0"><feedback><p id="c0aa906a660b4457ada955f4fbf30015">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,A,C,D" name="AUTOGEN_{B,A,C,D}" score="0"><feedback><p id="b6cddae483274200894dceb250c91636">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,A,D,C" name="AUTOGEN_{B,A,D,C}" score="0"><feedback><p id="d392a852f30346cf8bf263dbf7f4b9cd">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,C,A,D" name="AUTOGEN_{B,C,A,D}" score="0"><feedback><p id="ce38ca02659941208481287500c51121">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,C,D,A" name="AUTOGEN_{B,C,D,A}" score="0"><feedback><p id="ec5fd175b43d4d279f5f2d7fec587d8a">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,D,A,C" name="AUTOGEN_{B,D,A,C}" score="0"><feedback><p id="b0ca0d4fcba34b44a0efa71ed683d622">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="B,D,C,A" name="AUTOGEN_{B,D,C,A}" score="0"><feedback><p id="ea6ee16dfa134d6aaecfe471c416bf4a">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,A,B,D" name="AUTOGEN_{C,A,B,D}" score="0"><feedback><p id="fb30f1c80b224c8abbd345134ce81ba3">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,A,D,B" name="AUTOGEN_{C,A,D,B}" score="0"><feedback><p id="ea4b2e2312fc4aa78cab580d12353fef">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,B,A,D" name="AUTOGEN_{C,B,A,D}" score="0"><feedback><p id="efae8ed0a09f4320be8e326bbb37a563">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,B,D,A" name="AUTOGEN_{C,B,D,A}" score="0"><feedback><p id="f06103c5bb5c469080af991c16b248eb">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,D,A,B" name="AUTOGEN_{C,D,A,B}" score="0"><feedback><p id="b93b133101d949a1aca5a6729010438c">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="C,D,B,A" name="AUTOGEN_{C,D,B,A}" score="0"><feedback><p id="ef1e5afbf1b84eca938f263b3ebac0b9">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,A,B,C" name="AUTOGEN_{D,A,B,C}" score="0"><feedback><p id="d5cbe5ba743d412e9a0ec966e0930362">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,A,C,B" name="AUTOGEN_{D,A,C,B}" score="0"><feedback><p id="abb5f91d0c634ef2904fe8389d1d4ea2">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,B,A,C" name="AUTOGEN_{D,B,A,C}" score="0"><feedback><p id="c0d53f0defc24a2e96ba4b712e49fcba">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,B,C,A" name="AUTOGEN_{D,B,C,A}" score="0"><feedback><p id="a36c4f5695554f4d8e9378c1b6ce5a92">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,C,A,B" name="AUTOGEN_{D,C,A,B}" score="0"><feedback><p id="ce7ae62eef61460b8d6e336812bd0f47">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response><response match="D,C,B,A" name="AUTOGEN_{D,C,B,A}" score="0"><feedback><p id="ebdf0933684c49ffbfe9435c80b2bd28">Incorrect. Option 1 is Sentiment Analysis, as we\xe2\x80\x99re trying to understand the general feelings of the various reviewers of the associated movie. Option 2 is machine translation, as we\xe2\x80\x99re looking to convert reviews in one language into another language. Option 3 is information extraction, as we\xe2\x80\x99re looking to extract specific information/features from text with a pre-specified goal of determining parts of the movie that viewers like the most. Lastly, Option 4 is Topic Modeling, as we\xe2\x80\x99re looking to separate reviews into classes while not necessarily knowing those classes a-priori.</p></feedback></response></part></ordering></page><page id="b559dac1d93d4242bb92956e9e1052e9"><multiple_choice id="da740e2fafd341b280c7a950b16db039" grading="automatic" select="single"><body><p id="c21ea7992ca6464da2c2d674b1d5ab11"> _____ focuses on the study of the formation of words &amp; analyzing their constituent parts.</p></body><input shuffle="true" id="da54ccb8e97941bb817de0c865d3306b" labels="false"><choice value="fcadd65bd77547ed848319386b754132">Morphology</choice><choice value="cf246b1c68e14a3ab402161ab0bfaebe">Semantic Analysis</choice><choice value="aa114ff4570a40f59073e7a11f3b6220">Pragmatics</choice><choice value="ae24d567643e4698914788a96eff2ab2">Syntactic Analysis</choice></input><part id="ce62688ad83e43ed857b7aec8f8c020c"><response match="fcadd65bd77547ed848319386b754132" score="10"><feedback><p id="a7d360df3f484244bb6f89fb03f21976">Correct. Morphology is the study of word structures, especially regarding morphemes, which are the smallest units of language. </p></feedback></response><response match="cf246b1c68e14a3ab402161ab0bfaebe" score="0"><feedback><p id="e5ffd68ec2324a5bada0dfcc8b2a21ec">Incorrect. The semantic analysis focuses on the literal meaning of text or sentences on the whole rather than the structure of individual words. Morphology, on the other hand, is the \xe2\x80\x9cstudy of word structures, especially regarding morphemes, which are the smallest units of language\xe2\x80\x9d and is the correct answer here.</p></feedback></response><response match="aa114ff4570a40f59073e7a11f3b6220" score="0"><feedback><p id="f205e7b3f57a4b94a246ee6e4dd745bc">Incorrect. Pragmatic analysis studies language that is not directly spoken and involves understanding implied hints that go beyond merely looking at constituent words. Morphology, on the other hand, is the \xe2\x80\x9cstudy of word structures, especially regarding morphemes, which are the smallest units of language\xe2\x80\x9d and is the correct answer here.</p></feedback></response><response match="ae24d567643e4698914788a96eff2ab2" score="0"><feedback><p id="bf04dffc48de4e4eb3d3adfaccfd9451">Incorrect. The syntactic analysis focuses on whether a sentence is grammatically correct and how such sentences are constructed and analyzed with respect to grammar. Morphology, on the other hand, is the \xe2\x80\x9cstudy of word structures, especially regarding morphemes, which are the smallest units of language\xe2\x80\x9d and is the correct answer here.</p></feedback></response></part></multiple_choice></page><page id="dd4fb69d12784fa2b9da2b25e812670b"><multiple_choice id="c2201f1880174856b2763d944af7b25e" grading="automatic" select="single"><body><p id="fb4aeac1a6984eceabb9eda3ac8bd445">Suppose that you build a spelling correction system that needs to correct the following sentence, which clearly has two words misspelled (one contextually).</p><quote> \xe2\x80\x9cThe schol principle talked with the students.\xe2\x80\x9d</quote><p id="f82a928017e6433688fe2fac2a572a37">Your corrector generates the following alternative sentences.</p><ul id="c8afbdde2b344fb795ed257e7529ce8f"><li><p id="e7a74b3aaa264e22af2313d1310f2946">The school principle talked with the students.</p></li><li><p id="c7f86f3560f6488aa77bf3dc6c370d6b">The school principal talked with the students.</p></li></ul><p id="c9caf69a8ded4f9db8286e0ae4c5e8c3">What tool or processing tasks would you rely on to pick one of these options?</p></body><input shuffle="true" id="e5ea495b45a246e2915cd25fa9a6b7b4" labels="false"><choice value="b7cb40f499404606ae2a878141e5fada">A morphological analyzer</choice><choice value="e6fc419981ad4b8cb3619241b46ae68f">A lemmatizer</choice><choice value="cdc0b3cc9666481eb5ba594516e75f03">A syntactic analyzer</choice><choice value="dfdad83f45bf4a498690b7a3e25adab0">A statistical language model</choice><choice value="f2f171c190a844a38f6cb5727f611aa4">A named entity analyzer</choice></input><part id="c30e994ae85c41c48aeb87f229996ba0"><response match="b7cb40f499404606ae2a878141e5fada" score="0"><feedback><p id="c963dbbb6c5d4622b7ac3b4d95514bff">Incorrect. Given that you have already generated a possible correct version, you need to choose the most \xe2\x80\x9cplausible\xe2\x80\x9d one. A statistical language model (4) would assign probabilities to the sentences, which can be interpreted as a measure of plausibility, and you can choose the option with the highest probability.</p></feedback></response><response match="e6fc419981ad4b8cb3619241b46ae68f" score="0"><feedback><p id="ddc2feb560e54077b6743508f77f9e05">Incorrect. Given that you have already generated a possible correct version, you need to choose the most \xe2\x80\x9cplausible\xe2\x80\x9d one. A statistical language model (4) would assign probabilities to the sentences, which can be interpreted as a measure of plausibility, and you can choose the option with the highest probability.</p></feedback></response><response match="cdc0b3cc9666481eb5ba594516e75f03" score="0"><feedback><p id="e5885e12f451404787934a3038d95ea1">Incorrect. Given that you have already generated a possible correct version, you need to choose the most \xe2\x80\x9cplausible\xe2\x80\x9d one. A statistical language model (4) would assign probabilities to the sentences, which can be interpreted as a measure of plausibility, and you can choose the option with the highest probability.</p></feedback></response><response match="dfdad83f45bf4a498690b7a3e25adab0" score="10"><feedback><p id="c0e4db2747154da59d8eb88111c4e10e">Correct. Given that you have already generated a possible correct version, you need to choose the most \xe2\x80\x9cplausible\xe2\x80\x9d one. A statistical language model (4) would assign probabilities to the sentences, which can be interpreted as a measure of plausibility, and you can choose the option with the highest probability.</p></feedback></response><response match="f2f171c190a844a38f6cb5727f611aa4" score="0"><feedback><p id="fd3b2078fb814b26b045e29e0e53e7e4">Incorrect. Given that you have already generated a possible correct version, you need to choose the most \xe2\x80\x9cplausible\xe2\x80\x9d one. A statistical language model (4) would assign probabilities to the sentences, which can be interpreted as a measure of plausibility, and you can choose the option with the highest probability.</p></feedback></response></part></multiple_choice></page><page id="c0d71c07531c47debeeb0efa809ecc9f"><ordering id="e312a7be6b9745dfb1cc10b825f47e24" grading="automatic"><body><p id="bcaa39a926064c6e8bdd55b343b5ae02">Identify which text preprocessing technique was used to arrive at the output in each case from the input text and select the option that has the right ordering for the text preprocessing technique.</p><quote>Input: Donna studies at Carnegie Mellon University.</quote><ul id="b07c88d804434e5cae48c144a00106ba"><li><p id="d2bfd5baa2994b43939315129f85c000">Output: </p><p id="c00e5051080e49d781a60b0a5909b60a">{\xe2\x80\x9cDonna\xe2\x80\x9d:\xe2\x80\x9dPER\xe2\x80\x9d, \xe2\x80\x9cCarnegie Mellon University\xe2\x80\x9d:\xe2\x80\x9dORG\xe2\x80\x9d}</p></li><li><p id="ab470b08cd3849169ac5ba2e86ca6c89">Output:</p><p id="d308eb494a4a461296a315796fe0d6c5"> { \xe2\x80\x9cDonna\xe2\x80\x9d : \xe2\x80\x9dNOUN\xe2\x80\x9d, \xe2\x80\x9cstudies\xe2\x80\x9d : \xe2\x80\x9dVERB\xe2\x80\x9d, \xe2\x80\x9cat\xe2\x80\x9d: \xe2\x80\x9cADP\xe2\x80\x9d, \xe2\x80\x9cCarnegie\xe2\x80\x9d: \xe2\x80\x9cPROPN\xe2\x80\x9d, \xe2\x80\x9cMellon\xe2\x80\x9d: \xe2\x80\x9cPROPN\xe2\x80\x9d, \xe2\x80\x9cUniversity\xe2\x80\x9d:\xe2\x80\x9dPROPN\xe2\x80\x9d } </p></li><li><p id="fb4b4e41a2e0465a924933bdfd0b7170">Output:</p><p id="e9ee0e9b10604f48a794f35e0ad8312c">[\xe2\x80\x9cDonna\xe2\x80\x9d, \xe2\x80\x9dstudi\xe2\x80\x9d, \xe2\x80\x9dat\xe2\x80\x9d, \xe2\x80\x9cCarnegie\xe2\x80\x9d, \xe2\x80\x9cMellon\xe2\x80\x9d, \xe2\x80\x9cUniversity\xe2\x80\x9d]</p></li><li><p id="fd2166af993c421482dcde20fdce7b1a">Output:</p><p id="ed89ae0860254bd08b884aac05d5d2ea">[\xe2\x80\x9cDonna\xe2\x80\x9d, \xe2\x80\x9cstudy\xe2\x80\x9d, \xe2\x80\x9cat\xe2\x80\x9d, \xe2\x80\x9cCarnegie\xe2\x80\x9d, \xe2\x80\x9cMellon\xe2\x80\x9d, \xe2\x80\x9cUniversity\xe2\x80\x9d]</p></li></ul></body><input shuffle="true" id="ad5b7695e0e44e84b9c9e31c08dbc52b"><choice value="A">Parts of Speech Tagging</choice><choice value="B">Named Entity Recognition</choice><choice value="C">Stemming</choice><choice value="D">Lemmatization</choice></input><part id="fad2f038e54449bc9519c92698013a20"><response match="B,A,C,D" score="10"><feedback><p id="a76bbc53d2954ff2b2b0197637c62b99">Correct. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="e337d20819984129989d09018e8cdea4">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,B,D,C" name="AUTOGEN_{A,B,D,C}" score="0"><feedback><p id="adbb353e21fc4061ab05d4232534a67a">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,C,B,D" name="AUTOGEN_{A,C,B,D}" score="0"><feedback><p id="a1dc5f69c2ea464aaf75b9cb77e278ef">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,C,D,B" name="AUTOGEN_{A,C,D,B}" score="0"><feedback><p id="eb7bfa4bce4a46ad98c8b73dd5cd6d1a">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,D,B,C" name="AUTOGEN_{A,D,B,C}" score="0"><feedback><p id="c5a2d29939cc469494c5d38334f49d8e">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="A,D,C,B" name="AUTOGEN_{A,D,C,B}" score="0"><feedback><p id="ff5a2ad18f5641cdb203bdcd5f39f60f">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="B,A,D,C" name="AUTOGEN_{B,A,D,C}" score="0"><feedback><p id="fb3dbe0e68884b619633e06e85eba41c">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="B,C,A,D" name="AUTOGEN_{B,C,A,D}" score="0"><feedback><p id="c06679edeb0f43b7bdee96c2e83ce09f">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="B,C,D,A" name="AUTOGEN_{B,C,D,A}" score="0"><feedback><p id="dd8e9358bae0436cb7691302946b3b5a">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="B,D,A,C" name="AUTOGEN_{B,D,A,C}" score="0"><feedback><p id="cf1218d492d841088075ff3a7e5ceb3e">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="B,D,C,A" name="AUTOGEN_{B,D,C,A}" score="0"><feedback><p id="acb1e7814a8f4646942194d4c191f5d2">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,A,B,D" name="AUTOGEN_{C,A,B,D}" score="0"><feedback><p id="e221577eef39496899359e897ed824e4">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,A,D,B" name="AUTOGEN_{C,A,D,B}" score="0"><feedback><p id="ada25444c24c40da8272f0e2bd6e7480">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,B,A,D" name="AUTOGEN_{C,B,A,D}" score="0"><feedback><p id="d901df8e7bef46cbbde5e8470a01bcb0">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,B,D,A" name="AUTOGEN_{C,B,D,A}" score="0"><feedback><p id="fc061ea056164fe3b6fc90f667e852a0">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,D,A,B" name="AUTOGEN_{C,D,A,B}" score="0"><feedback><p id="e42d0dba4d25414dbaef995cc5d70c30">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="C,D,B,A" name="AUTOGEN_{C,D,B,A}" score="0"><feedback><p id="a087dbef0d0d48c7b55c7d3ae07ed872">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,A,B,C" name="AUTOGEN_{D,A,B,C}" score="0"><feedback><p id="e056050038d04951bac609f9a184525e">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,A,C,B" name="AUTOGEN_{D,A,C,B}" score="0"><feedback><p id="e7e1105e1b694ff790718e884e25b377">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,B,A,C" name="AUTOGEN_{D,B,A,C}" score="0"><feedback><p id="eb317380fb754ad8a088a7667c7fbd8a">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,B,C,A" name="AUTOGEN_{D,B,C,A}" score="0"><feedback><p id="cfdb54607dba44c28b10f44d9bab277e">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,C,A,B" name="AUTOGEN_{D,C,A,B}" score="0"><feedback><p id="b60082f39c6c4ed3aff719111ec41e56">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response><response match="D,C,B,A" name="AUTOGEN_{D,C,B,A}" score="0"><feedback><p id="fc85af9837e54a809bc99ae07904938e">Incorrect. Output 1 refers to Named Entity Recognition, as we extract the named terms in the sentence, such as CMU, and figure out what they are (in the case of CMU, \xe2\x80\x9cORG\xe2\x80\x9d refers to the organization). Output 2 refers to Part of Speech Tagging, as each word is extracted from the text and matched with the appropriate part of the speech tag (NOUN for nouns, ADV for adverbs, and so on. You\xe2\x80\x99ll get more experience with this later on). Output 3 refers to Stemming, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d whose end (i.e., \xe2\x80\x9ces\xe2\x80\x9d) is chopped off to get \xe2\x80\x9cstudi.\xe2\x80\x9d This should not be confused with lemmatization as that is a more sophisticated form of arriving at a base word that would process \xe2\x80\x9cstudies\xe2\x80\x9d to \xe2\x80\x9cstudy.\xe2\x80\x9d Output 4 refers to Lemmatization, as we\xe2\x80\x99re specifically modifying certain tokenized words, like \xe2\x80\x9cstudies,\xe2\x80\x9d to their more base counterparts, i.e., \xe2\x80\x9cstudy.\xe2\x80\x9d</p></feedback></response></part></ordering></page><page id="c6a2425754974ef6ace1962db99c7084"><multiple_choice id="bcac438efec649c691c8068d10204796" grading="automatic" select="single"><body><p id="a7d2dcb1102c441f8bdeb167f6fbd562">Daenerys Targaryen wants to advance the state-of-the-art in NLP for a new language, Dothraki. She learns that new words in Dothraki are formed by combining smaller meaningful words. Given this information, which of the following language analysis techniques would be most useful in analyzing Dothrak language texts?</p></body><input shuffle="true" id="eb33e1872e4745cb924a66b00200e610" labels="false"><choice value="bf23c07af3024d6c85e692fc8677c011">Semantic Analysis</choice><choice value="a31a7feb71104e05b1480be8d1cd4db6">Pragmatics and Discourse Analysis</choice><choice value="c5cbec0ea9f94e46b7769f6c959ba3ed">Syntax Analysis</choice><choice value="c965202e0fdf45a19c6ceeaad69ddc8d">Morphological Analysis</choice><choice value="bba09c511f8c46d4b22c2f540a2cd1f9">Phonological Analysis</choice></input><part id="c1f5156322d547f89416372dcca4e48c"><response match="bf23c07af3024d6c85e692fc8677c011" score="0"><feedback><p id="e697f44231114203a1cd466542216062">Incorrect. Semantic analysis is the field of linguistics focused on understanding the meaning of words, but morphological analysis focuses on the individual words themselves. As Dothraki is focused on the combination of individual words from smaller words, it makes sense to use that technique instead.</p></feedback></response><response match="a31a7feb71104e05b1480be8d1cd4db6" score="0"><feedback><p id="b0c808796220437b9aca11e939456fdd">Incorrect. While it might be useful to look at the words in context, it\xe2\x80\x99s not a given that Daenerys has dialogues to allow them to perform such analysis. Morphological analysis, on the other hand, focuses on the individual words themselves. As Dothraki is focused on the combination of individual words from smaller words, it makes sense to use that technique instead.</p></feedback></response><response match="c5cbec0ea9f94e46b7769f6c959ba3ed" score="0"><feedback><p id="bceac81aa8b54d36871e35f70a7d1abb">Incorrect. Syntax analysis focuses on grammar and on how words fit together. As we\xe2\x80\x99re looking at individual words instead, syntax analysis is not the best way to handle this accordingly. Morphological analysis, on the other hand, focuses on the individual words themselves. As Dothraki is focused on the combination of individual words from smaller words, it makes sense to use that technique instead.</p></feedback></response><response match="c965202e0fdf45a19c6ceeaad69ddc8d" score="10"><feedback><p id="d74ec3b97e2f4d37bc5fc3a8482b14f4">Correct.</p></feedback></response><response match="bba09c511f8c46d4b22c2f540a2cd1f9" score="0"><feedback><p id="cdb4fd1b707b4b078b2210a6b4f1a231">Incorrect. We\xe2\x80\x99re more focused on the meaning of individual words rather than how they sound. Morphological analysis, on the other hand, focuses on the individual words themselves. As Dothraki is focused on the combination of individual words from smaller words, it makes sense to use that technique instead.</p></feedback></response></part></multiple_choice></page><page id="a6525672abe740c88ea1901c71468c82"><multiple_choice id="bc6961750b8740328d841fb0088bf4c8" grading="automatic" select="single"><body><p id="c930768821ea4130bc455cf39cbc3d2d">What is the role of tokenization in the natural language processing pipeline?</p></body><input shuffle="true" id="ada6f8950d444ca095b104a6c27219a2" labels="false"><choice value="b615196a33734092bf62b2727484b5f8">It turns input text data into numerical features which can be used for subsequent data processing and modeling.</choice><choice value="d4d816a8e3634241a4e75d14eb2dc28b">It leads to a more efficient representation of text data.</choice><choice value="c87182bac3974e2ab3ed55a98a42eb2a">It removes commonly used terms but does not carry useful information.</choice><choice value="a617f6245a2a4f519f023c0b16c1811a">It allows for the analysis of individual smaller units in the text data.</choice><choice value="e9ad238853834767a1e87285e46c4662">It helps detect whether each smaller unit of the text is a noun, verb, adjective, adverb, or another type.</choice></input><part id="bf54b3f434c1481b9d7d8d0ffc7d93b2"><response match="b615196a33734092bf62b2727484b5f8" score="0"><feedback><p id="bd42e88fedc7462bb8929d97f81953eb">Incorrect. Tokenization is not a feature engineering step.</p></feedback></response><response match="d4d816a8e3634241a4e75d14eb2dc28b" score="0"><feedback><p id="cc14a3bff8cf4bc38daa047365a4fc69">Incorrect. Tokenization converts an input string into a list of individual tokens, which is not a more efficient representation.</p></feedback></response><response match="c87182bac3974e2ab3ed55a98a42eb2a" score="0"><feedback><p id="be0d1a5bb2b74f869c44f10d6652523b">Incorrect. This task is stopword removal, not tokenization.</p></feedback></response><response match="a617f6245a2a4f519f023c0b16c1811a" score="10"><feedback><p id="b428c035d2d5497fbbd791f58714bb84">Correct.</p></feedback></response><response match="e9ad238853834767a1e87285e46c4662" score="0"><feedback><p id="fc2c7910f9c1461ba6d209eefff5dbb4">Incorrect. This task is part-of-speech tagging, not tokenization.</p></feedback></response></part></multiple_choice></page><page id="c078c96cbd7642bd9e7126fb1d02eb5c"><multiple_choice id="c1ad4f59722b44d6b5ef6734808953ea" grading="automatic" select="multiple"><body><p id="c19f5ff8a57c4fd6ab8383fde6f859dc">Select all tasks that require other applications besides NLP.</p></body><input shuffle="true" id="da92eee9ca33407ab3472b76615b3dea" labels="false"><choice value="A">Identifying if the sentiment of a collection of tweets is positive or negative.</choice><choice value="B">Detecting grammatical errors in an essay submitted via taking a photo.</choice><choice value="C">An autonomous vehicle reads the texts on the traffic sign.</choice><choice value="D">Turnitin detects plagiarism by scanning students\xe2\x80\x99 text submissions via Google Docs or Microsoft Word.</choice><choice value="E">Translating Phasa Thai (Thai Language) to English.</choice></input><part id="f4d51df4b49d46fb9f5d17be09c9fb32"><response match="B,C" score="10"><feedback><p id="fffb2c1d81454b32968305a243333fd4">Correct. </p><p id="bb5971a5ac094daa89be1b76630737c1">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="be6be428328040769da0a4ea20bf3990">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="ba808a097541462f8e4f7c733b957a57">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="f5fc43702157413ea02ae49fbab1f3a4">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="d57c5d53dceb4bf2b6ca159b5840fe91">Translating one language to another only requires NLP.</p></feedback></response><response match="B" score="5"><feedback><p id="a911f6b430a84731ae6006cad0857234">Partially correct. </p><p id="aaccadc614874edab02df39812c81347">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="df2cb234286447558625b490870634b7">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="ffd0088ca84e4e3b96c50b0b7b0efcbe">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="a1b66963046e4dbab783f46132d513df">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="d63e33f96b844ff6abefc73fc97214d8">Translating one language to another only requires NLP.</p></feedback></response><response match="C" score="5"><feedback><p id="eb2e5b7cf25546dcade0849680ec402f">Partially correct. </p><p id="dcf052a04bae44e595cc928679dae44b">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="bd480f0862fd41509d8bcec451ab4968">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="c9ad826006db472ca9a1b3e967172f8b">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="b52295273cd84f878267da3e9033b000">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e7dc0214f6304007b6e12d9687203dd8">Translating one language to another only requires NLP.</p></feedback></response><response match="A" name="AUTOGEN_{A}" score="0"><feedback><p id="f3a361cbd8f14a21892e05ff9f2c12aa">Incorrect. </p><p id="ecba5c05d5a34eadb4b122e1f2aaf255">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="e0ee8934f8e442dea2d13e236c71305d">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="a05587908f734e459f6f32158b740163">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="c0d0fdfecce54289b44143024322ba9f">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="beb04139b6ad4bf7bb626c366c3045be">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B" name="AUTOGEN_{A,B}" score="0"><feedback><p id="e8a6c794f45c4622aaaf700c4a7a2e5a">Incorrect. </p><p id="c982427b59f442a7809f90e1362b8f96">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c57bc49a40594c74a8d72072c6e4b8f4">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="cead2c2188ba49d2bcc00988135f1158">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="bd1b9db1b3ba455699d101c80aa3de84">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="ab69bda574644ca8a14887f32915ac31">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="f605ad57b34d4ef296d2b18250dd2bb9">Incorrect. </p><p id="ad3370e650ef4f06af7bcd21cea3657b">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="fc3aff33175843fface85d99e345cc7e">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="b0e9599200e44f2b9be9843abe9f60ea">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="e9b2a1d52bdc43d19a1cc85314732c94">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="f4bb3271e7a54ff9b0cfec7fdd275097">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="ff6c2fd5982944ce934540aca466a6ea">Incorrect. </p><p id="f4f5ed5c64614749a5ac6fd3fe3127d4">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c37c9b20d3394f67aa98550805024d95">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="cca3c41a34f4471892e0c8269d5134ed">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="cab9f5209b6e4560b970eb0e451c4cbf">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="ad531f6e33bd42aca235bca1ff17d74f">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="f0ec9106af364a46872306f46849e893">Incorrect. </p><p id="f6b10b40ffb44f9c80d9bd0fc592c2c8">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c6cbd5e175104b93989a17428c665c9e">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="f50e97a84fa042beb7a69b65266e44a1">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="eb608e71eebe4512a0bb03815c4d545a">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="c30699f0716e49459ffa2f347a08afb1">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="a3738c0df02341a6bcedde6a463fea0a">Incorrect. </p><p id="b4869da81b634bffbd2ef7bae5837a05">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="b81b67b601c446258fbf13c57334f344">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="e48b0ac86883439eb21e3e574b2da70a">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="f52b51a75cb547fb8e21593bb54366d9">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e6b685b230ed4b6b99ebf90a7919d90a">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="b8fed12c4897417e985d66d9f750bb98">Incorrect. </p><p id="ecb850f6ca7647bba2af2413b5ff11ec">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="cd79650179244bb4abfca8e97b183239">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="ff7f45496afb45cf8fab132037ed52da">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="ae46d57a08a44db081590b04fcab22ab">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e68138c0b87447478b22d80031f74131">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="d24f751a4b2b4d2aa46cd2d2ecf14a4f">Incorrect. </p><p id="d6dbe35c89e747988f5a3340b6dc3a4a">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="f6d60d272a794c248a1a3e0433db4fee">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="cb8f2635cd9d4f3ea51beaa1c48abeae">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="c256810c1091432ca229765c9492b4f3">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e42d0399e52047bc8146b82b25274a19">Translating one language to another only requires NLP.</p></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="d0ebc53b64c445b099c29afd4843643a">Incorrect. </p><p id="d2f01c2b5ed64670a87354113af7579b">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="f078fcfd3c4d4cac807aad6da0caa4fc">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="ffba767c7e144827bb6f67045539a96c">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="e2b44f9d1df74f6bb580887c7ffa3905">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="d9531b4d64dd4ecc9a3efb3374e8c7ef">Translating one language to another only requires NLP.</p></feedback></response><response match="A,C" name="AUTOGEN_{A,C}" score="0"><feedback><p id="e1a829dff89a4c2194753283bd1a0c58">Incorrect. </p><p id="be0c53166b4c4ae6a8b124055f6e472b">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c6837cfea1ae4c618436175fef1fb776">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="e4177f99a7844837908c847912d89db3">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="af1239a0f8544b779a4231951fc2bf44">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e3a4c2dc0cf2475abd2a2f2ba7c81b72">Translating one language to another only requires NLP.</p></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="bdb7806251924c9a85b03b421b7c8bd5">Incorrect. </p><p id="d0238a8b36104cfca4c47a3c4b18ef80">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="fec3fd9a73cc44818b10d1bfb824a76d">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="dba7212338f84f09b63d062da7f3d90d">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d56aaefa74f646b99c93ff112cf81365">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="b2bc3065526c4626adaa999dd3cc4c37">Translating one language to another only requires NLP.</p></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="d88c16f73ae244a4aeb69b3acd34155a">Incorrect. </p><p id="fc7a625375e24adfa55ba23896993532">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="ee70ede0374341ffb884c0360e420397">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="e8f5c15742564c79905c000ceabb68df">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d2a19287c76f46ffaede92fd7883884b">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="faedbc350931475b822e68c63e4b7f52">Translating one language to another only requires NLP.</p></feedback></response><response match="A,C,E" name="AUTOGEN_{A,C,E}" score="0"><feedback><p id="a27c6184bae64d0ba0c4f08b150e73f9">Incorrect. </p><p id="ca75f441174a4eb4b7c954ff42c928cd">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="ee8d01733a954995aac17110d88d8899">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="a78b92ffcc084142933e467e3e233122">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="dffd56ed76e54fbf8ff7d014013c4e5c">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="acdbe9abc4bb4a509bb1c666bab86f9f">Translating one language to another only requires NLP.</p></feedback></response><response match="A,D" name="AUTOGEN_{A,D}" score="0"><feedback><p id="ff8cd04810854fe7baf54176f1f3c61c">Incorrect. </p><p id="c16aa32cd01e4866860dae6ab7b0b30e">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="af8763becaa24fa5a696726c255cd583">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="b3d65797e8ce45ba8476678221172779">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d2243efa27cb4f20afacfc7971c9b137">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="f005ebc108b944b1a2997638a6047bfb">Translating one language to another only requires NLP.</p></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="b068c2f51ca344cc84cfc3789a84128a">Incorrect. </p><p id="e99a24ffd0544f8fabd4a2f58d93feba">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c712388b182e43ad82de89f874debc04">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="fa7f52f152ca42f79bffaa2ffe661fde">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d30e2a5c806841eb806670d63798a5df">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="f1507a2df7ac4a8f9159aa8e6076535b">Translating one language to another only requires NLP.</p></feedback></response><response match="A,E" name="AUTOGEN_{A,E}" score="0"><feedback><p id="ea794cd352684253a011e74f31a1fbce">Incorrect. </p><p id="e38e9cdfe1f44dc79f25577691d9c403">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="fbf70f34d8284ac1a7b5a70059d4b581">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="b0ea3101d5b54a2299eac4f6e592f8e9">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="e27d21c2c8664e06acc9f228efb04962">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="c6489a7c0e3144dbbac6e2fc47ff9744">Translating one language to another only requires NLP.</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="c08d52a8fb674ad8bf2bf35353df309a">Incorrect. </p><p id="f5cb5f50a8bf453d90a9267c59ffa187">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="e7644caae4284a3380895612bfa11a6d">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="a0e3d77d0d4140518a98fea3a776f698">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="fc62e98770424fe5aebd88924565d755">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="e70c2f224a41413f89fd8ec349726113">Translating one language to another only requires NLP.</p></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="c9b59a3086b44c4399c74717c6bc212d">Incorrect. </p><p id="c68566eb8f4142a6b6c9665c92359768">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c6ae6a62da59479c8bcff2b6967db421">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="b687b6e83f2b452e9be727aace252590">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="bd2288e93c374460a334902941001079">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="c575806c69bc4d1bbadab5c7fb1051cb">Translating one language to another only requires NLP.</p></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="c1d3023e7376406ea517bcef5732fd10">Incorrect. </p><p id="c95d023f73f74c6c95bf72e02a8b4211">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="a62c458a1e7a4597a4a36f8d33fec09b">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="b23f0c9a0cf3467da816db5eb24ddbfd">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="b504380264f14036b4ee922e0b3fd2e8">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="f769339f497f427494aafb4610b7cf59">Translating one language to another only requires NLP.</p></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="d48fd40a3ba44227a5e48b7f2c36df4a">Incorrect. </p><p id="dd639b3ad44d4a8189b9b5060f45dff4">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="dee2f3326e854ceea9e18841211088c9">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="fd92594ede3c475199f846f2336d9c38">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="f1f09f9af302472d9867c81c86872196">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="efc050a1d84740b280ed60c2967ec5fd">Translating one language to another only requires NLP.</p></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="b093638e9ae344bf9d0caada8443b6c2">Incorrect. </p><p id="b921f195c0404e3d86e87949c45e8db6">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="c92f6b94a3ce4d0bb7ea2693e6250a7a">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="f23b2d0084f94052ac523a7d6e5e64a8">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="f6826837b8964275860e4356a68bc782">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="dd33e1c56a7141e48baca4a5721ddf2c">Translating one language to another only requires NLP.</p></feedback></response><response match="B,E" name="AUTOGEN_{B,E}" score="0"><feedback><p id="a991b6722479407ca67e70dbf6b4bdaa">Incorrect. </p><p id="ff38dcdd9efc4b98bf5bf6c4b2cf3a44">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="fe508f2e3ecd4807a0e841fb966066e8">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="febb92c72c37447fb6cc3ced32a22f94">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="e3593e11a5b4491dbcacd353b3b2d381">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="f5396c9067644016888450bde0a66198">Translating one language to another only requires NLP.</p></feedback></response><response match="C,D" name="AUTOGEN_{C,D}" score="0"><feedback><p id="e191be8c91e94c519f9614b6987b6512">Incorrect. </p><p id="c3fb989be5ed4a7782b9cc15fcf263a6">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="cbb0dbcd033043f4859775b0d926348a">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="a7145062e1d6452f8f98f98752fecc3f">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d7e3fd9cfcb24670861eba406650bf43">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="c7e14238b95a4c41b1ab99e60d053c56">Translating one language to another only requires NLP.</p></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="ec3ef48f5f5f43d788765bd348b72e55">Incorrect. </p><p id="eade05c44b4f4e34893e9591db0238bd">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="ccca4d26cf704f058ff0eabd1b00c8aa">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="cf3f1c23a5bf47b19f54cf45586dfe3c">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="c8eabc331b9240ad8ec4627e8ebd38ab">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="a5d7f90416174d398887d3b6bf92c869">Translating one language to another only requires NLP.</p></feedback></response><response match="C,E" name="AUTOGEN_{C,E}" score="0"><feedback><p id="fc24d0db3c8a4d988e8c5cd76a937b89">Incorrect. </p><p id="f75a23838cc34cf5a5f8a7c3cc3af09a">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="e53bdd4babed4d62b1cbb491b7c3d236">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="f28658cf60ff430faec4252b42298e08">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="d06d90275166424a8330f37315b33ed2">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="bf0cff7ff28d47e9bc61c2cacd5b38c2">Translating one language to another only requires NLP.</p></feedback></response><response match="D" name="AUTOGEN_{D}" score="0"><feedback><p id="b138aa768cd54992b8119fc2fc37b510">Incorrect. </p><p id="a7a349d932344376926d6629ad1d88fc">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="f1bef118ca7040ec87a79108e74cad91">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="d265dd8982df486faf0c4c61b2d164ab">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="fb2c183efc204d6f87c752f50a844b03">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="b17001de45a74540b9403e3100e5ba61">Translating one language to another only requires NLP.</p></feedback></response><response match="D,E" name="AUTOGEN_{D,E}" score="0"><feedback><p id="beb134b852374e629ec4630f94120b2e">Incorrect. </p><p id="b8a1438ae83448e689866950fb5dd638">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="f84bea5bbd6a494f8edee835120ba7a4">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="f2ac32bd14f84d89933fffdf352eedd9">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="b701f38f19584f5da9c12538fc0c6af7">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="a3439459a36e4481ab580cdafb1583c8">Translating one language to another only requires NLP.</p></feedback></response><response match="E" name="AUTOGEN_{E}" score="0"><feedback><p id="bb75bf0dab42426dbe6265c001782416">Incorrect. </p><p id="d4f03f706eab45d99286c2a94757013e">Recognizing emotion or sentiment in a collection of tweets only requires NLP.</p><p id="e2114ae3451f45d7b75e0412d7fd55f7">Detecting grammatical errors in an essay submitted via taking a photo requires computer vision applications to detect texts in that photo first before proceeding to an NLP application.</p><p id="fe9bb567e6b440f187d1ceba5f87491e">Reading the texts on the traffic sign requires computer vision applications to detect the texts first before proceeding to an NLP application.</p><p id="e32c9d9fb52942acb52aadac78969154">Since Google Docs and Microsoft Word submissions are in text form, detecting plagiarism from such texts only requires NLP applications.</p><p id="cb5c7e92a221410f97adcb7fa65fd745">Translating one language to another only requires NLP.</p></feedback></response></part></multiple_choice></page></assessment>\n'