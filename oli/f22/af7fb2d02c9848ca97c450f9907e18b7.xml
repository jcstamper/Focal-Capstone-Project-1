b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="af7fb2d02c9848ca97c450f9907e18b7"><head><title>Practical Data Science Optimization</title></head><body><p id="ecd5da8bba8d4f1db021b73e7ebd53b6">Throughout the course of this module, you have learned a lot about the underlying hardware that makes or breaks data science operations. While choosing underlying hardware goes a long way to ensuring that your system works within the budgets you allocated for yourself, you should also be prepared also to optimize your code accordingly. Given that times for jobs can range from overnight to multiple days, even a meager 10% speedup can provide more time to tune your model and extract bigger insights into your problem.</p><p id="db9203d3b414490ba20ad197feb860ab">Even if you have experience optimizing C or C++ code, data science code can be much trickier to optimize. To better understand why, let\xe2\x80\x99s consider a couple of notable factors at play.</p><section id="ddea827cefeb4c17aa186287b03ec06a"><title>Interpreted Languages</title><body><p id="d84aa7ea6f0647d0be65d0253285e845" /></body></section><p id="a2fc77c519fd4d92b77786b379cab6bf">Most languages in which data science is done are <em>interpreted</em> rather than <em>compiled</em>. When you interpret code, you do not have the same ability to statically optimize the code as a compiled language. As a result, some of the automatic optimizations you might expect to happen will not, and this will result in slowdowns compared to C++.</p><section id="f87fae5231644ae8abed504309feb3ec"><title>Usage of Matrix-Manipulation as a Primitive</title><body><p id="c980aec1826541cda77e1acdc89bb279" /></body></section><p id="f5ac9af5a9c349a5a3ab497a71f933a0">For most data science stacks, you will need to use matrix-manipulation libraries instead of implementing every bit of an algorithm from scratch. These libraries provide fast implementations of specific operations in a pre-compiled binary, ensuring that the actual code is much faster than what is possible in the interpreted language as is.</p><section id="c9e55b845ed549c9bfa0ac7b5d9b3316"><title>Large-Software Stack</title><body><p id="da43553842b0465e94a8d07ffd65a915" /></body></section><p id="f95ba26588444d6384b77cd2a806072c">Sometimes, the code you are looking at will have layers upon layers of code underneath it that could be the source of your performance issues. Even simple data science projects will have libraries for linear algebra operations linked in, along with the tree of libraries your project requires. This added complexity can make it difficult to understand where the potential problems are and make the relationship between code and performance harder to reason with.</p><p id="c2ee5efb4f574fc78c375ca25da75541">Despite these factors, however, there are principles that can be followed to improve performance actively. These are not going to be surefire ways to optimize code, but tend to lead to better performance more often than not.</p><section id="d703edda4c024853b9708876d16868f7"><title>Vectorization</title><body><p id="cd4c9707416a43a2a1453ebf6e645f16" /></body></section><p id="e4ebc193843a44868c8781a403ad8d63">Many data science operations require the use of some matrix or data-frame manipulation library. <em>Vectorization</em> is the process of writing your code in the language of that library. This involves reducing the number of imperative programming constructs you use, from if-statements to for-loops, and increasing the number of functional programming constructs you use, such as reduce and map functions. The general goal of this step is to specify what you want the library to do rather than how you want the library to do it, as the libraries you work with can then optimize the performance accordingly.</p><p id="e572c3369d6f4cc19d4c04fc4ad2a191">In particular, your goal should be to do at least the following:</p><ol id="b84c29768ed64528b68abbb6cfaec284"><li><p id="b0a3b4520180438eb9cc409a57f285c6"><em>Remove for-loops and replace them with maps:</em> For-loops in interpreted code are much slower than for-loops in pre-compiled code. If you can replace a for-loop with a map function or a function without any side-effects that take in each element of the matrix as input, applies some operation without any side-effect, and returns that element, then your code will speed up accordingly.</p></li><li><p id="b7b293e24f3d46ffa1e99ef8cf351ab3"><em>Use conditional indexing instead of if-statements:</em> Like the above tip, moving branching code from your interpreted environment to the pre-compiled environment will generally be faster. If you are able to make some function that associates some element of a matrix with a Boolean without side effects, using conditional indexing to express what you want makes it easier for the library to perform its job for you.</p></li></ol><p id="b6c07bb67b1a454bb9c4bc6f0e3a5d6c">You could also look at trying things like <em>stride manipulation</em> or <em>pivoting,</em> but the main goal of vectorization is to utilize the resources involved as effectively as possible. The more effectively you can use the library you have access to, the faster you will be able to make your code.</p><section id="afe2b89d7f604ec1b2848a93dcd3e2f2"><title>Multiprocessing or Multithreading</title><body><p id="faedf4d2a0414cc49356c7e3a70e3c23" /></body></section><p id="f2b32a33c63749229ce8fd47870fe633">If your operation deals with processing large amounts of data, it might pay to make your code friendly to multiprocessing or multithreading libraries. Here, you will create either separate copies of your program, called processes, or separate execution environments which share data, called threads. In doing so, you can likely parallelize disk operations that might be the main bottleneck of your program.</p><p id="e2f12d9d33524f759703332b08becaa4">Alternatively, you could also try switching your programming model to use something like <em>Spark</em> or <em>Hadoop Map-Reduce</em>. These tools utilize the \xe2\x80\x9cMap-Reduce\xe2\x80\x9d framework for computation. In essence, you deconstruct the pipeline you wish to parallelize into separate phases, consisting of the following phases:</p><ol id="b343fef4d0814f73b54eca120f80d4a1"><li><p id="c37d300f98a841f095bbf68c9d78c671"><em>Mapping:</em> Here, you separately process each line of a data file, and apply some operation to turn it into a <em>key, value pair</em>.</p></li><li><p id="ebad4e0493eb4312abe4639b0f249a3b"><em>Reducing:</em> Here, you take all of the data for a given key, and process the values together, producing some output to then map again.</p></li></ol><p id="bba99f12ef5c4268a19863d2dc748278">While it can be challenging to construct the pipeline in this manner, it is necessary to learn how to rephrase the calculations you want to go into these varying programming frameworks, and it is part of your job. If you take courses on cloud computing or ML on Large Datasets, later on, you\xe2\x80\x99ll be exposed to these tools and be forced to grapple with these concepts in more detail than we have time here to cover.</p><p id="cd815873221f4eb7abb78d23fbd716c5">These frameworks can automatically parallelize the job with those functions given, allowing you to process more data faster.</p><section id="b1588040b126495680d44af568ba1c40"><title>Delegating to a Compiled Language</title><body><p id="bbb079fdd17d49e8a80f850b0b4e3842" /></body></section><p id="ab4a83e6a5dc404f80f099a464894b79">If the above steps are not enough, you could write sections of your code in a compiled language and then create functions that use that code in your interpreted language. While this is generally not advised unless you know the code is the main bottleneck, it can provide large speedups at the cost of technical complexity.</p><wb:inline idref="mooclet_activity" purpose="didigetthis" /></body></workbook_page>\n'