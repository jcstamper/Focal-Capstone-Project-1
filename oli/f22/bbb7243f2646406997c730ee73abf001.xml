b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="bbb7243f2646406997c730ee73abf001"><head><title>Validity and Bias</title></head><body><p id="d6b9e8d9013e463e97f8986fc9d95245">It is critical in <em>any</em> research to have a clear and unambiguous definition of the <em style="italic">population of interest</em>. That is, it pays to be explicit, rather than vague, about the nature of the population we are interested in studying. Doing so will ensure proper inference or conclusions about the data we study. Regardless of the study design, any analysis would suffer from potential incorrectnesses derived from any part of the data science lifecycle.</p><p id="b4f5e8dbd51b4f63b5c7d57aeb7157fd" /><p id="dc6bdb99a9404a9b9a46c3f1a643e4ee"><em style="italic">Validity</em> is the development of sound evidence to demonstrate that the intended test interpretation (of the concept or construct that the test is assumed to measure) matches the proposed purpose of the test. This evidence is based on test content, response processes, internal structure, relations to other variables, and the consequences of testing. </p><p id="ac1c93de6f2048328495ad1ece5e1858" /><p id="f44152fb9f1b44d38890a7f174c351e8"><em style="italic">Threats to validity</em> refer to specific reasons for why we can be wrong when we make an inference in <em>an experiment</em> because of covariance, causation constructs, or whether the causal relationship holds over variations in persons, setting, treatments, and outcomes. In<em> an observational study</em>, the threat to validity concerns whether the observed changes can be attributed to the exposure or intervention and not to other causes and whether we can generalize that exposure more universally causes the outcomes.</p><p id="d2232908a03149a395ae39aa6f5ca867" /><p id="d2621791b2814be09fbf81327e319128">There are four types of validity:</p><ol id="aa12d3ed791a4206ae1c876b70971aee"><li><p id="de53ae3c7e1d476fa86929532167a342">Statistical conclusion validity refers to the appropriate use of statistics (e.g., violating statistical assumptions, restricted range on a variable, low power) to infer whether the presumed independent and dependent variables covary in the experiment.</p></li><li><p id="d86547f4928f453ea6dd270260a60812">Construct validity means the validity of inferences about the constructs (or variables) in the study.</p></li><li><p id="de103fe0d6294a77ae115962ce82b9df">Internal validity relates to the validity of inferences drawn about the cause and effect relationship between the independent and dependent variables.</p></li><li><p id="a0d12678e51b4555878eac41b622348a">External validity refers to the validity of the cause-and-effect relationship being generalizable to other persons, settings, treatment variables, and measures.</p></li></ol><p id="e0fcd8d855cf486f8c4eb201cd1368d5" /><p id="b6adc3a0a8f6420aa3dc0e1e7d8e69ab">In this module, we will discuss external and internal validity in more detail. In addition, you can read more about statistical conclusion validity and construct validity in these resources.</p><p id="b3d4810021df4100859e43794df3a6cc" /><p id="d5a74801193046e297e97f35dc72fb35">[ADD resources]</p><section id="b5606e4347dd48658e7c3aa8018e1660"><title>External validity</title><body><p id="a35050d53a1d4e738977cec3fcbb8274"> </p></body></section><p id="b33485c199484c00b4b4f0f14dd82c30" /><p id="c3f7604ee35c4dafa75ecb5b47b1712b">As data scientists, once we have defined the population of interest for the study, we must work hard to ensure that the data we will collect or the data given to us is representative of that population. For example, to investigate the impact of class size on high school student achievement, we need to decide whether it is possible to obtain a simple random sample of students from the population of students who are enrolling in formal education institutions in the United States. Alternatively, we might decide that we only want to study students in public schools, private schools, charter schools, etc. or that we want to study all high school students regardless of age. No matter what the sampling plan is, it is critical that the data we use is a <em>representative sample</em> of the population we want to study. Doing so is crucial to ensure the <em style="italic">external validity</em> of the study. <em style="italic">External validity</em> refers to the ability to generalize the findings or results to a known population of interest. <em style="italic">Threats to external validity</em> are problems that threaten our ability to draw correct inferences from the sample data to other persons, settings, treatment variables, and measures.</p><p id="be4fec584697433c9df0f08c509a5b73" /><p id="b3fd463c50e441609fa4480ec6c6a809"><em style="italic">Sampling bias</em> is bias in which data is collected in a way that some members or groups of members in a population are systematically more likely or less likely to be selected in a sample than others. Sampling bias results in discriminatory data with over or underrepresented instances that are related to the study design or data collection method and can occur in both probabilistic and nonprobabilistic sampling. A study measuring the completion rate of graduate students in the United States with a sample of students from one socioeconomic background, race, or gender will undermine the external validity of that study. This means the results of the study can not be truly generalized to the entire population of graduate students in the United States.</p><section id="dbbc18d096c84d0e8efdd8070b4ec439"><title>Internal validity</title><body><p id="d541a39f6922499ba0e7f1a28f502466"> </p></body></section><p id="ac5e982f2ace46f2afbbd94e35902b31" /><p id="f8f40d68cbcb4a7b810a550ad2fb6503">As data scientists, we want to conduct sound research that produces meaningful, impactful, or novel results for stakeholders. To produce such results, we need to ensure the confidence about the ability to draw inferences from the data about the population of interest established in the study after ruling out any alternative explanations. Failure to do so would result in internal validity threats. Threats to internal validity are problems in drawing correct inferences about whether the covariation (i.e., the variation in one variable contributes to the variation in the other variable) between the presumed treatment variable and the outcome reflects a causal relationship.</p><p id="cc923892cb6241718f98cfb84a6c1450" /><p id="fdf3374fb7c94c218ab8d198fe88d8a6">Adapted from Creswell (2012), table 1 displays the threats to internal validity, their descriptions, and suggestions for data scientists to avoid such a threat.</p><p id="dd55eb3f11b54fe8af2aae49a24e2f8e" /><p id="be4f10b84d27447b9f1b9b07bbc00b5a" /><table id="cded8476793e4334a4a06f85d90e8859" summary="" rowstyle="plain"><cite id="if855ab351a2a4fc08da65002d695e458" /><caption><p id="ee76818cd7cb4931a652df47bc86e16e" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="b21845b616d7484283ef83a13c043ff3">Type of Threat to Internal Validity</p></td><td colspan="1" rowspan="1" align="left"><p id="c637c86753d84c3aa2bf4ac242673583">Description</p></td><td colspan="1" rowspan="1" align="left"><p id="d65da298e8e2458a87d9fc198b92f8df">Suggested response by Data Scientist</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ab561154e6864ee0a26ef2574f857c71">History</p><p id="ff1f3434b40046238596264f5279faae" /></td><td colspan="1" rowspan="1" align="left"><p id="ea975970a9b14251b437565081ec44cf">Time passes between the beginning of the experiment and the end,and events may occur between the pretest and posttest that influence the outcome. In educational experiments, it is impossible to have a tightly controlled environment and monitor all events. </p></td><td colspan="1" rowspan="1" align="left"><p id="e1f1525e0bd54fbfa94c4ece54094759">The data scientist can have the control and experimental groups experience the same activities (except for the treatment) during the experiment.</p><p id="e851c7d9c6d14a87b0920fdc15e7d5b8" /></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="c01a7cfa69704309a8d4fee4b4af6368">Maturation</p><p id="dc1c6b22c1ea40e49c3c16456e8bc047" /></td><td colspan="1" rowspan="1" align="left"><p id="c8c992be1fb04fb0b57e3406ad05da20">Individuals develop or change during the experiment (i.e., become older, wiser, stronger, and more experienced), and these changes may affect their scores between the pretest and posttest. </p></td><td colspan="1" rowspan="1" align="left"><p id="d4e486c5c96740aeb39dce9d128cb2ae">A careful selection of participants who mature or develop in a similar way for both the control and experimental groups helps guard against this problem.</p><p id="a5dfaceb696d415ba62da2b88b115953" /></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ec1e9803441a454999f0c3b5af0e8b31">Regression to the mean</p><p id="eff1f5ed208547a1b7590919d03a5777" /></td><td colspan="1" rowspan="1" align="left"><p id="d0cf5104382749a7adbcc9f91deb9616">Participants with extreme scores are selected for the experiment. Naturally, their scores will probably change during the experiment. Scores, over time, regress toward the mean.</p></td><td colspan="1" rowspan="1" align="left"><p id="ccbe9367d15446b0aaaec53236007384">The data scientist can select participants who do not have extreme scores as entering characteristics for the experiment.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="b8f91819e7a34db4b6f963fef2dfd4e8">Selection</p><p id="c959abac95b747048b2a4f829683c620" /></td><td colspan="1" rowspan="1" align="left"><p id="a9ec11b3d23048d0a324d5876fd99abc">Participants can be selected who have certain characteristics that predispose them to have certain outcomes (e.g., cognitive ability, more receptive to treatment, or more familiar with a treatment) </p></td><td colspan="1" rowspan="1" align="left"><p id="f92b3315ec94441da5cfe972dbaaac56">Random selection may partly address this threat.</p><p id="c13ca2e896354624993f04e0c41a27d3" /></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="d1c88b5f217f4ea7a31ee302e419e27e">Mortality (also called study attrition)</p></td><td colspan="1" rowspan="1" align="left"><p id="dd039bd6b1324628bdb35dbc5d7c521a">Participants drop out during the experiment for any number of reasons, and drawing conclusions from scores may be difficult. </p><p id="c7b8e53a9e564b2389226b53e715f7b9" /></td><td colspan="1" rowspan="1" align="left"><p id="d97756bd54444b20bb3e2c8cbdd8e61d">The data scientist can recruit a large sample to account for potential dropouts or compare the outcome of those who drop out with those who continue.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e4bea3116f2c4a7da8adc3c0f65dfcb5">Diffusion of treatments (also called cross-contamination of groups)</p></td><td colspan="1" rowspan="1" align="left"><p id="bcdead08da75466f987409d084b4a6ff">Participants in the control and experimental groups communicate with each other. This communication can influence how both groups score on the outcomes. </p></td><td colspan="1" rowspan="1" align="left"><p id="c033a777392a4175ba8e26d18d45a741">The data scientist must keep the two groups as separate as possible during the experiment.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fa40a23af1e9489e800e95b3b840e9a6">Compensatory equalization</p><p id="ab2bbb66c3b641a2b00160582a56c8a3" /></td><td colspan="1" rowspan="1" align="left"><p id="b74519e415f241ddab334733469ba7f5">When only the experimental group receives a treatment, an inequality exists that may threaten the validity of the study. The benefits (i.e., the goods or services believed to be desirable) of the experimental treatment need to be equally distributed among the groups in the study. </p></td><td colspan="1" rowspan="1" align="left"><p id="fd1ce47f4c794111946fdcc7d1da6db6">The data scientist can provide benefits to both groups, such as giving the control group the treatment after the experiment ends or giving the control group some different type of treatment during the experiment.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="bc993a68a42442ee817bd16e3b0deb59">Compensatory rivalry</p><p id="d111dbe697c446da9e8a8451da300605" /></td><td colspan="1" rowspan="1" align="left"><p id="a6bc6493a63242518691080aa3e7c8ba">Participants in the control group feel that they are being devalued, as compared to the experimental group, because they do not experience the treatment.</p></td><td colspan="1" rowspan="1" align="left"><p id="f48efd128d694ead88fc329b19fad04d">The data scientist can try to avoid this threat by attempting to reduce the awareness and expectations of the presumed benefits of the experimental treatment.</p><p id="a2a4de2cf9524f7392b15b851109dad5" /></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="eae9f765d4254337b3624df191c0f356">Resentful demoralization</p><p id="d39d5bc770c842628806529f9c5ceb20" /></td><td colspan="1" rowspan="1" align="left"><p id="ee08aaadae224daba2ad1200266bdbcb">When a control group is used, individuals in this group may become resentful and demoralized because they perceive that they receive a less desirable treatment than other groups.</p></td><td colspan="1" rowspan="1" align="left"><p id="cab27c9f67104348bedc467b2b699124">The data scientist can provide treatment to this group after the experiment has concluded or provide services equally attractive to the experimental treatment but not directed toward the same outcome as the treatment.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="f70b0b737b1a45798801f6db4912d906">Testing</p><p id="cd31d7ef626144968b2b0a7d4aea4743" /></td><td colspan="1" rowspan="1" align="left"><p id="ba24871cf4e14c8cb2c060f091865891">Participants become familiar with the outcome measure and remember responses for later testing</p></td><td colspan="1" rowspan="1" align="left"><p id="ab0b6db505ed40d2a79be345250510eb">To overcome this threat, the data scientist can measure the outcome less frequently and use different items on the posttest than those used during earlier testing.</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="a24459a9e85545a788ec28dcde425e35">Instrumentation</p><p id="a093ebf322744791b2588d1b7717bed1" /></td><td colspan="1" rowspan="1" align="left"><p id="f9ed76a0ba694de0a1513ef7f4e12037">The instrument changes between a pretest and posttest, thus impacting the results of the outcome.</p></td><td colspan="1" rowspan="1" align="left"><p id="ad1083b0d0eb41f4bd5ec00bba8fc18c">The data scientist must standardize procedures so that the same observational scales or instrument is used throughout the experiment.</p></td></tr></table><section id="cc97db6da6754951a7b79a038bb6a3b1"><title>Statistical Bias</title><body><p id="c61ef9d3f4d24331b1b7d73303f7a690"> </p></body></section><p id="dd51b441b9584b67894d26fe27de91a1" /><p id="a1fa4f19f5664313ab1e9576a298f6f4">Statistical bias is anything that leads to a systematic discrepancy between the true parameters of the population of interest and the statistical features used to estimate those parameters. Bias made can be conscious or unconscious and the bias will affect the performance of a data science model but most importantly, the analytic solution and the decisions made after implementation of that solution.</p><p id="e77b3c9548fe4a1295bef6e796dec550" /><p id="e624894dd4024cca9cb8170ff991cb49">Statistical bias resulted from violations to external validity or internal validity of a study. In the previous module, we explored sampling bias that undermines external validity. In this module, we will explore additional common statistical biases that you need to be aware of and taken into account during the data understanding process.</p><p id="f440da6a88a8449eba501a338a787902" /><p id="f565feb8ff314239bc3cd5def8c4b628"><em style="italic">Selection Bias</em>, a threat to internal validity, occurs when there is a mismatch between the data selected for the study and the subject matter that the data scientist wants to make inferences about. Selection bias is usually a concern of studies using convenience samples. </p><p id="d970ca791b044fedbef29cc0939e2316" /><p id="b4b8e638a60f435fb1868fb7bdd0b010"><em style="italic">Self-selection Bias</em> occurs when individuals select themselves to be included in a study. Self-selection bias is a threat to external validity of the study since such bias is usually untrollable during the data collection phase. Self-selection bias is often associated with certain characteristics of the sample that induce such individuals to be included in the resulting study sample. Take the example of a survey. If the response rate of a survey is not perfect, it is likely that certain characteristics of those individuals are related to the reason why they responded to the survey. </p><p id="b68488baa4f646a2adf0745b9276680a" /><p id="e65834d97f1e449bab49bcbcbc60689c"><em style="italic">Confirmation Bias</em>. Your prior knowledge, beliefs, and values can play a role in the data that is used to build your analytic solution, this is because as humans, we are prone to use our personal beliefs and experiences to guide us through daily life and decision making. This type of bias occurs when we favor evidence that confirms our personal beliefs, values and hypotheses.</p><p id="d9103422b5e841e393e1db44328e27c9"><em style="italic">Information Bias. </em>Also known as measurement bias, occurs when data is collected, measured or interpreted wrongly. Misclassification of observations is an example of information bias, for example an observation with attributes similar to the stereotypical female student is recorded as female when that observation is male. Another example is misclassification of patients, consider the COVID-19 pandemic; groups under the age of 45 are seen as low risk; so during a screening exercise, those in that age group might not be screened and therefore classified as negative. The data collected has misclassification bias and is not accurate. One way to control information bias is to implement <em style="italic">blinding.</em></p><p id="de7100a8b8c84bb08e5280aefbc28754"><em style="italic">Confounding Bias </em>occurs when incorrect inferences are made about the subject matters while failing to account for a potential confounding variable, an exogenous factor that causes the subject matters of interest. </p><p id="d37ad110996c40798be2f97ae117caa4" /></body></workbook_page>\n'