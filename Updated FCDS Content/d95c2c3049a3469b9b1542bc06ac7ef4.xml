b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="d95c2c3049a3469b9b1542bc06ac7ef4"><head><title>Levels of Representation in Natural Language Processing</title><objref idref="dd4c3ba5100f4c4bb694c45cef8caaf8" /></head><body><p id="db0bb0ee135d476ca65753f9efa9b7f4">A language processing system will rely on different representation choices for capturing relevant aspects of the language input and output. These representations typically depend on the task and what is needed in downstream processing in the pipeline.</p><p id="d2c3ff80a440449e9321ea8134832d6b">A typical classical NLP pipeline uses at least the representation levels, as shown in the following figure.</p><image id="dee91473fb2b416288c7ff970c980207" src="../webcontent/image-cd0dc533028541da8dac5675eb0babb0-1.png" alt="" style="inline" vertical-align="middle" height="380" width="500"><caption><p id="e9b47fda16584670997a32baf7520d22" /></caption><popout enable="false"></popout></image><p id="b3224276adf740978092e844706b7c9e"><em>Phonetic and Phonological Representations</em></p><p id="c39c1fabe2364a1993ef80cb0cda4821"><em style="italic">Phonetics</em> is the study of speech sounds as physical entities (their articulation, acoustic properties, and how they are perceived), while <em style="italic">phonology</em> is the study of the organization and function of speech sounds as part of the grammar of a language. Knowledge of phonetics and phonology is pivotal for applications that require understanding or generating speech data, like digital voice assistants, text-to-speech generators, etc. </p><p id="ffdbbc694a9f4366b49aa47c388ccb60">For instance, speech recognition systems analyze (representations of) waves of air pressure (originally) generated by a human speaking and classify segments of such waves into abstractions called <em style="italic">phonemes</em>. Sequences of such phonemes are then transcribed into orthographic symbols making up words taken into context, usually through language models.</p><p id="b0eebd1b41b845beac3d25cbb47fd5ee"><em>Morphological Representation</em></p><p id="b01f4b2823ad45a798049ba173d88db5">Morphology is the study of word structures, especially how <link href="https://www.thoughtco.com/what-is-a-morpheme-1691406" target="new" internal="false">morphemes</link>, which are the smallest units of linguistic representation that come together and makeup words that can then be used to satisfy the semantic and syntactic constraints of a sentence. Morphemes can themselves be meaningful words that can appear by themselves in the language (free morphemes)  or can be affixes that can only appear when combined with other morphemes (bound morphemes). </p><p id="efd05a29f2754fc4af6e8987722a2d03">In many languages of the world, words typically consist of one or more morphemes, and these morphemes can combine in many different ways to build words (suffixation, prefixation, infixation, interdigitation, etc. A typical morphological takes in an orthographical representation of a word and generates a representation of all possible morphological interpretations of that word.  For instance, a word such as books can be segmented into morphemes as book+s, and then this segmentation can be interpreted as either book+Noun+Pl (the plural form of the noun <em style="italic">book</em>) or book+Verb+Pres+3PSg (third-person singular form of the present form of the verb (to) <em style="italic">book</em>).</p><p id="a79f9c1a09904f118b623fa4e3f42879"><em>Lexeme Representation</em></p><p id="e4e4c76aee854927ae83e5a1e98f1589">A morphological representation does not necessarily capture all the information in a word (or sometimes in a sequence of words). The lexeme representation typically adds additional information to a word representation, such as the <em style="italic">sense</em> of the root word (e.g., when we use the word \xe2\x80\x9cbanks,\xe2\x80\x9d \xe2\x80\x93 are we referring to \xe2\x80\x9cbanks on the Wall Street\xe2\x80\x9d or are we referring to the \xe2\x80\x9cbanks of the river\xe2\x80\x9d? At this level, we also perhaps conjoin words that work together (e.g., <em style="italic">look up </em>or <em style="italic">piss off</em>) and treat those as a single lexeme.  </p><p id="d60e92d5987d43eb812294b4302268f7"><em>Syntactic Representation</em></p><p id="f452413165e64da89c0b321573028192">As one may already guess,<em> </em>not every sequence of words constitutes a valid sentence in a natural language. Consider, for instance, the following sentences:</p><ul id="c96fb89d4f4e42f48f3acbea2b1af055"><li><p id="b5a5c3338e254531b527c09d71eededa">I want a flight to Tokyo</p></li><li><p id="dc517041b72142999d0bc08b09a1e706">I want to fly to Tokyo</p></li><li><p id="ea456a34deb7482fb0c4b0c0864a3411">I found a flight to Tokyo</p></li><li><p id="a7bc4f828df944e28c910acec78f4d7f">I found to fly to Tokyo</p></li></ul><p id="ada4764d8b2b46cab6140f064df45e6f">The first three look fine with our understanding of valid English sentences, but the last one does not.  Furthermore, we sort of know that in the first sentence, \xe2\x80\x9cto\xe2\x80\x9d goes with \xe2\x80\x9cTokyo,\xe2\x80\x9d \xe2\x80\x9ca\xe2\x80\x9d goes with \xe2\x80\x9cflight,\xe2\x80\x9d and \xe2\x80\x9cto Tokyo\xe2\x80\x9d goes with \xe2\x80\x9ca flight\xe2\x80\x9d and \xe2\x80\x9cI\xe2\x80\x9d and \xe2\x80\x9ca flight to Tokyo\xe2\x80\x9d go with \xe2\x80\x9cwant,\xe2\x80\x9d the main verb of the sentence.  Such relationships are hierarchical and can be captured with linguistic computational formalisms called <em style="italic">grammars</em>.</p><p id="bd722073c9a5493fb40920640329f623">Grammars assign structure to valid sentences in a language. But at the syntax level, validity is only about the structure and not the meaning of a sentence.  For example, the sentence \xe2\x80\x9cColorless green ideas sleep furiously\xe2\x80\x9d is a syntactically perfectly valid sentence, but semantically it is nonsense.</p><p id="cb473dcf85c6408e9e0a90c7e87bf46e">The syntactic representation of sentences is hierarchical: two commonly used representations are <em style="italic">constituency syntax trees</em> based on grammar expressed using context-free grammar formalism rules and <em style="italic">dependency trees</em> based on lexical relationships between words.</p><p id="db95c331987f4829b27de66dbd0f2483">For example, the following tree representation captures the structure of the sentence, \xe2\x80\x9cA boy with a flower sees a girl with a telecope.\xe2\x80\x9d The various symbols, such as <em style="italic">NP</em> (noun phrase) or <em style="italic">VP</em> (verb phrase), are names of various intermediate structure types as defined by the underlying grammar.</p><image id="e6c5f907b123425782afe39146670408" src="../webcontent/image-cd0dc533028541da8dac5675eb0babb0-2.png" alt="" style="inline" vertical-align="middle" height="300" width="600"><caption><p id="b78153ca0e6f4705bf4f46557b8bff00" /></caption><popout enable="false"></popout></image><p id="be3ddaacb4db4ea5bb1f75247cc34475">Here the structure is for the interpretation of this sentence where the boy is using the telescope to see the girl.</p><p id="c638e8f9bbac400d9b2128cefa456988">The sentence can also have the following tree representation:</p><image id="af936d6ee282471b9b14fadb7ca7f1a7" src="../webcontent/Screen_Shot_2022-10-04_at_15334_pm.png" alt="" style="inline" vertical-align="middle" height="341" width="600"><caption><p id="d953072cfc37420c994d7c774de600d6" /></caption><popout enable="false"></popout></image><p id="a8359a75f91d490888817117d392d7d4">This is for the interpretation where the girl is carrying a telescope!</p><p id="d6dbf08be1e948f88352b6a04bf39d05">This brings out another major issue in NLP:  there are usually a multiplicity of representations for almost all inputs (remember the two possible interpretations of \xe2\x80\x9cbooks\xe2\x80\x9d above, which need further context to resolve during actual processing). Rerouting such ambiguities at every level of linguistic representation is probably the hardest problem in NLP.</p><p id="e56a9b148fbb4c0f87f5c3839ea69b65">A more recently commonly used syntactic representation relies on <em style="italic">dependency relationships</em> between lexical items, forgoing any use of the intermediate structure or phrase types in the trees and representing lexical relations between headwords and dependents, with a label denoting the relation as shown here.</p><image id="aecc3e53f0a1441ca54bc1c3c6345df3" src="../webcontent/image-cd0dc533028541da8dac5675eb0babb0-4.png" alt="" style="inline" vertical-align="middle" height="180" width="500"><caption><p id="f1c088c45c2c430b9bb659dcb6de9ce3" /></caption><popout enable="false"></popout></image><p id="a4e2f3a554fd441abe60ee6f44ffb4b2">Here \xe2\x80\x9csaw\xe2\x80\x9d is the main meaning carrier of the sentence. \xe2\x80\x9csaw\xe2\x80\x9d has the <em style="italic">subject</em> \xe2\x80\x9ckids\xe2\x80\x9d and a <em style="italic">direct object,</em> \xe2\x80\x9cbirds.\xe2\x80\x9d \xe2\x80\x9cfish\xe2\x80\x9d is related to \xe2\x80\x9cbirds\xe2\x80\x9d as a <em style="italic">prepositional object</em> which itself is related to \xe2\x80\x9cwith,\xe2\x80\x9d which is a <em style="italic">preposition</em>.</p><p id="c88881271a36462f8ef064b0d1de2ce8"><em>Semantic Representation</em></p><p id="df05a32a9a2e4a0681fb2b4aff5c6df3">Loosely speaking, this level represents the \xe2\x80\x9cmeaning\xe2\x80\x9d of a sentence, sometimes compositionally scaffolding the structure of a sentence as described by a syntactic representation. Early approaches to semantic representation have assumed rather discrete representations of entities, properties, and events in a \xe2\x80\x9cworld model\xe2\x80\x9d and have employed formalisms such as formal logic to capture what is called the truth-conditional semantics of a sentence.  A sentence such as \xe2\x80\x9cEverybody has something they  like.\xe2\x80\x9d would be represented by a logical form such as \\(\\forall x \\exists y\\  likes(x, y)\\).  The true value of such a sentence can then be computed based on the description of the world model.</p><p id="a7d0f41d1c914faeb8c6eb3d5543231c">A less formal but potentially more useful approach to semantics has been flatter but still hierarchical representations using <em style="italic">semantic roles</em>. Such representations assign the same semantic representation to syntactically different sentences if those express essentially the same event.  For example, all these sentences:</p><ul id="aca460720fd44cfbbad41a62f9fabaf6"><li><p id="bee89641fdc64042b302d1c2fc4a0bd3">Warren bought the stock.</p></li><li><p id="a307814f2f83432e958de882b824991a">Someone sold the stock to Warren.</p></li><li><p id="be3467e0ff2d4ec9b8c6ba307e90947c">The stock was bought by Warren.</p></li></ul><p id="d32167d988574ab1bca9a4947b7f9493">are describing the same \xe2\x80\x9cselling\xe2\x80\x9d event where the <em style="italic">buyer</em> is Warren, <em style="italic">stocks</em> are sold, and the <em style="italic">seller</em> is not known or not expressed explicitly, but it is inherent.  Thus the semantic representation for these sentences will be the same.  There have been many similar approaches proposed along the same lines differing in the types of roles and granularity of how events are represented.</p><p id="ec09b32a28224a51b91b17f9eb13e912">Much more recent approaches to semantic representation, especially in deep learning contexts, rely on embeddings computed by either running the embeddings of individual words through an encoder (e.g., in a machine translation system) or usually by even just adding up the embeddings of individual words to get a representation of the sentence.</p><p id="fa128fe395a2465d96bc974f8c6f8dc9"><em>Pragmatics</em></p><p id="fdc44c10077a43b8b6736c5dbeaca078">Pragmatics deals with understanding how the context in an utterance is made, or a sentence is used to contribute to the overall meaning and communicative intent and which aspects of a context are relevant to the interpretation of the utterance of a sentence.  Such contextual information also includes intonation, physical gestures, and social identity.  For example, an utterance such as \xe2\x80\x9cCan you pass the salt? \xe2\x80\x9c in a dinner set is really not a question of someone\xe2\x80\x99s ability to pass the salt but is rather interpreted as a gentle request.</p><p id="e9bf95bd521d4285aa9d0c7459503525">Thus pragmatics requires representation of all aspects of the context, including the set of all propositions that all discourse participants in agree on for the purpose of going on with the discourse.</p><p id="f6492b502c374c6b8b02607235620310"><em>Discourse</em></p><p id="e96bd35db0744a97a956a72683a28cdb">A sequence of natural language sentences incrementally describes a local model of entities and the (evolving) relations between them. This model is known as the discourse model, and we, as the understander of the text, interpret linguistic expressions in the sentences with respect to this mental model that the understander of the text builds incrementally as we read,  containing representations of the entities referred to in the text, their properties and the relations among them.  This mental model already assumes a jointly agreed world model (e.g., everyone \xe2\x80\x9cknows\xe2\x80\x9d New York City or \xe2\x80\x9cBill Clinto\xe2\x80\x9d), and one introduces entities that will be mentioned by naming them the first time they need to be mentioned and then as the text develops uses a variety of linguistic referring expressions to refer to these entities as needed.</p><p id="b99932b91f2d4033a8bd8f25a4324b20">Furthermore, not every possible sequence of sentences constitutes a meaningful discourse. Consider the following two sequences of sentences:</p><ul id="e08b816b4f9a425db442d29d8b2d1a32"><li><p id="cc0289ca4a9940579b71d9af665cb649">Eric is a pathetic programmer. He only knows Java. Worse still, he always optimizes the outermost loop first. However, the incompetence of his managers ensures him a steady, six-figure income.</p></li><li><p id="dc0759efedd444aaa70bae9273907baa">Worse still, he always optimizes the outermost loop first. Eric is a pathetic programmer. However, the incompetence of his managers ensures him a steady, six-figure income.  He only knows Java.</p></li></ul><p id="ef1b37d746b8428e86639559e9d1d353">Clearly, only the first of these \xe2\x80\x9cmakes sense\xe2\x80\x9d; the second is not something we are likely to see feel that while we probably understand each sentence, we have a feeling that the whole thing does not \xe2\x80\x9cmake sense.\xe2\x80\x9d</p><p id="b62f3fbf4cf244f1ab6e80c56de88028">A sentence sequence has to exhibit hard-to-define properties to be interpreted as a discourse: They have to have <em style="italic">cohesion</em> and <em style="italic">coherence</em>. Cohesion refers to the degree to which two passages of speech/text are \xe2\x80\x9cheld together\xe2\x80\x9d by formal devices like shared words and discourse markers that indicate continuity or lack of continuity. On the other hand, coherence refers to the degree to which passages in a text have \xe2\x80\x9cmeaningful relationships.\xe2\x80\x9d</p><p id="b48de360f5a7456e9df195454529e289"><em>Representation in Neural Models </em></p><p id="bbf1a5eea36b4cfc8429159d1afd319b">Recent work in NLP has been using a representational paradigm based on a real vector representation of words. Such representation represents not only the identity of words (as a lexicon would) but also their semantics by capturing aggregate contexts words appear in to represent word semantics.  The idea of such representations is actually quite old and goes back to what is known as the <em style="italic">distributional hypothesis</em>, first put forward in the 1950s.  This hypothesis basically states that \xe2\x80\x9cWords that occur in similar contexts tend to have similar meanings.\xe2\x80\x9d</p><p id="c7f1f088b5b248fbb7615c0fdbc132fc">Such representations have been instantiated with the notion of embeddings which can be computed directly from the distributions of words in large amounts of text using a variety of algorithms, such as <em style="italic">word2vec</em> or <em style="italic">glove</em> embedding algorithms. Recent NLP algorithms that make use of the meanings of words use embeddings. Basic embeddings can be static since the computations rely on the orthography of individual words. Thus words with multiple meanings, such as \xe2\x80\x9cbook,\xe2\x80\x9d \xe2\x80\x9cbank,\xe2\x80\x9d or \xe2\x80\x9cdown,\xe2\x80\x9d get an embedding that lumps the semantics of all different meanings into one vector. Recent large transformer models such as BERT can compute <em style="italic">contextualized embedding</em> from static embeddings as input when a sentence is an input.  These contextualized embeddings capture different uses of an ambiguous word and are typically different for each distinct user/meaning of a word.</p></body></workbook_page>\n'