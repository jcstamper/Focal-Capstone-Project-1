b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="fa4af4b47a6b4c43af857ae981212dc6"><head><title>Computer Vision and Applications</title></head><body><section id="d1943e0d9a3a4e0a8485f9c753d71a17"><title>Computer Vision and Applications</title><body><p id="af48818cc6d8489f9681bc8cac838ce6"> </p></body></section><section id="c0e53afa6b4f44e4b69daf3b384eb348"><title>Introduction to Computer Vision</title><body><p id="ba088d9609b3465b85ae946f03d35189"> </p></body></section><p id="a1d6ddf798964b0e8070f7c2c011cccb">Computer vision is the study of how to equip computers with (super) human-level perception, or more specifically, how to analyze or manipulate pixel values in a meaningful way. While computer vision models take input feature matrices and output scalars or vectors, much like the standard machine learning paradigm, the fact that their inputs are images (2D or 3D matrices) presents several interesting challenges.</p><p id="b15eae3a634840b0bdafecf854d0f9c9" /><p id="ce0a513226964041b7e367103181e8c0">Through the course of this module, we will be building upon the Deep Neural Network concepts introduced in the previous module. The power of neural networks, particularly multilayer perceptrons, lies in the ability to automatically extract a hierarchy of features at different levels of abstraction for classification tasks. As a result, neural networks preclude the need for feature engineering as standard machine learning methods require. However, one of its downsides is the presence of too many parameters and the inability to incorporate particular input structures required to model data from specific domains.</p><p id="ee984d58d9884298b89b2a14ec704f4d" /><image id="b7fab2a7b12946818ba62994a5f8cec9" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-1.png" alt="" style="inline" vertical-align="middle" height="245" width="468"><caption><p id="aedab54dcd9247b7ab44025f2ce523f2" /></caption><popout enable="false"></popout></image><p id="c278135776324ca7bfd6101aae5eafb7" /><p id="c75f92ea61aa46a8a944ceeb84e21acc">Figure 1. Rivian Pickup Truck.</p><p id="a6b481baa080426ca054f8e12e799fb7" /><p id="eaf0f9d27cc7436583bfb3dd9fab475d">Let us consider the image analysis task, where we would like to figure out what is happening in a given image or a sequence of images. In this image of a pickup truck (Figure 1), we get important signals regarding the objects within the truck, such as wheels, headlights, doors, and so on. The spatial proximity of the key features helps us understand what is happening in this image. This is the task of <em style="italic">image understanding</em> in computer vision. The input to all the computer vision models is the raw pixels in the images, which are just matrices of numbers representing the intensity levels of various spatial locations. From the computer&apos;s view, an image (Figure 2) is just a big matrix with a number (or tuple of numbers) at every pixel (Figure 3).</p><p id="c2f90adf701d4ea88a0c82b49d33afcd" /><image id="e42445efc10b41c78512f784a472658a" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-2.png" alt="" style="inline" vertical-align="middle" height="320" width="468"><caption><p id="fa21a549bb5d4135ae4495b375796b8c" /></caption><popout enable="false"></popout></image><p id="ea681f39e62d4999a40e79330d5f0ebf">Figure 2. What a person sees.</p><image id="fbe9f9c20ef641d182f071718e72a19c" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-3.png" alt="" style="inline" vertical-align="middle" height="283" width="468"><caption><p id="ba224a8e93124ecd860bc57db0de9d1f" /></caption><popout enable="false"></popout></image><p id="bfd06b0e456a4e4c85712715166acd8c">Figure 3. What a computer sees.</p><p id="af91760537f144b78e967d7f6ff39e11" /><p id="f67ef49f35f24688941af38e6dff0f55">A straightforward approach would be to flatten the image&apos;s pixel values and feed them as inputs to a multilayer perceptron. However, by doing so, we lose the valuable signal captured by the spatial structure of the image. Therefore, while learning useful visual features in computer vision, the key idea is to preserve and use the spatial structure of the image. One way is to use some spatial filters to extract a spatially adjacent set of pixels in the image and then feed those image patches to a multilayer perceptron. This idea sparked the need for a mechanism for weighting those extracted patches from the image to highlight their relative importance. In addition, it is sensible to use spatial filters of varying sizes to extract features at different resolutions. The algorithm we described was formalized as the convolutional neural network (CNN).</p><p id="caae906c03b5460ea40ca062de793821" /><p id="f8fd89611af74b378dd536de04812c0a">In this module, we will introduce the basic CNN architecture and classic architectures such as LeNet, AlexNet, VGGNet, and ResNet, which you will be implementing during the Computer Vision task in one of the Projects during the course. We will also brief the current state of CNN research and a few contemporary applications of computer vision.</p><section id="f119d60ec8d5447cad7f412d55cc0cb1"><title>Computer Vision Applications and the three \xe2\x80\x9cRs\xe2\x80\x9d of Computer Vision</title><body><p id="a64b3531ddf1471c924a485fcc946ffe"> </p></body></section><p id="e76493b8116845f3be5b90c4fd70900b" /><p id="c186236c9eae42a3ac11a2de29d094d1"><link href="https://en.wikipedia.org/wiki/Jitendra_Malik" target="new" internal="false">Jitendra Malik</link>, a computer vision pioneer, proposed the &apos;Three R&apos;s&apos; as the classic problems of computational vision: reconstruction, recognition, and (re)organization. You might have come across many computer vision applications in your daily life, which are most likely attempts to solve one of the three Rs. In this section, we brief a few common applications of computer vision.</p><p id="c998f79e6b6b4353a876243aff98b1a2" /><ol id="a9dc8e8b3f9a496eae44c756366f115b"><li><p id="d56fbad720094f10b185728d28be6aff">Optical character recognition (OCR)</p></li></ol><p id="e705feacf66746b2be33dbc242665ef8" /><image id="d68ae692e2d84de1b85b4d7ec0573acb" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-4.png" alt="" style="inline" vertical-align="middle" height="226" width="363"><caption><p id="bc2210f711e74d13892147231d4aceb8" /></caption><popout enable="false"></popout></image><p id="ac4718629fe14fd0bd8c466f85ff9b31">Figure 4. LeNet 5.</p><p id="b1b96350a41a4218ad5731eb982967c4" /><p id="c868ab39fc704f03bcbcd6ec6032b4e4"><em>Optical character recognition</em> or <em>optical character reader</em> (<em>OCR</em>) is a technology to convert images of text into texts. The text images can be typed, handwritten, or printed into machine-encoded text such as a scanned document, a photo of a document, or an image that contains the text. Figure 4 shows the results of probably the first OCR task, LeNet. OCR is a commonly used method to digitalize printed text to reduce storage size and enable editability and searchability.</p><p id="b939d0aa0a17463b91524d5fadd0397b" /><ol id="e381d16575c64d898c5b862075dfdec6"><li><p id="e3eeb86c338348a7bbe5b83c5bd145ae">Object Recognition</p></li></ol><p id="cc95022f4a0043a7afc2eef46dd0920c" /><p id="fff728ef28724234a9901d938b19161d"><em>Object recognition </em>is a computer vision technique for identifying objects in images or videos. It might be relatively easy for a human to look at a photograph or watch a video and spot people, objects, scenes, and visual details. However, it is not as straightforward for a computer not only to recognize the items but also to understand what the items mean to the level of understanding of a human. Object recognition is a key technology behind driverless cars (Figure 5), enabling them to recognize a stop sign or to distinguish a pedestrian from a lamppost. It is also valuable for disease identification in bioimaging, industrial inspection, and robotic vision applications, just to name a few.</p><p id="b4b0c157d24b4bd38f7cc0c11d29e122" /><image id="ee88fe97c2fe447290f1abc16a0a7750" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-5.png" alt="" style="inline" vertical-align="middle" height="258" width="353"><caption><p id="bfbd0c1223e44173886e14365d12674f" /></caption><popout enable="false"></popout></image><p id="e56423240de141e2a33e38858090355b">Figure 5. Object recognition technology from Tesla\xe2\x80\x99s Autopilot and full self-driving capabilities.</p><p id="de59fd2c259c4bdb818f5d84071aaf0a" /><ol id="cedc345773934645ae72a05480f87e85"><li><p id="ff2e4ec65f834ccfb08a67da5ea8ac5c">Face Recognition</p></li></ol><image id="d07fc00cfb824cd48a307bd906950506" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-6.png" alt="" style="inline" vertical-align="middle" height="261" width="468"><caption><p id="b472b1aa105c438eb48a1ac6c40d4fb4" /></caption><popout enable="false"></popout></image><p id="f05bf8b4a201474ea75fdfcdbc28e8df">Figure 6. Apple\xe2\x80\x99s Face ID.</p><p id="ef3a560d5bf94577be3509ff8da685c3" /><p id="dbaa2bacd8424a0aa44ab199f7520c93"><em>Facial recognition</em> is a specific case of object detection where the primary object is the human face. While similar to object detection as a task, where features are detected and localized, facial recognition performs not only detection but also recognition of the detected face. Facial recognition systems search for standard features and landmarks like eyes, lips, or a nose and classify a face using these features and the positioning of these items. Some applications of facial recognition include:</p><ol id="d1a515bccf1f4a699d57e84f6948b8b0"><li><p id="fe0c48620d0b4cebb47cc82193a5f7cf">The facial recognition system is used as an ID verification process to authenticate users for security purposes, such as Apple&apos;s Face ID (Figure 6), <link href="https://www.travelandleisure.com/airlines-airports/clear-airport-security" target="new" internal="false">Clear</link> airport security service, and the United States&apos; driver&apos;s license photo database.</p></li><li><p id="ec304394ce33483eb0f0f815e789c9fb">Image augmentation applications on various social media services, such as Snapchat, use an algorithm to detect faces and perform augmentation to swap faces in an image for entertainment (Figure 7). </p></li></ol><p id="bc2ab3a398494f838f6924d7c393289e" /><image id="c00d6c7c49d0413ca17796bac5f81039" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-7.png" alt="" style="inline" vertical-align="middle" height="351" width="468"><caption><p id="d01306ef818648c2b5e25f97f6003c35" /></caption><popout enable="false"></popout></image><p id="cffe6ab0f3114cbc9e176adedd8391de">Figure 7. Snapchat\xe2\x80\x99s Face Swap.</p><p id="bdd0d776b457414e8d71cc0ce47cd6ad" /><ol id="c0a20f0fcf1b4c57ba25cb899ab409ac"><li><p id="eacd88d181fd4634b64be5233dbc4076">Vision-based Biometrics</p></li></ol><p id="db5512096b8a4711bb9ec678d9a63602" /><p id="d6323f6d48544a1fb1ac502086c9c6a3" /><image id="b1036cb2e4bb44fb988331c7ee31f210" src="../webcontent/image-fa4af4b47a6b4c43af857ae981212dc6-8.png" alt="" style="inline" vertical-align="middle" height="224" width="300"><caption><p id="e650ebdd439c4276abb24e0d79cf7d42" /></caption><popout enable="false"></popout></image><p id="a636acbddcfe45479aa5eb72e133a0f1">Figure 8. Sharbat Gula, photographed in 1984 and 2002.</p><p id="fe30394e933d4a1bbb7c0ebeee1dc1dc" /><p id="ba4d4dd59dc640418729bdf7a7885ede">Sharbat Gula, one of the students in an informal school at the Nasir Bagh refugee camp, was identified 18 years later from a photograph taken in 1984 when she was 12, using an analysis of her iris pattern image (Figure 8). <link href="https://www.robots.ox.ac.uk/~az/lectures/est/iris.pdf" target="new" internal="false">Daugman (2004)</link> computed IrisCodes from both of her eyes from the photograph in 1984 and 2002, respectively, and matched them using a Hamming Distance to confirm that the images are of the same person. Read more about the story <link href="https://www.cl.cam.ac.uk/~jgd1000/afghan.html" target="new" internal="false">here</link>.</p></body></workbook_page>\n'