b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="fa6250d2e56a418db1cf98a4827de1a4"><head><title>The Basics of Hardware: Processors</title></head><body><p id="f7fb9eff462347519d586bb98fcd7c04">Besides memory, the other main aspect of any hardware system you will need to assess in order to understand if it\xe2\x80\x99s important for computing are the processors inside the system. In data science, you will see a variety of processors being used, but they tend to split into three main categories, from least expensive to most expensive: CPUs, GPUs, and DSAs.</p><section id="a2d4e4b75e734decb85ea3b10551f69a"><title>CPU</title><body><p id="b5211ea7191542c68e9b90c232996ac3" /></body></section><p id="fa8a9c7c747040369f13b19141958355">The primary processor on a system, the Central Processing Unit, is used on most systems for the majority of complex calculations unless the application developer specifically invokes another processor. They can handle less parallelism than GPUs but are more able to handle longer sequences of branching statements with ease.</p><section id="f86553e88d804c5ab6ec22911da6c0d9"><title>GPU</title><body><p id="cf2bed16c5b947ec8f848a0fa18914a2" /></body></section><p id="b5d3087c96de4f60af6a53200551fb94">Also known as the Graphics Processing Unit, this is an additional processor present in systems to help manage graphics and other calculation-intensive operations where there is significant <em>data parallelism,</em> i.e., where we can split the data into chunks and process each chunk separately. While most systems nowadays have an integrated GPU of some kind, in data science, we tend to focus on systems that have a separate GPU, which has performance in mind. As data science applications and graphics applications require similar data-parallel computation, these tend to be much faster in some tasks than CPUs.</p><section id="c80930a05d0a46359a924557c8c36b03"><title>DSA</title><body><p id="d2d213184c9e4c4ea700737ed2fbd7cb" /></body></section><p id="d5b5e223c10d4fca91fa6c64818dbadd">Also known as Domain-Specific Architectures, this category ranges from Google\xe2\x80\x99s TPU to Intel\xe2\x80\x99s Crest<cite id="i323137a7a3b049f4aba3644364c2c4a0" entry="c0d25870d40440c7bbd25ad591e3a61d" />. These are purpose-built systems to solve computationally expensive modeling problems, like those found in neural networks. These tend to bring the largest performance gains for data science but are further limited in what they can do, as they are built to solve specific problems and can be difficult to program directly.</p><p id="bcc1e21c349a4e73a3d01b057442b3ac">While it is tempting to use the most-efficient DSAs and try to squeeze as much performance as possible out of the newest systems, remember that, in the data science process, you will need to budget cost as well as <em>time</em>. It might be useful to use a DSA or a GPU, but you should remember to do the following when deciding whether to use either chip for a project or not:</p><ol id="bd8a1a6be7cc4c9fa03f8ddf63c70198"><li><p id="f1c7e0f8863041c79f4fc169b83f8a72">If you have access to trial usage of the DSA/GPU for your project, check that the tools you are using utilize the accelerators at all. As these chips require separate programming APIs to utilize, the tools which you use them might not be compatible out of the box or at all.</p></li><li><p id="ffeb676345d042b19980ea50723de761">Additionally, before setting and forgetting your system, check the usage patterns of the code you are able to run.</p><ul id="d9d4b914f4534f85bf7e5820cea905ce"><li><p id="ba847797cea6428e9703ebf0051372be">If the code is relatively I/O, Network, or Memory intensive, it might not make sense to use an accelerator chip, i.e., a GPU or a DSA, in your system. Instead, it might pay to try to use multiple processors or multiple computers together to solve the work in question.</p></li><li><p id="e6eefc64600246e08f19483d54db5d7e">If the code is computationally expensive, check to see if the memory usage aligns with the memory limits of your GPU/DSA. As these chips have their own memory, keeping to such limits can ensure that your code runs smoothly.</p></li></ul></li><li><p id="a1e91f70c6444d2ea2ed3ff26a00263c">Lastly, and most importantly, use profiling tools on your code. While such tools can be difficult to use at first, they provide the best way to see immediately where the potential slowdowns are and can give you ideas about where you need to optimize your code. If you do not want to use a profiler, you could even use just a simple timer in your program and count the time taken to run some hot sections accordingly.</p></li></ol></body><bib:file><bib:entry id="c0d25870d40440c7bbd25ad591e3a61d"><bib:book><bib:author>John L. Hennessy and David A. Patterson</bib:author><bib:title>Computer Architecture: A Quantitative Approach</bib:title><bib:publisher>The Morgan Kaufmann Series in Computer Architecture and Design</bib:publisher><bib:year>2017</bib:year><bib:edition>6</bib:edition></bib:book></bib:entry></bib:file></workbook_page>\n'