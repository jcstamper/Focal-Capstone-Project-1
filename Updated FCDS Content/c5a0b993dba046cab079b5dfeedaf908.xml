b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="c5a0b993dba046cab079b5dfeedaf908"><head><title>Classification</title></head><body><p id="ec4671bb39f9467f987cdfa704321907">Let us assume that you have a medical dataset that contains observations with features including patient age, weight, height, sex, and race, and you have been tasked with identifying whether a patient is diabetic or not). It would take a long time for you to review each observation and compare their feature value and symptoms to classical symptoms of diabetes. Using a data science approach, you can assign a diagnosis to each observation based on the historical data for that diagnosis. You would be a classification problem. <em style="italic">Classification</em> works with an existing dataset that has labeled outcomes and seeks to label the outcomes of a new, previously unseen dataset. Below, you will find the different types of classification problems. Later in the course, we will explore methods that can be used to solve classification problems.</p><p id="aae08dbe32214ecb8836cd4c1f7e8fe0"><em>Binary Classification</em></p><p id="b82be53056f24b529afb4989453a8174"><em style="italic">Classification</em> tasks that are binary will classify observations in a dataset into two defined categories. The observations are grouped based on the presence of characteristics unique to one of the two categories. An example would be making a decision on a credit card application (i.e., approve/deny).</p><p id="ed613473c1fc48018e491acca857b218"><em>Multi-Class Classification</em></p><p id="e107df1cb1e247edaeb5b7f27f9d2aad"><em style="italic">Multi-class classification</em> also referred to as multinomial classification, classifies observations into one of three or more classes. Each observation can only be classified as one of the multiple classes. That is, an observation can not be labeled as belonging to imore than one class. For example, if our task is to classify images with a single fruit in each, a classifier would classify each new image into one type of fruit, e.g., one of orange, pineapple, peach, and mango.</p><p id="b4e936b642ed426795c19b64831fe612"><em>Multi-Label Classification</em></p><p id="ddcc3e7e8d614c288deb52650595c24c">Unlike multi-class classification, which assumes that each observation belongs to one class, <em style="italic">multi-label classification</em> allows for observations to be classified under multiple classes hence the term multi-label classification.</p><table id="b197cf59369349d8a071241f8baa2726" summary="" rowstyle="plain"><cite id="idfa435e5ec24446aa0857cd7a7d4ee4e" /><caption><p id="de24dd1615354461b30736fcad440d23" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="aba75676e36d4be28116fb7453bddb31"><em>A quick thought: </em>Can you think about a scenario where observations can belong to multiple classes at once (thereby leading them to be labeled under those classes)?</p></td></tr></table><p id="b0c6dd39168d446bb0d776efa40d5fcb">Multi-label classification can be applied to, for example, classifying textual data. One important such application is document classification, the task of determining the topic of a document. It is conceivable that a document on politics can also be considered a business or an economics document \xe2\x80\x93 though perhaps not that strongly. Or, if you watch movies, you know that some movies can belong to multiple genres, e.g., Romantic Comedy, Romantic Drama, and Thriller Comedy, etc. Let us stick with this example and conceptually define how a multi-label classification task would pan out.</p><p id="fba333e6d0f04f62983dd4b94d90251c">You are tasked to classify movies based on their plot. We can assume that we have defined our analytic objective, defined our requirements, and we have gathered and prepared our data. When you classify the observations in this dataset, you might find Movie A will belong to Romance and Comedy. Let us now look at the different multi-label classification techniques and see how they can handle problems with multi-labels without causing a dimensionality issue to your dataset and jeopardizing the performance of your model.</p><p id="b0a137baf27441ddbace6fc1c039a5c6"><em style="italic">Multi-label Classification Techniques</em></p><ul id="e16a8bd757f94e1e8b9df198b4d6203e"><li><p id="c925b22826544a2ebfa134ebc3304418">Multi-label classification does not have constraints on the labels that observation can have, and this makes it difficult to learn. Using the <em style="italic">OneVsRest</em> Technique, the classifier makes the assumption that labels are mutually exclusive and there is no consideration for correlations between classes.</p></li><li><p id="e84e0a041fce43c58bee529cedf3f23a">Similar to OneVsRest, the <em style="italic">Binary Relevance</em> technique trains a separate single-label binary classifier for each class, i.e., for each class, an observation will either be predicted as belonging to that class or not. This technique ignores any correlation between classes.</p></li><li><p id="d648f104430d429fae5663c4179331a8">The algorithm for your classification task can also adapt the algorithm to perform multi-label classification. A popular example is using a multi-label version of the k-Nearest Neighbors (kNN), a supervised learning technique we saw before that makes the assumption that similar data points are always close together.</p><p id="ef8df6ec7189441c8134a37754a06a7b"><em>Example: </em><link href="http://scikit.ml/api/skmultilearn.adapt.mlknn.html" target="new" internal="false"><em>scikit-multilearn for MLkNN</em></link><em>.</em></p></li><li><p id="ce82cad3c4df4f19a83788facb4e7cf6">You can transform your task into a multi-class task by training all unique class combinations on one multi-class classifier.</p><table id="f28887f80f364a2c9b56e36d25705b56" summary="" rowstyle="plain"><cite id="ia5234d4ae95d498e99ff8a9d52313df8" /><caption><p id="fc5d900b5dc145ba93d6ae782eb200a7" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="b05128bd13734d938a04778f96a853a2">X</p></td><td colspan="1" rowspan="1" align="left"><p id="b2fbe78ed75a4f958c79733b8e2466ac">Y<sub>1</sub></p></td><td colspan="1" rowspan="1" align="left"><p id="d8e2d7d35dfb435cac49e2b0730ef0fc">Y<sub>2</sub></p></td><td colspan="1" rowspan="1" align="left"><p id="a32938619e0845d9802f9389cac1f8a0">Y<sub>3</sub></p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="d2e9dd0a85e84695951a3b030dded0d9">X1</p></td><td colspan="1" rowspan="1" align="left"><p id="c4e7143876254eeb8e6b89a03960124c">0</p></td><td colspan="1" rowspan="1" align="left"><p id="a95c8df536c34d54b35ebc1d03d46b2c">1</p></td><td colspan="1" rowspan="1" align="left"><p id="c91f0116c74f45ab85182861ae5b679d">1</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fd04af12ec7e460a9b77b2bc95dda30f">X2</p></td><td colspan="1" rowspan="1" align="left"><p id="eabc9036af5740dc97b2cfd06d0128ac">1</p></td><td colspan="1" rowspan="1" align="left"><p id="de4f0e7479fd49febf18c3b5da68f3f4">1</p></td><td colspan="1" rowspan="1" align="left"><p id="a5a644ff78964c9bbe60d2318f789783">0</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e30ebc2a383443c9a8e9f9f180c5bc99">X3</p></td><td colspan="1" rowspan="1" align="left"><p id="d6101035d0d645d898aea96d6e927f22">1</p></td><td colspan="1" rowspan="1" align="left"><p id="fe353729ee7f4eada9d8802afb6df1e0">1</p></td><td colspan="1" rowspan="1" align="left"><p id="d3ddb5bd569d4ab2a77533c3d38f6ac0">0</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="c24dc09d50d345b69bb62c1a420df8dc">X4</p></td><td colspan="1" rowspan="1" align="left"><p id="cf17b34c63334a668d12d50dcd7bda4f">1</p></td><td colspan="1" rowspan="1" align="left"><p id="f0dc160a625f4994bbce33451c3fd978">0</p></td><td colspan="1" rowspan="1" align="left"><p id="b7d24e75b84747408fba350b693ecab5">1</p></td></tr></table><p id="fa137c8c55014d37af76a446c991ff59">Here we see that observations X2 and X3 belong to the same classes. This technique will transform our task into a single multi-class task and give a unique class to all possible combinations in your training data set.</p><table id="b89ed54620a9471fbb97ef0f649b15cf" summary="" rowstyle="plain"><cite id="ib3f8c07a4de941c685320f828ea8fb57" /><caption><p id="d7039c1e3dd04680a863acb7f0706255" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="f1bd6e7b821b40f39f87ad0b5465af79">X</p></td><td colspan="1" rowspan="1" align="left"><p id="c6d0ae8072b4484186823b7c5520e1b8">Y<sub>1</sub></p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="b289cfbe531f4a86acb742d024d9a13d">X1</p></td><td colspan="1" rowspan="1" align="left"><p id="e5801f7ea1544e5ca4f5cbff31c8f124">1</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fb9a257c2f8f436b9b864566792ea8ea">X2</p></td><td colspan="1" rowspan="1" align="left"><p id="b26471dcd2e34ef8a90b87cf85fd08fa">2</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="d2f28860102c4ba9a29449e92ef85f33">X3</p></td><td colspan="1" rowspan="1" align="left"><p id="ec2b40bb1de54310bd756659d1409602">2</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="dba2dbbc930d43f6bfca1a64940045b7">X4</p></td><td colspan="1" rowspan="1" align="left"><p id="dca408912d0a459cabe69953b681637c">3</p></td></tr></table></li><li><p id="cafdf910196643afbf529f815cfa9bab">So far, we have seen that OneVsRest, Binary Relevance, and Label Powerset techniques do not consider correlations between classes. <em style="italic">The Classifier Chains</em> technique will build a chain of binary classifiers to take into account any correlations between classes. The number of classifiers that are constructed equals the number of classes, i.e., if we have classes: comedy, drama, and romance, we will have three classifiers as well C1:C3.</p></li></ul><p id="cfeed6f28e6645228a45ff0e08290f11">We should mention <link href="https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf" target="new" internal="false"><em>Logistic Regression</em></link> in this section because it is an important classification technique. You will learn more about it in the next module. Logistic regression uses a logistic function to model the probability of a class or event. Some questions you can answer with logistic regression are: Will you pass or fail a course, will you develop high blood pressure based on certain attributes, or will 18 to 35-year-old college-educated men from Pennsylvania vote for the Democratic or Republican presidential candidate in the 2024 presidential elections? The logistic regression model can have independent variables that are of diverse data types, but the response is categorical.</p></body></workbook_page>\n'