b'<?xml version="1.0" encoding="UTF-8"?>\r\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="d36a94bc5b3e4f6d91845ce57283dafa"><head><title>Summary and Quiz 9</title></head><body><ul id="a21407e4808a44e1b82da52db5bc15bd"><li><p id="a6e265b74ab44b04a9252f714fd7f819">You can categorize data according to characteristics using a technique called <em style="italic">Cluster Analysis</em>. If you think about how we reason and learn as human beings, we make sense of events, people, and things by placing them in groups.</p></li><li><p id="a89e90257c2d4626a41b5dd432f732e9"><em style="italic">Hard Clustering </em>divides data into a number of groups and can only belong to one cluster. All clusters are independent of each other. </p><p id="e5cbc48cc6d84d22b9678971ec15b17f"><em style="italic">Soft Clustering</em> groups data into clusters but a data point can belong to more than one cluster to a degree. </p><p id="a7dfe5c403b64f1a9fb6735403a4550e"><em style="italic">Overlapping Clustering </em>allows data to belong to more than one cluster.</p><p id="b6a56dfa9c5f40098775aea99ebf2943"><em style="italic">Hierarchical Clustering </em>organizes data in a hierarchical manner so that the hierarchies are represented by a dendrogram.</p></li><li><p id="ad05d9b1f8c14b6397811140d4953750">The data within clusters adhere to distance measures to ensure that dispersion is minimized. <em style="italic">k-</em>Means Clustering technique abides by a number of distance measures but the most popular is the Euclidean Distance</p></li><li><p id="d2cce92077a74a03af8ff59cbd73175a">The main difference between KNN and KMeans is that one is an unsupervised technique (Kmeans) and the other is supervised. <em style="italic">k</em>NN is a supervised classification method that involves labeled data that is used to train a model to accurately predict the class of a new observation according to its closest or neighbor data points. <em style="italic">k</em>Means does not provide a labeled dataset to the model for learning purposes. <em style="italic">k</em>Means will partition the data into a number of clusters.</p></li><li><p id="ebdaa3b88ba644e0a555456f15f6d1ae"> Agglomerative Clustering involves starting the clustering process with one observation forming its own cluster. Clusters are then formed by combining or agglomerating the nearest clusters until there is one cluster left. Essentially, at each step of agglomerating clusters, the clusters with the smallest distance from each other will be combined. </p></li></ul><activity idref="newc7b41a6dc19842928a84ed5bd2b88e19" purpose="checkpoint" /></body></workbook_page>\r\n'