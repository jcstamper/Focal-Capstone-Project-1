b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="da0341efc524427287f5f056a3c2e31c"><head><title>Statistical Inference</title><objref idref="f4d0b27f5b9e41ef9f78810b14467651" /></head><body><p id="c5d8d1ce7f8d46c6a0e039d95328b939"><em style="italic">Statistical Inference </em>is the process of drawing an informed conclusion about an aspect of your entire dataset using statistical methods. Those conclusions are typically drawn using exploratory data analysis or summary statistics. The goal of this process is to use probability theory to make inferences about your data. This is the first step of learning about the attributes of your population from the sample that you have drawn. Understanding statistical inference ensures that you analyze your data properly and eventually draw the right conclusions for decision-making purposes.</p><p id="ab1d614113ca41b58819b6c798e64fba">If you recall from a previous unit, you learned that the objective of your data science project could be to explore the data and gather insights from that exploratory exercise. You can use statistical inference to draw scientific conclusions and test hypotheses. The significance of a sample data set or descriptive statistics is often in question during the EDA process, but using statistical inference techniques can give significance to your conclusions from EDA. Statistical inference techniques are categorized under <em style="italic">Estimation and Hypothesis Testing.</em></p><p id="a98acd597a9749cba0742c0f94b75ec4"><em>Sampling Distribution</em></p><p id="f1a77325818d4ecf97e2f3f16f74714c">Voter preference is a variable that varies among voters. Likewise, the sample proportion voting for a given candidate is a variable. If a sample was randomly drawn from a larger population, the act of <em style="italic">random sampling</em> makes the sample itself a random variable. Before the sample is obtained, its value is unknown, and that value varies from sample to sample. If several random samples of size n=2705 each were selected, a certain predictable amount of variation would occur in the sample proportion values. This distribution is called a <em style="italic">sampling distribution</em>. The sampling distribution of a statistic is the probability distribution that specifies probabilities for the possible values the statistic can take.</p><p id="c41d51b9f500413cac5546ea4a3e8851">Each sample statistic has a sampling distribution. There is a sampling distribution of a sample mean, a sampling distribution of a sample proportion, a sampling distribution of a sample median, and so forth. A sampling distribution is merely a type of probability distribution. A sampling distribution specifies probabilities not for individual observations but for possible values of a statistic computed from the observations. A sampling distribution allows us to calculate, for example, probabilities about the sample proportion of individuals who voted for the Republican in an exit poll. Before the voters are selected for the exit poll, this is a variable. It has a sampling distribution that describes the probabilities of the possible values.</p><p id="d1f8ab7566f143df81d93477e54de72d"><em>Random Sampling</em></p><p id="e577e97b8adc49818a8c1b7028423503">Suppose a student decides to record her commuting times on various days. She selects these days at random from the school year, and her daily commuting time has the cumulative distribution function in Figure 1.</p><image id="af0590464f254b3caa19210e81ce1306" src="../webcontent/image-da0341efc524427287f5f056a3c2e31c-1.png" alt="" style="inline" vertical-align="middle" height="488" width="650"><caption><p id="abebd959a2d644b3bbf9325cec48c780">Figure 1. Cumulative Distribution Function of Commuting Time.</p></caption><popout enable="false"></popout></image><p id="d9055800c7bc4ce3961930da4f250f3a">Because these days were selected at random, knowing the value of the commuting time on one of these randomly selected days provides no information about the commuting time on another of the days. That is because the days were selected at random, and the values of the commuting time on each of the different days are independently distributed random variables.</p><p id="f55d3385bbf94ca1948833b10256b05e">The situation described is an example of the simplest sampling scheme used in statistics, called simple random sampling, in which <em style="italic">n</em> objects are selected at random from a population (the population of commuting days) and each member of the population (each day) is equally likely to be included in the sample.</p><p id="fbe26f98b70648ffa4baa43e941ed0e9">The <em style="italic">n</em> observations in the sample are denoted \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\), where \\(Y_{1}\\) is the first observation, \\(Y_{2}\\) is the second observation, and so forth. In the commuting example, \\(Y_{1}\\) is the commuting time on the first of her <em style="italic">n</em> randomly selected days, and \\(Y_{i}\\) is the commuting time on the \\(i^{th}\\) of her randomly selected days.</p><p id="cdf2ebb41b564e638ec40124d4d131d9">Because the members of the population included in the sample are selected at random, the values of the observations \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\) are themselves random. If different members of the population are chosen, their values of <em style="italic">Y</em> will differ. Thus the act of random sampling means that \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\) can be treated as random variables. Before they are sampled, \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\) can take on many possible values; after they are sampled, a specific value is recorded for each observation.</p><p id="dfb1f851aec5402482319d03d78118e5"><em>I,I.D.</em></p><p id="c037350e112143669641a6cea9be93de">Because \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\) are randomly drawn from the same population, the marginal distribution of \\(Y_{i}\\) is the same for each <em style="italic">i</em> = 1,.., n; this marginal distribution is the distribution of <em style="italic">Y</em> in the population being sampled. When \\(Y_{i}\\) has the same marginal distribution for <em style="italic">i</em> = 1,..., <em style="italic">n</em>, then \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\), are said to be <em>identically distributed</em>.</p><p id="d8a6d74dc8144a6f945c90ac31464303">Under simple random sampling, knowing the value of \\(Y_{1}\\) provides no information about \\(Y_{2}\\), so the conditional distribution of \\(Y_{2}\\) given \\(Y_{1}\\), is the same as the marginal distribution of \\(Y_{2}\\). In other words, under simple random sampling, \\(Y_{1}\\) is distributed independently of \\(Y_{2}\\), \xe2\x80\xa6, \\(Y_{n}\\).</p><p id="f8215d7156a948fb86e11cee991d5bfa">When \\(Y_{1}\\), \xe2\x80\xa6, \\(Y_{n}\\) are drawn from the same distribution and are independently distributed, they are said to be <em>independently and identically distributed</em> (or <em>i,i.d.</em>).</p><p id="e322b65db7804141a3a87b6c172be6ef"><em>Standard Error</em></p><p id="c740af7cab024a32876ca896d521805e">The sample mean, \\(\\bar{y}\\), is a variable because its value varies from sample to sample. In practice, when we analyze data and find \\(\\bar{y}\\), we don&apos;t know how close it falls to the population mean \\(\\mu\\) because we do not know the value of \\(\\mu\\). Using information about the spread of the sampling distribution, though, we can predict how close it falls. For example, the sampling distribution might tell us that with high probability, \\(\\bar{y}\\) falls within 10 units of \\(\\mu\\).</p><p id="abdc78dbf37a49e39e0a384a1ecb3978">For random samples, it fluctuates around the population mean \\(\\mu\\), sometimes being smaller and sometimes being larger. In fact, the mean of the sampling distribution of \\(\\bar{y}\\) equals \\(\\mu\\). If we repeatedly took samples, then, in the long run, the mean of the sample means would equal the population mean \\(\\mu\\). The spread of the sampling distribution of \\(\\bar{y}\\) is described by its standard deviation, which is called the <em style="italic">standard error</em> of \\(\\bar{y}\\). The standard error of \\(\\bar{y}\\) is denoted by \\(\\sigma _{\\bar{y}}\\).</p><p id="f9da699fd84840198de7cd03d6e0467d">For a random sample of size <em style="italic">n</em>, the standard error of \\(\\bar{y}\\) depends on <em style="italic">n</em> and the population standard deviation \\(\\sigma\\) by \\(\\sigma _{\\bar{y}}=\\frac{\\sigma }{\\sqrt{n}}\\).</p><p id="d2fb4494644142949eaf5ddcf81413ac"><em>Confidence Interval</em></p><p id="e5bca99498ec45f1867e7b3bf5514ea9">Because of random sampling error, it is impossible to learn the exact value of the population mean of Y using only the information in a sample. However, it is possible to use data from a random sample to construct a set of values that contains the true population mean \\(\\mu _{y}\\) with a certain prespecified probability. Such a set is called a <em>confidence set</em>, and the prespecified probability that \\(\\mu _{y}\\) is contained in this set is called the <em>confidence level</em>. The confidence set for \\(\\mu _{y}\\) turns out to be all the possible values of the mean between a lower and an upper limit so that the confidence set is an interval, called a <em>confidence interval</em>.</p><p id="e1a1fa8ede2b44bb847f01d8b5cc079a">Consider this example:</p><example id="a95519e5d0ed41878033f78bcfa27a66"><title>Title</title><p id="b6129ab90df54a26805915abc22383c9">Consider that we are measuring the heights of 40 randomly selected male soccer players, our sample mean is 175cm. We calculate the standard deviation of the athletes&apos; heights to be 20cm. Let us calculate the CI.</p><p id="a28a04a714064244a61d0660862dbfd4">n = 40, mean = 175, s = 20.</p><p id="a0cd139314734cc8b1ebb256a2adb0dc">You will decide on the CI to use (95%) and then find the z-value for the selected CI. A 95% CI means that 38 of the 40 confidence intervals will contain the true mean value. </p><p id="f25fd3f8ac644375acc4785f2500fc02">The z-value for 95% CI is 1.960</p><p id="f84dd0d5e7604907ad1347bcb5437c8e">We calculate the 175 \xc2\xb1 1.960 \xc3\x97 20/\\(\\sqrt{40}\\)</p><p id="ca4a014a7e0f42eca4c4ab4b037e541e">175cm \xc2\xb1 6.20cm</p><p id="e853c20bbe6e40bcb4bff92c8c014d71"><em>168.8cm to 181.2cm</em></p></example><p id="ccf15a98e86143c8a52815be3d462efd"><em>Degrees of Freedom</em></p><p id="e56705f43e554e74b778cd4f91d0adca">Usually, the standard deviation for the population of interest is not known. In this case, the standard deviation is replaced by the estimated standard deviation <em style="italic">s</em>, also known as the standard error. Since the standard error is an estimate of the true value of the standard deviation, the sample mean follows the t-distribution with mean and standard deviation. The t-distribution is also described by its degrees of freedom. For a sample of size n, the t-distribution will have n-1 degrees of freedom. The notation for a t-distribution with k degrees of freedom is t(k). As the sample size <em style="italic">n</em> increases, the t-distribution becomes closer to the normal distribution since the standard error approaches the true standard deviation for large <em style="italic">n</em>.</p></body></workbook_page>\n'