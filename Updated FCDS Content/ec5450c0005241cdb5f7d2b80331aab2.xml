b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="ec5450c0005241cdb5f7d2b80331aab2"><head><title>Bias-Variance Decomposition and Trade-off</title><objref idref="fb91d7452cca428ebc8f86c4062f67ff" /></head><body><p id="ae73f0c790f04e1b82e426c77285dbaa">The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relationships between features and target outputs (underfitting).\r</p><p id="d6a550bf0ed742bb90956fda4ab90ecf">The variance is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting).</p><quote>Variance refers to the amount by which <em style="italic">f-hat </em>would change if you estimated it using a different training data set. Bias refers to the error that is introduced by approximating a real life problem, which may be complicated, by a simpler model. E.g Real life does not present scenarios that have a simple linear relationship, this means linear regression will present some bias in the estimate of <em style="italic">f. ~ISLR 34-35</em></quote><p id="fe72e5920d9e461e9b82a098dbeea298">When you decompose bias-variance, you will analyze an algorithm&apos;s ability to predict outcome for data that your model has not seen. The bias-variance tradeoff is encountered while working with some supervised learning techniques. The premise is that your model will adequately learn the training data, and it should properly generalize well to new data. </p><p id="df81b077fecc49758cc8d5c512616409">As seen in the figure below, a supervised learning method that can represent training data well but experiences overfitting is considered a high variance method. A method with high bias will not adequately learn the training data and this leads to underfitting. High variance models are typically more complex and those with high bias tend to be simpler. </p><image id="d02b32d12a6e4ff9aa5c24218dda4ee5" src="../webcontent/High_variane_Low_Bias.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="fc384000c0404af1b7abb2e70c891747"><em style="italic">Bias-Variance Diagram.</em></p></caption><popout enable="false"></popout></image><p id="d99bc3ae27b847f6a12f11ad93c33afa"><em>The Bias-Variance Decomposition</em></p><p id="ed12358367d04cd69c3b2d325e24e28f">Let us look at a very well deconstructed mathematical representation of Bias-Variance by <link href="https://towardsdatascience.com/the-bias-variance-trade-off-explanation-and-demo-8f462f8d6326#:~:text=our%20sample%20set.-,Meaning%20of%20Bias%20and%20Variance,true%20values%20in%20the%20data.&amp;text=This%20will%20usually%20be%20the,the%20inherent%20data%20generating%20function." target="new" internal="false">IBM&apos;s Aditya Prasad</link>:</p><p id="d7cc61208b154473aff6095a7c818cd9">Note that bias and variance of an estimator are mathematically related to each other and also to the performance of the estimator. Let us define an estimator\xe2\x80\x99s error at a test point as the \xe2\x80\x9cexpected\xe2\x80\x9d squared difference between the true value and estimator\xe2\x80\x99s estimate.\r</p><p id="e17d3962ad184a7bbaa12c7f83e77b72">Whenever expected value is referenced, this means the expectation over all the possible models, trained individually over all the possible data samples. For any unseen test point x\xe2\x82\x92, you will have :-\r</p><p id="abb402fa612b4a69a34ff26df727aaaa">Err(x\xe2\x82\x92) = E[(Y \xe2\x88\x92 g(x\xe2\x82\x92))\xc2\xb2 | X = x\xe2\x82\x92]\r</p><p id="ec485511b4484aa8bb15ec2e8ef12615">Refer to f(x\xe2\x82\x92) and g(x\xe2\x82\x92) as f and g respectively and skipping the conditional on X :-\r</p><p id="c15f0f2743b54fb4850e5546c7d5c911">Err(x\xe2\x82\x92) = E[(Y \xe2\x88\x92 g(x\xe2\x82\x92))\xc2\xb2]\r</p><p id="f6d8248eca94495fbc36abe1be1fbce8">= E[(f + \xcf\xb5 \xe2\x88\x92 g)\xc2\xb2]\r</p><p id="b84b3f68a9af4c489be52baa3d74fec0">= E[\xcf\xb5\xc2\xb2] + E[(f \xe2\x88\x92 g)\xc2\xb2] + 2.E[(f \xe2\x88\x92 g)\xcf\xb5]\r</p><p id="b2c1f6b7090149a1a44fe86ebc8278e3">= E[(\xcf\xb5 \xe2\x88\x92 0)\xc2\xb2] + E[(f \xe2\x88\x92 E[g] + E[g] \xe2\x88\x92 g)\xc2\xb2] + 2.E[f\xcf\xb5] \xe2\x88\x92 2.E[g\xcf\xb5]\r</p><p id="de8d9be3a8464b438e96a057beee1e86">= E[(\xcf\xb5 \xe2\x88\x92 E[\xcf\xb5])\xc2\xb2] + E[(f \xe2\x88\x92 E[g] + E[g] \xe2\x88\x92 g)\xc2\xb2] + 0 \xe2\x88\x92 0\r</p><p id="dadf5ef7c1294400865f61beb2f37465">= Var(\xcf\xb5) + E[(g \xe2\x88\x92 E[g])\xc2\xb2] + E[(E[g] \xe2\x88\x92 f)\xc2\xb2] + 2.E[(g \xe2\x88\x92 E[g])(E[g] \xe2\x88\x92 f)]\r</p><p id="e3ebbc835ce2437eb839e2f55116d746">= Var(\xcf\xb5) + Var(g) + Bias(g)\xc2\xb2 + 2.{E[g]\xc2\xb2 \xe2\x88\x92 E[gf] \xe2\x88\x92 E[g]\xc2\xb2 + E[gf]}\r</p><p id="f746f8de940c4629a22613c82bdc687a">= \xcf\x83\xc2\xb2 + Var(g) + Bias(g)\xc2\xb2\r</p><p id="b7803acab79f4d63be40e0b8e01fe570">So, the error of the estimator at an unseen data sample x\xe2\x82\x92 can be decomposed into variance of the noise in the data, bias, and the variance of the estimator. This implies that both bias and variance are the sources of error of an estimator.\r </p><p id="cac1073287b445a083e49ce7add480f4"><em>The Trade-off!</em></p><p id="aa8075cb55c14eabb3e4c0d99c457dae">When bias is increased, variance would be decreased and vice versa, this tells you that they are complementary. It is safe to say, there is a trade-off between both when it comes to the performance of our model. A model will present a high error when there is high bias and also, when there is overfitting or there is high variance and low bias. The model can not generalize to new or unseen data. We want a model that is balanced between bias and variance to ensure error is minimized. </p><p id="e85064777a754c278b1dde3a71f19e18"><em>Reading: </em><link href="http://www.inf.ed.ac.uk/teaching/courses/mlsc/Notes/Lecture4/BiasVariance.pdf" target="new" internal="false">Bias-Variance Tradeoff</link>.</p><image id="a9e4f584084b44c18edd557acfbb3c00" src="../webcontent/Underfitting_etc.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="c2f90ce6d51b4cdcbea00aa53164d081"><em style="italic">Overfitting-Underfitting-Balance</em></p></caption><popout enable="false"></popout></image><p id="c539374d3e534586ad073495ad239d37">As shown in the figure above, an ideal and balanced model is one that has a low bias and low variance. You can work against overfitting (high variance) with dimensionality reduction techniques, this way the model is simplified. Trade-off can be optimized using a technique that will be discussed on the next page, <em style="italic">Cross Validation. </em>The figure below gives you a visual representation of bias-variance with training dataset. </p><image id="e35e5492580747f5bfaf78099096ede4" src="../webcontent/DL_Ng.jpg" alt="" style="inline" vertical-align="middle" height="431" width="800"><caption><p id="fe49370443864c7aaf5bc1cfcc9eff75"><em style="italic">Bias-Variance and Training-Test Data.</em></p><table id="f07d248bde164e99855290d3eb18cd49" summary="" rowstyle="plain"><cite id="ic731287b7a1c404e936e0436c3c865ad" /><caption><p id="efdeff9256e442ffb581371a0a96aa4c" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="d8a682d5dfeb43a897d4ba4d0626b49d">Additional Reading: <link href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html" target="new" internal="false">Bias-Variance Tradeoff</link></p></td></tr></table></caption><popout enable="false"></popout></image><wb:inline idref="newd4ec284a06f44356b8bcf0b30b6994ee" purpose="didigetthis" /></body></workbook_page>\n'