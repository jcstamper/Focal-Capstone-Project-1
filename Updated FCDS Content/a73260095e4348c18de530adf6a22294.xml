b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="a73260095e4348c18de530adf6a22294"><head><title>Introduction to Deep Learning</title></head><body><section id="aaf09080a7644c6bb9157c3ae1a0bc7a"><title>Introduction</title><body><image id="c79b4fb4f96b484a90e38e724a1737ad" src="../webcontent/Screen_Shot_2022-07-14_at_91923_pm.png" alt="" style="inline" vertical-align="middle" height="432" width="650"><caption><p id="ee076263be6b4c17a83a256fbe8dd053">A few samples of completely fake faces generated by a generative adversarial network (GAN). Source: ThisPersonDoesNotExist.com</p></caption><popout enable="false"></popout></image><p id="cf4aedf81c17412c85ebc1a238427678">Deep learning applications have been widespread in recent years with the increasing availability of data and compute resources. Deep learning is an area of machine learning that draws inspiration from how the human brain functions as a model of computation. Like most machine learning algorithms, deep learning also involves a transformation of data from an input to an output: for example, using speech samples as inputs to predict the speaker or taking some text in one language and translating the text into another language. As the problem becomes more and more complex, classical machine learning approaches fail to adequately learn such transformation or mapping of input to output from the data. Deep learning algorithms overcome this using many successive transformations of input data, thus the deep in deep learning.</p><p id="b7176cc14fee4543b826f861812c3ce9">At a very high-level abstraction, we can view neurons as aggregating signals from their inputs and sending processed signals to their outputs. Such input signals can be visual signals detected by the retina or acoustic signals detected by the ear. Again at an abstract level, the neuron can be considered computing a weighted summation of the inputs weighing each input by a synaptic weight and doing a final non-linear transformation on the sum.</p><p id="f11a4ae74fba4dd0a0449b21bcff74b0">Inspired by this, neural networks consist of neurons that are connected to each other via weights. Each neuron receives weighted inputs from neurons in the previous layer, these are summed and passed through a nonlinearity function, commonly called the <em style="italic">activation function</em>, and the resulting output is passed on to neurons in the next layer, again, connected with some weight. The <em style="italic">deep</em> nature of deep neural networks refers to having a very large number of layers of such connected neurons.</p><p id="e36f12b3761f4d24aaa56079b2f870f2">In this module, we discuss some of the key concepts in deep learning.</p></body></section><wb:inline idref="mooclet_activity" purpose="didigetthis" /></body></workbook_page>\n'