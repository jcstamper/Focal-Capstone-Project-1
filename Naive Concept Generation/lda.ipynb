{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: the requirements and to can\n",
      "Topic 2: the and requirements can to\n",
      "Topic 3: the requirements and to can\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from lxml import etree\n",
    "import string\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "# Function to parse XML and extract textual content\n",
    "def extract_text_from_xml(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        xml_bytes = f.read()\n",
    "    xml_str = xml_bytes.decode('UTF-8')\n",
    "    return xml_str\n",
    "\n",
    "# Function to preprocess the text\n",
    "def preprocess(text):\n",
    "    # Tokenize, remove punctuation, convert to lowercase\n",
    "    tokens = [word.strip(string.punctuation).lower() for word in text.split()]\n",
    "    # Remove words that are only 1 character\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "    return tokens\n",
    "\n",
    "# Function to conduct LDA concept extraction\n",
    "def extract_lda_concepts(text, num_topics=3, num_words=5):\n",
    "    # Tokenize the input text\n",
    "    tokenized_text = preprocess(text)\n",
    "    \n",
    "    # Create a dictionary and corpus required for LDA\n",
    "    dictionary = corpora.Dictionary([tokenized_text])\n",
    "    corpus = [dictionary.doc2bow(tokenized_text)]\n",
    "\n",
    "    # Use the LDA model from Gensim\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "    \n",
    "    # Extract the top topics\n",
    "    topics = lda_model.top_topics(corpus)\n",
    "    \n",
    "    # Extract the key concepts (words) for each topic\n",
    "    concepts = [[item[1] for item in topic[0][:num_words]] for topic in topics]\n",
    "    return concepts\n",
    "\n",
    "\n",
    "xml_file_path = 'a3e60ec52fd1485daf95a85dac31bbff.xml'\n",
    "xml_text = extract_text_from_xml(xml_file_path)\n",
    "\n",
    "concepts = extract_lda_concepts(xml_text)\n",
    "\n",
    "for i, topic in enumerate(concepts, 1):\n",
    "    print(f\"Topic {i}: {' '.join(topic)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
