b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="e8e5d28852f643df950ffdaabd47bb7c"><head><title>113-Common Language Processing Tasks</title></head><body><section id="bd0bd3a36a854c8db785abafe8ab3fc6"><title>Common Language Processing Tasks</title><body><p id="ec417b04f1944dd2ab80dd370b5478dc"> </p></body></section><section id="f2f874979616468cb3f2e2868357b556"><title>Learning Objectives</title><body><p id="e1dd5a8d85a94a67a61c0e204e335c79"> </p></body></section><ol id="c562fc29fd6345a5b980859085ad28f6"><li><p id="e5f1b1f4ce9e4c9bae6813550bc83049">Understand the typical tasks that are employed in natural language processing pipelines,  including tokenization, stemming, morphological analysis, part-of-speech (POS) tagging, named-entity recognition, and parsing</p></li></ol><p id="b8ec4b2a3e0148ac8d2c2a27dcc53fe0"><em style="italic">Language data</em> could refer to data from multiple sources like speech, image, video, and text data. Thus, language processing tasks applied to preprocess this largely depend on the form of data and its source. The rest  of this module focuses primarily on text data as the input and output.</p><p id="cfd8de9f3de84df29a8aafa6110fc94e"><em>1. Tokenization</em></p><p id="c9a25338c10746d99df243f16cef5f3c">Tokenization is the process of splitting an input sentence, paragraph, or an entire document into a list of tokens, where each token is a linguistic unit in speech or writing. For example, the string sentence &quot;Today is a good day.&quot;, when tokenized, would yield [&apos;Today&apos;, &apos;is&apos;, &apos;a&apos;, &apos;good&apos;, &apos;day&apos;,  &apos;. &apos;]. In general, tokenization may split independent punctuation but may need keep some punctuation if those are deemed to be part of a token. For instance, in \xe2\x80\x9cDr. Smith\xe2\x80\xa6\xe2\x80\x9d the token is \xe2\x80\x9cDr.\xe2\x80\x9d and not \xe2\x80\x9cDr\xe2\x80\x9d.  In English, sometimes tokenizers choose to split contracted words e.g.  \xe2\x80\x9cJohn\xe2\x80\x99s\xe2\x80\x9d is split as John and \xe2\x80\x9c\xe2\x80\x99s\xe2\x80\x99\xe2\x80\x9d.  The downstream task in the pipeline may choose the interpret the punctuation or ignore them. </p><p id="c76ce92e5a3c4335b3464cc5f8085ce2">Text in other languages may need to go through more complex operations during tokenization depending on their writing systems. For instance, Chinese is typically written without any spaces between words and a sequence of characters needs to be split into individual words before further processing, using a process known as word segmentation.  On the other hand, Arabic text is written without the short vowels, and for certain downstream applications, one may need to add these through a process known as <em style="italic">diacritization</em>.</p><p id="d5ceff8df8214ecca3b8bc763a890574"><em>2. Stop word removal</em></p><p id="ae99f6defd974c979093504a8269b1fc">Stop words are words that belong typically to a closed class of words in the vocabulary of a language that themselves do not carry meaning but function in a sentence to get the syntactic relations right. Typical stop word lists in English words such as \xe2\x80\x9ca\xe2\x80\x9d, \xe2\x80\x9cthe\xe2\x80\x9d \xe2\x80\x9cin\xe2\x80\x9d, \xe2\x80\x9con\xe2\x80\x9d, etc. They are also rather frequently used words by nature and usually interfere with some downstream tasks. For example, applications such as document classification rarely benefit from such words. Thus once tokenization is done, one may need to remove all such words in a process called stop word remove.  This can be done by sorting the vocabulary of the text collection by frequency, and defining the top 10\xe2\x80\x93100 vocabulary entries as stop words, or alternatively by using one of the many predefined stop word lists available online. </p><p id="f1e85a413fbf4c8bb50f2e523b47ca25" /><p id="b9b3635cd7cf491fa9dcd0302510fc08"><em>3. Morphological Analysis, Lemmatization,  Stemming</em></p><p id="ec96c46b6b494d6e9f485d5b6331d707">Many language processing tasks, such as spelling checking and correction, parsing, and surface generation, either need to extract and process the information encoded in the words, or to synthesize words from available semantic and syntactic information. This is especially necessary for languages with rich(er) morphology, such as German, Hungarian, Finnish, Turkish, and Arabic, to name a few.  </p><p id="b53cf85063d441a2bf6e8ef034ef1d7c">Morphological analysis typically segments words into their constituent morphemes taking into account any orthographical variations in orthography dues to morphology. For instance, while processing a word such as \xe2\x80\x9cstopped\xe2\x80\x9d, a morphological analyzer would need to know about the root words \xe2\x80\x9cstop\xe2\x80\x9d and the suffix \xe2\x80\x9c-ing\xe2\x80\x9d,  and that under certain phonological circumstances, certain consonants at the end of the root words need top duplicate when the following suffix starts with a vowel (cf. \xe2\x80\x9cstops\xe2\x80\x9d).  It would then represent this word with something like stop+Verb+Past. Similarly, a word like \xe2\x80\x9ceasiest\xe2\x80\x9d would be segmented as \xe2\x80\x9ceasy+est\xe2\x80\x9d using an orthographical rule in English that changes a stem final \xe2\x80\x9c-y\xe2\x80\x9d to an \xe2\x80\x9c-i\xe2\x80\x9d in orthography as there is no difference in pronunciation. The output representation would be easy+Adj+Super. Other more mundane mappings include handling special cases such as generating \xe2\x80\x9cgo\xe2\x80\x9d as the root words for words such as \xe2\x80\x9cwent\xe2\x80\x9d or \xe2\x80\x9cgone\xe2\x80\x9d.</p><p id="b26f59787e4f4ebfbbb204e93b56e706">Morphologically complex languages have many other orthographical processes usually root in phonology, such as vowel harmony, consonant and vowel insertions or deletions, or duplications. Morphological analyzers would have to take all of these into account in order to analyze words.</p><p id="ead8259f24ee425fb3d272e4098671b1">The state-of-the-art tools for morphological analysis rely on the well-established computational formalism of finite state transducers.  There are numerous toolkits that take in a description of the root and affix lexicon of a language and compile these into large finite state transducers which take in a word in a language and generate representations for all possible morphological interpretations of a word. A side benefit of finite state transducers is that they a bidirectional and given a morphological analysis, they can produce the actual word.</p><p id="d34d8d9513d5492fa36a886142f6d300">When full morphological information is not necessary or not available a \xe2\x80\x9clighter\xe2\x80\x9d operation called  <em style="italic">stemming</em> can be used. Stemming refers to heuristically stripping off known word endings to get to a base word (that itself may not be an actual word) that can be used as a proxy for the word, especially in tasks where morphological details are necessarily needed. Stemming in English for instance maps  &quot;change,&quot; &quot;changing,&quot; &quot;changes&quot; to &quot;chang.&quot; <link href="https://tartarus.org/martin/PorterStemmer/" target="new" internal="false">Porter Stemmer</link> is a popular algorithm used for stemming for English. Stemming has limited applicability in languages whose morphology is more complex than English.</p><p id="fbc78a8094cb47f6be6f2e7c7eb600d6">A slightly more accurate version of stemming is called <em style="italic">lemmatization</em> which does a more informed version of stemming using an additional lexicon and predicts the actual stem of the word or its lemma \xe2\x80\x93 the standardized form to look the word up in a dictionary. In the examples above it should return \xe2\x80\x9cchange\xe2\x80\x9d as the lemma.</p><p id="ea75292c55a94f528a9ef1a615b1e523">Of course, a full morphological analyzer would do lemmatization in addition to interpreting the affixes and would be a tool of choice for languages with complex morphology.</p><p id="d98fc12b4a5b4a60be5b7fcba346bcd4" /><p id="b6e203cf3ed5463fb61a12fe6775ef24" /><p id="e95691711f154a39a3a8bf47fee911e0"><em>5. Part-of-Speech Tagging</em></p><p id="a59f2c0e96c14ff1884757a5b785bbc8">Morphological analyzers typically assign words a morphological interpretation in addition to a lemma. Such information includes the category of a word\xe2\x80\x99s morphological interpretation and any additional syntactically (or semantically)  relevant information such as whether the word is a common or a proper noun, whether it is a singular or plural noun, or what the tense of a verb is, etc. </p><p id="cfef39306812464d96dd1c4ae8faaae8" /></body></workbook_page>\n'