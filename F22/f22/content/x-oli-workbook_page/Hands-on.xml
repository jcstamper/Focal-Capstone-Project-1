b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="Hands-on"><head><title>[Additional Resource] Hands-on: Data Versioning + Code Versioning with DVC, GIT, and AWS\xc2\xa0S3</title></head><body><p id="cdb4eb34a1544c77ae83105d43f95028">AI projects are data intensive. Data can be </p><ul id="e9e6b8e6c7db461ea5ca7e4d4b9198c9"><li><p id="b346a664ea174314a385baef6869744f">public (from government websites and open data)</p></li><li><p id="b7557e386c9f4f0db2f47c6cf8749726">paid (from the marketplace, brokers, and other services)</p></li><li><p id="fd02c47a9f2849da8053e7d6c28663af">gathered (from customers using the product platform)</p></li><li><p id="a5fa996547024c2c8c386908ea22c3d0">owned (from employees like annotators who manually create data)</p></li></ul><p id="d6b98ec741de4eb8aa6859a1750bdeef">We get the data mentioned above periodically to build models. Therefore, we need to analyze the quality of data and model performance every time new data is available.</p><p id="ae6cc71f163e4992b9599885d7d7c939">It is critical to track data efficiently. For example, let&apos;s say we are working with a customer who provides us with newly collected data weekly. Let us also assume we found a drift in data distribution, and we want to roll back to the model version and keep tuning the model from that checkpoint. The previous model can be reproduced by model parameters (weights) and hyper-parameters. However, we might want to reproduce the model using another library that optimizes the performance, which requires retraining or using old data to build another model. Therefore, we need a tool to version model weights and training data efficiently.</p><p id="e95f078ec3024212a90e21516a93e441">Sometimes, after our initial engagement, we return to old projects based on customer requirements. We might want to reproduce the previous models built by other developers to deliver predictions to customers. However, the performance of models depends on the data used to train the model. Hence, data needs to be tracked periodically.</p><p id="fa7a9fb2c89b43b0a06145b6f8bb1430"><em>Why are traditional code versioning tools inefficient in tracking data?</em></p><p id="f6965a167fb9402e886571205d47f754">The Git system (e.g., in Assembla / Atlassian) can only track comparatively small files (e.g., the source code) used for the project. Because git contains a complete history of file changes, disk and memory requirements will grow significantly if we commit data files. Hence, DVC (Data Versioning Control) aims to bring git to projects that use a lot of data and helps to track and version data efficiently. DVC is also easy to learn as it runs on top of git and uses the same git vocabulary. </p><p id="b81cffa3450a44e7af5d0f010e85ab64">git-lfs can be a solution for data versioning using pointers and remote storage. However, one of the main advantages of DVC over git-lfs is it doesn&apos;t require installing a dedicated server, and it can be used with cloud storage like AWS S3, GCP, Azure, etc. We can also assign tags for each data file version, which allows us to track necessary metadata, such as who gave us the data and when we got it.</p><p id="c2be37b544bb44ec9c00f5c90b5cc1e0"><em>Other advantages of Data Tracking efficiently help in:</em></p><ul id="e62aa057d3c84b3d9d635b9f15011d8b"><li><p id="dadda75159024ae69ef0b3abc0af4d09">Managing the Data Quality</p></li><li><p id="fbd29bb61bad441584a1ee75d5919781">Automating testing and deployment</p></li><li><p id="ded710a2e99e46039a1306cb5ff01987">Easy integration with MLflow, which helps in tracking experiments</p></li></ul><wb:inline idref="mooclet_activity" purpose="didigetthis" /><p id="f9865985b27b406b93f69ed65591a421"><em>Getting started with creating a repo and pushing code to Assembla and data to S3 (using DVC) </em></p><p id="d704785c346f4b909a4f978b1d542fb3">1. Install <link href="https://docs.anaconda.com/anaconda/install/" target="new" internal="false">Anaconda</link></p><p id="e06cb860203245888b177ae3870ab6a1">2. Define the project folder structure</p><ol id="cb86a2c00e394b0d96c869db97ff4f4c"><li><p id="c105d487cdc54a5e9e3dfad5a805f756">Example</p><image id="a1e28b68c9dc48c8abd3f18a7e6c639b" src="../webcontent/image-Hands-on-1.png" alt="" style="inline" vertical-align="middle" height="533" width="300"><caption><p id="bce505670cfa4e5aaa630e02ba1468b1" /></caption><popout enable="false"></popout></image></li><li><p id="aaf330fd50044ea5a41576db0d269778">Clone the above sample repo <link href="https://github.com/kaushikData/AI_template_directory" target="new" internal="false">here</link>.</p></li></ol><p id="ea57a33a4d1e431280cb01f614e30a60">3. Create a virtual environment for DVC in the respective project folder and activate it</p><codeblock id="ea978d0591034fb9a605118da78f1b34" syntax="text" highlight="" number="false" start=""><![CDATA[conda create -n mypython3 python=3.8\nconda activate mypython3]]></codeblock><p id="ac754b16567f4ff4a0a6cc146c515b1d">4. Install dvc</p><codeblock id="fd964a08b92e4f9f9931d2f8f791d0ce" syntax="text" highlight="" number="false" start=""><![CDATA[pip install dvc]]></codeblock><p id="fd312c4df8714fa0976947eedfc54213">5. Install boto3 for pushing data to AWS S3</p><codeblock id="cfd7eea5063c490ea505235a5d4e6304" syntax="text" highlight="" number="false" start=""><![CDATA[pip install boto3]]></codeblock><p id="eff4079f98934ed3a564bfaf7691a25d">6. Install dvc[s3]</p><codeblock id="e27df87d578c4203b4bdffd5c153d2f7" syntax="text" highlight="" number="false" start=""><![CDATA[pip install dvc[s3]]]></codeblock><p id="fceb1f218ae547e2a61f8f39fb665723">7. Initiate DVC which creates .dvc/.gitignore, .dvc/config and .dvcignore files</p><codeblock id="d7bb3deaca0644df945eec9efd9f5343" syntax="text" highlight="" number="false" start=""><![CDATA[dvc init]]></codeblock><p id="cea3a1889d584fd280eed54b5523f22e">8. Commit the above dvc files</p><codeblock id="b816d81cc23e421284b02ffe771fddfc" syntax="text" highlight="" number="false" start=""><![CDATA[git commit -m "Initializing DVC - First Commit"]]></codeblock><p id="a97da53da2c84fbabdcf35b25b179a89">9. Avoid tracking the data folder for git</p><codeblock id="bfa2a19d1e7042f3863dd3e9a05b8363" syntax="text" highlight="" number="false" start=""><![CDATA[rm data/**/.gitkeep\ngit rm --cached -r data\ngit commit -m "stop tracking data"]]></codeblock><p id="df952d7b736a41d88989b5e519333060">10. DVC tracks the data files by adding a data folder to the DVC cache. It prevents adding to GIT by implicitly adding the data folder to .gitignore.</p><codeblock id="c2ad53b82bcb4a27897f79a78c15c576" syntax="text" highlight="" number="false" start=""><![CDATA[dvc add data]]></codeblock><p id="ab04112aac1e4b1eb33c9524291ae263">11. Git add and commit data.dvc</p><codeblock id="eed5344a3ca24c69b89eec732ba15771" syntax="text" highlight="" number="false" start=""><![CDATA[git add data.dvc\ngit commit -m "add data"]]></codeblock><p id="e1086ebde14c49beb109bf429f33ecc5">12. <link href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html" target="new" internal="false">Create a bucket on S3</link></p><p id="fe5ca9dc37df4191838846093a173929">13. DVC Remote Add\xe2\x80\x8a-\xe2\x80\x8acreates a remote section in DVC&apos;s config file</p><codeblock id="f7c2961ade7749ee9612535a88d96011" syntax="text" highlight="" number="false" start=""><![CDATA[dvc remote add -d remote s3://yourBucketName/folderName]]></codeblock><p id="c6729bb05a9b4eec971cbf732fb00f14">14. Set AWS credentials</p><codeblock id="f6c259d22ee24e9a80a5fa1768294681" syntax="text" highlight="" number="false" start=""><![CDATA[dvc remote modify remote access_key_id AWS_ACCESS_KEY_ID\ndvc remote modify remote secret_access_key AWS_SECRET_ACCESS_KEY]]></codeblock><p id="d43dbd2c3c3b44f4b8b78d0080b88dd4">15. Push the data folder to S3</p><codeblock id="b7c41bf507b74340ba63e17020c78d0d" syntax="text" highlight="" number="false" start=""><![CDATA[dvc push]]></codeblock><p id="f91bc8e319ac491bb35ee758f1bd9062">16. Remove AWS credential information in .dvc/config before pushing to git</p><p id="b8bf45437ace45069b1d22a6305ac3c3">17. Push the updates to git</p><codeblock id="b0c3cc5b90bc456d9c935c9bed42943a" syntax="text" highlight="" number="false" start=""><![CDATA[git push origin master]]></codeblock><p id="f8083e3482154781b4f8697e8605851a">Kudos, you completed the hands-on Data Versioning tutorial with DVC and AWS S3. Now you have the version history of the data and can revisit the respective files in the future. </p></body></workbook_page>\n'