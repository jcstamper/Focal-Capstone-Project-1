b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE assessment PUBLIC "-//Carnegie Mellon University//DTD Assessment MathML 2.4//EN" "http://oli.web.cmu.edu/dtd/oli_assessment_mathml_2_4.dtd"><assessment xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" id="newf33797d9a8a44d10b9aee4a8c0bad202" recommended_attempts="1" max_attempts="1"><title>Quiz 3</title><page id="f0b7239f05b1411fb298f51c34e61374"><title>Assessment Page Title</title><multiple_choice id="eb6cb3d4f469469c8ea062f9433bb338" grading="automatic" select="single"><body><p id="f7ee1f64d62145f3870e88b9e07917ca">You\xe2\x80\x99re working on a large-scale deep learning pipeline, and are trying to compare the results of over 10 different deep learning configurations on a large dataset to find which configurations you want to explore next. What is the best way of doing so?</p></body><input shuffle="true" id="a634d02b5dc7457c95cd1b6aa7e7c95f" labels="false"><choice value="e475ea2322434158ad4abb42cffe081c">You run a Paired McNemar test on all pairs of configurations. With that information, you can figure out what configurations are doing consistently better than each other, and run more tests accordingly.</choice><choice value="bde44b6c80a641f3b2d9c2d56729c6b4">You simply rank the k-fold cross-validation scores of each model and pick the best three results to explore next. As this replicates the process of evolutionary search, it\xe2\x80\x99s likely to give you a good suggestion for future exploration.</choice><choice value="eca4a858e4ca40d1877e65c061559be5">You run LOOCV (Leave One Out Cross Validation) on each configuration, and use their results to judge which is best. You remember that this approach allows you to best estimate test-dataset performance from a statistical point of view.</choice><choice value="ed465a67f24d41c481d6c7f10cce9165">You perform a Friedman test on the relative ranks between algorithms, and then use a predetermined baseline to distinguish which algorithms are suitable for further experimentation, and which ones are not. </choice></input><part id="b1c0a0100ed94fd8836989253e942de1"><response match="e475ea2322434158ad4abb42cffe081c" score="0"><feedback><p id="f021e80b66fd4f568a0245001cb8b00a">Incorrect. Remember that performing an all-pairs set of configurations can lead to \xe2\x80\x9cp-hacking\xe2\x80\x9d, and might not lead to you selecting the best algorithm.</p></feedback></response><response match="bde44b6c80a641f3b2d9c2d56729c6b4" score="0"><feedback><p id="deb833f36fc34fe68c2dd824ecbc382e">Incorrect. While this approach is the simplest, it tells us nothing about the significance of the differences between each of the models, which can lead to us picking bad models. If there are 4 models, each with accuracies within 0.01% of each other, and the rest are much worse off, we should explore all 4 of them.</p></feedback></response><response match="eca4a858e4ca40d1877e65c061559be5" score="0"><feedback><p id="a45ec142f854414c8aff1d9f32cf7581">Incorrect. Recall that we have a large dataset. Running LOOCV on any dataset larger than even a thousand data points could take months to do.</p></feedback></response><response match="ed465a67f24d41c481d6c7f10cce9165" score="10"><feedback><p id="ff2b7c40714341759c465aded1e6ebe2">Correct. The Friedman test, when combined with the associated post hoc tests, should allow you to distinguish between promising and non-promising groups accordingly. </p></feedback></response></part></multiple_choice></page><page id="ba7549e1ec26485386525e972eb14f2b"><title>Assessment Page Title</title><multiple_choice id="d04fe70a64f94d4884c180a5d228a6eb" grading="automatic" select="single"><body><p id="e9e658cdfb8b431c95fdd3dfadc9645c">Which of the followings is not an example of feature engineering?</p></body><input shuffle="true" id="c198f68f0ae347e38f8849d82a941348" labels="false"><choice value="c4f841b400ff45b8a9b1042d432f926b">Convert an input degree in Fahrenheit unit to Celsius unit.</choice><choice value="db0250d74e56483cb4786f82e24bbdfc">Conversion of an input currency in euros to dollars.</choice><choice value="bfd035769e3d43fc9ee02744c6655c70">Conversion of an input weight in pounds to kilograms.</choice><choice value="b5a10f9252dd462288787832f4c217c0">Translate an input text from English to French.</choice><choice value="a6ef168f311a49e5835ba298a73a5e66">Convert an input length of feet to inches.</choice></input><part id="bc2d810ba86f409a88fc7efe2331db34"><response match="c4f841b400ff45b8a9b1042d432f926b" score="0"><feedback><p id="a92deb240db1475ca0b845db92b7319f">Incorrect. Celsius unit is a numerical output feature.</p></feedback></response><response match="db0250d74e56483cb4786f82e24bbdfc" score="0"><feedback><p id="ed6e0bcf344247f8a63b18ed22561503">Incorrect. Dollars is a numerical output feature.</p></feedback></response><response match="bfd035769e3d43fc9ee02744c6655c70" score="0"><feedback><p id="cee92c3962f44ed9a9aeddbce3d6fc17">Incorrect. Kilograms is a numerical output feature.</p></feedback></response><response match="b5a10f9252dd462288787832f4c217c0" score="10"><feedback><p id="f81d09f8598a477a83e887fc66d8f62f">Correct. Feature engineering must output numerical features. Translation to French doesn\xe2\x80\x99t output numerical features.</p></feedback></response><response match="a6ef168f311a49e5835ba298a73a5e66" score="0"><feedback><p id="f184a724e2d447299a8f748fcd999feb">Incorrect. Inches is a numerical output feature.</p></feedback></response></part></multiple_choice></page><page id="fc69f386dab34538997a02ebfcde927a"><title>Assessment Page Title</title><multiple_choice id="ba944f0e57f549a8a086f5ac046320bc" grading="automatic" select="single"><body><p id="c5af6dadfd014f0d87d9863805bea56b">During exploratory data analysis, Jack found that the number of sunglasses sold is positively correlated with the number of drowning victims. What may explain the correlation between these two variables? </p></body><input shuffle="true" id="e90431fc223a4ff5b125ade4604e6963" labels="false"><choice value="e3653f575cd542268572b15324bf2bf8">Buying sunglasses leads to a higher risk of drowning.</choice><choice value="bc92ab5f837b48abafd82bf166e4feb3">When people buy sunglasses, they are less likely to go swimming and, therefore, less likely to drown.</choice><choice value="dbee30013d7843828ed4ccee94c2f116">When the number of drowning victims increases, companies tend to decrease sunglasses prices, leading to higher sales.</choice><choice value="bd35ee88d7314a04802f435c638f14e6">Sunglass sales increase in the summer or when it gets sunny. During this time, people also tend to go swimming more, so the number of drowning victims increases. </choice><choice value="f24cdcc7ab8e4f1293a336fe49a12c50">This correlation is only due to random noise.</choice></input><part id="a5c173fad503422da01cb4b28ebe8a3d"><response match="e3653f575cd542268572b15324bf2bf8" score="0"><feedback><p id="fb71f89179fa4acaaa481a73ab99e38e">Incorrect. This statement implies a non-existent causal relationship between buying sunglasses and drowning.</p></feedback></response><response match="bc92ab5f837b48abafd82bf166e4feb3" score="0"><feedback><p id="a53c1e7dfc5d4477af318bcb3b71cb03">Incorrect. This statement is claiming a negative correlation between buying sunglasses and drowning; however, the correlation Jack discovered was positive.</p></feedback></response><response match="dbee30013d7843828ed4ccee94c2f116" score="0"><feedback><p id="f3d89de016c3438f9fe550eb9f0a19d9">Incorrect. There is no evidence that sunglasses prices are calibrated based on the number of drowning victims.</p></feedback></response><response match="bd35ee88d7314a04802f435c638f14e6" score="10"><feedback><p id="fc0d100c56a2475c92808a1449a23b13">Correct. The hot weather can be a factor that leads to the increase/decrease in both sunglasses sales and the number of drowning victims.</p></feedback></response><response match="f24cdcc7ab8e4f1293a336fe49a12c50" score="0"><feedback><p id="ae54fe03ca794e8ea89a53c9fcabe5c6">Incorrect. The hot weather can be a factor that leads to the increase/decrease in both sunglasses sales and the number of drowning victims.</p></feedback></response></part></multiple_choice></page><page id="cc2866ec3f0f4c73a39a5791a79f93c1"><title>Assessment Page Title</title><multiple_choice id="a8190485f6d946cc9bbb735183d30197" grading="automatic" select="multiple"><body><p id="f0c88013bd854eba9acb775d38403f0e">Which of the following is (are) not true about a sampling distribution?</p></body><input shuffle="true" id="f3874b550a5c4f0ba2cdffa14147b208" labels="false"><choice value="A">Provides information about individual observations from the population.</choice><choice value="B">It can illustrate the probability distribution of the population proportion.</choice><choice value="C">It can illustrate the probability distribution of the sample median.</choice><choice value="D">Allows us to know the population parameters with certainty.</choice><choice value="E">Shows the probability for each possible value of the sample proportion.</choice></input><part id="cc979f2f14f94f1e8542fe116a9e4a30"><response match="A,B,D" score="10"><feedback><p id="b71f3604d82e4ed68322e2948b4abb06">Correct.</p></feedback></response><response match="B,D" score="7"><feedback><p id="a3430db8adeb4686bf3777a47e86c808">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,D" score="7"><feedback><p id="d5efa90fdd074ca88f27a6ae2c46ca79">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B" score="7"><feedback><p id="ecbfca5ef820494cb5acf20c345ecdc7">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A" score="4"><feedback><p id="cb1f6313d0354f63a2a12573c509a28e">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B" score="4"><feedback><p id="f25c29770c964456a475bb304390b26a">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="D" score="4"><feedback><p id="c9a49eba081e4c809d37e838aee43114">Partially correct. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="cc5eb229b7d142edab14c8bc48e9b436">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="f9d7f8c6e0b94977939e83e371fae856">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="e62d0747417748fc8251f41f5d39bf82">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="fd8c7dcfc75d43aca20adfe0afe326f5">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="bbdd99e2dcc34d73b0c9134cf7febdd6">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="e141f48e16a347e784148ce302bb82d5">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,C" name="AUTOGEN_{A,C}" score="0"><feedback><p id="f3dd48d0abec4c6ea32ac37ef71561ba">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="bb8cdb66f7fd4ac4aa814def45d27b6a">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="d0531bd7354845b0a82900229d13230c">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,C,E" name="AUTOGEN_{A,C,E}" score="0"><feedback><p id="acbac23df41a4bad94bd6cd29a3822ec">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="e95394ac97274290bce7e9cf39f4f5e5">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="A,E" name="AUTOGEN_{A,E}" score="0"><feedback><p id="be2f8cf859d7480aa09bbb012eca7263">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,C" name="AUTOGEN_{B,C}" score="0"><feedback><p id="ab3249fe63834c8589e0285f9336d2d5">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="acd89004d8d047b98b5c1a7253abfdce">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="faa5d492ab05462b83df4d802b5791b6">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="c547a52514d74f1ebde184991227c0e3">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="a9f5c037f7444d69b1103eaf69dc3a08">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="B,E" name="AUTOGEN_{B,E}" score="0"><feedback><p id="f4589403c0864978a6232675f7e9f515">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="C" name="AUTOGEN_{C}" score="0"><feedback><p id="a11f429a9c5042ad97d1a9cb27e9fbb6">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="C,D" name="AUTOGEN_{C,D}" score="0"><feedback><p id="b58fce1771b940668694345f5553677a">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="cad7ad3915834da190fed7119f08bf4c">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="C,E" name="AUTOGEN_{C,E}" score="0"><feedback><p id="b247ffd6bd354665962191e1ade3b2dd">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="D,E" name="AUTOGEN_{D,E}" score="0"><feedback><p id="e73f99d2b4be408296d024bab269e0b1">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response><response match="E" name="AUTOGEN_{E}" score="0"><feedback><p id="c05955a7896b48c6b1cb58893cb79f2b">Incorrect. A sampling distribution is simply a type of probability distribution. Each sample statistic has a sampling distribution. This includes sample median and proportion. \xe2\x80\x9cProbability for each possible value\xe2\x80\x9d merely means \xe2\x80\x9cprobability distribution.\xe2\x80\x9d</p></feedback></response></part></multiple_choice></page><page id="d9b3925a41714b4cab8fa3b5bb5d8fce"><title>Assessment Page Title</title><multiple_choice id="eba55d0b2d524870a66c6415e9c6b20b" grading="automatic" select="single"><body><p id="fd14565085de4fa6958315428446634f">During the exploratory data analysis process, you will need to evaluate your data for outliers. Assume you have the following set of data: 4, 7, 8, 10, 6, 17, 12, 8, 14, 1, 3, 7, 17.</p><p id="fadf45a1cffa479c82147cfee3bc9313">Which option below is the IQR and Outlier:</p></body><input shuffle="true" id="c36b94277a9c49d58b0642446ffa4a6c" labels="false"><choice value="d5db850f2cfb4afea208d96fff3da4d4">IQR = 6, Outliers = None</choice><choice value="cba2ec44cad74e13858621e8f2d980ce">IQR = 10, Outliers = 4.</choice><choice value="b3ca264ed4b04e3fb8a2c92dbbc7854e">IQR = 5, Outliers = 12.</choice><choice value="d6fd8edadf4143d1ac0bd69f6c1398dc">IQR = 7, Outliers = 17.</choice><choice value="b37e584dcb9e4f54a1e30f7e1ce446e5">IQR = 8, Outliers = None.</choice></input><part id="d4b532fbc8674c34b27f8c00862e905d"><response match="d5db850f2cfb4afea208d96fff3da4d4" score="0"><feedback><p id="b462f3a77e564b0583b2026efa51a495">Incorrect. 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 14, 17, 17. IQR = Q3 - Q1 = 13 - 5 = 8. No outlier.</p></feedback></response><response match="cba2ec44cad74e13858621e8f2d980ce" score="0"><feedback><p id="e2bc617fd5694aca841f2ba95eae162a">Incorrect. 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 14, 17, 17. IQR = Q3 - Q1 = 13 - 5 = 8. No outlier.</p></feedback></response><response match="b3ca264ed4b04e3fb8a2c92dbbc7854e" score="0"><feedback><p id="f1dfa6267bb7475bb9674726c7468ed1">Incorrect. 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 14, 17, 17. IQR = Q3 - Q1 = 13 - 5 = 8. No outlier.</p></feedback></response><response match="d6fd8edadf4143d1ac0bd69f6c1398dc" score="0"><feedback><p id="b812a98442fe475d97be2b959a4e1cfe">Incorrect. 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 14, 17, 17. IQR = Q3 - Q1 = 13 - 5 = 8. No outlier.</p></feedback></response><response match="b37e584dcb9e4f54a1e30f7e1ce446e5" score="10"><feedback><p id="d0aa323a16304a5ebde8f5f6cd339a6b">Correct. 1, 3, 4, 6, 7, 7, 8, 8, 10, 12, 14, 17, 17. IQR = Q3 - Q1 = 13 - 5 = 8. No outlier.</p></feedback></response></part></multiple_choice></page><page id="cfc66275c11c4ba88e2b99b553d305c0"><title>Assessment Page Title</title><content available="always"><p id="f4bc1dfbc58e493a86bf72ac19781ae2">The table below shows variable <em>age</em> was log-transformed and <em>educational attainment</em> was created based on the number of years of education. Use this table to answer questions 6 and 7.</p><table id="bb1bb4c4ddfe4900864c6d28b66b8309" summary="" rowstyle="plain"><cite id="id8d7a1794671428ea74aa42d580a6350" /><caption><p id="d3796a6185be4b2faadf9db5f3127477" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="a5eba5d9cbd642ffa3516cfd342d8b2e">ID</p></td><td colspan="1" rowspan="1" align="left"><p id="ba586d68511245acb46350f299e9d32a">Age</p></td><td colspan="1" rowspan="1" align="left"><p id="c176f897cf66463bbe29407e1f598a2e">Ln Age</p></td><td colspan="1" rowspan="1" align="left"><p id="b8e40ab87c89430d8caa4fa04bd525a9">Years of education</p></td><td colspan="1" rowspan="1" align="left"><p id="ca0ecd6cedf24de79796c5bb09ae01ae">Educational attainment</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="fe419975befc42239eab1258328e23b4">1</p></td><td colspan="1" rowspan="1" align="left"><p id="dd6c9ffefa8447f6865e2d5a83251908">25</p></td><td colspan="1" rowspan="1" align="left"><p id="bb85abef4f6e4c26b2949ffe85acf70c">3.22</p></td><td colspan="1" rowspan="1" align="left"><p id="cc90b67838c84dd593a17113e45839d8">9</p></td><td colspan="1" rowspan="1" align="left"><p id="a8abc152013d47b3a91551756e3ffb03">High school</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ca7670ada68b4320ba8465dd6e690dfe">2</p></td><td colspan="1" rowspan="1" align="left"><p id="e467f2fb8847481fa50b4c32640e3942">35</p></td><td colspan="1" rowspan="1" align="left"><p id="c1caaade5a104e27a96257021e7525df">3.56</p></td><td colspan="1" rowspan="1" align="left"><p id="f39062bf6ef64a04ac064955db9de9ed">18</p></td><td colspan="1" rowspan="1" align="left"><p id="ab016a8ff28740028f55d4b30deeffbb">Master\xe2\x80\x99s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ab10d76212ca41068bbf91e1cf152793">3</p></td><td colspan="1" rowspan="1" align="left"><p id="f35d6d8441e44a8ebbdd9a1a684c2623">44</p></td><td colspan="1" rowspan="1" align="left"><p id="baa62d46f1e5405580e6263951fe71fb">3.78</p></td><td colspan="1" rowspan="1" align="left"><p id="d27acea1f7224bc2b2a325d4d3bf7945">17</p></td><td colspan="1" rowspan="1" align="left"><p id="c1aca5c878484c409caee2771560ee9c">Master\xe2\x80\x99s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="a233e815ada9480d9f182a1f68b44acc">4</p></td><td colspan="1" rowspan="1" align="left"><p id="f55933b2e2bf4019ad348a3c91c3627d">28</p></td><td colspan="1" rowspan="1" align="left"><p id="f2a83d62d1814b7bb42c22615b542473">3.33</p></td><td colspan="1" rowspan="1" align="left"><p id="d6c96d0922fd4efea2528a368da90539">12</p></td><td colspan="1" rowspan="1" align="left"><p id="c7037f299def464ab6496e99b4552c28">High school</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e630168e4e39456689311a828d3ba818">5</p></td><td colspan="1" rowspan="1" align="left"><p id="abcfb55019b14ef3afecefc2725181a6">35</p></td><td colspan="1" rowspan="1" align="left"><p id="d043e7e7d91d4eb5a8f7652afc0fb1be">3.56</p></td><td colspan="1" rowspan="1" align="left"><p id="f72f60b509ce4432bd0ebe8200d66cb7">14</p></td><td colspan="1" rowspan="1" align="left"><p id="c3fb8368f25a40d5aa564f813fe6fcd9">Bachelor&apos;s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e92db866f1cd4365a68d327b0740eb80">6</p></td><td colspan="1" rowspan="1" align="left"><p id="fb8130f3b22a4db1ab6ed3063b51ab87">42</p></td><td colspan="1" rowspan="1" align="left"><p id="ddd277267df84ba6a3e232ec7fcd80d0">3.74</p></td><td colspan="1" rowspan="1" align="left"><p id="b8d81d118f7d4f1c961e129fc3e042f1">16</p></td><td colspan="1" rowspan="1" align="left"><p id="c7503fdc3cf441adb6e5560b740464a6">Bachelor&apos;s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="efbb931d891a4b00a16c522495572cb1">7</p></td><td colspan="1" rowspan="1" align="left"><p id="ded1d7c8998a474fad3ebc81f6164bf8">36</p></td><td colspan="1" rowspan="1" align="left"><p id="e91fee0208af4f1193e06b67ce6cf8ec">3.58</p></td><td colspan="1" rowspan="1" align="left"><p id="f4e36c5c8002473893d395dadaa152eb">11</p></td><td colspan="1" rowspan="1" align="left"><p id="f8a4524d33f7414fbc92aee937fda0f0">High school</p></td></tr></table></content><multiple_choice id="f3b55eb337f54ecc9fd75bd0f26bacc8" grading="automatic" select="multiple"><body><p id="dcbb7ba022b543059c6c7426a6bd9795">Which of the following keyword(s) best describe the type of variable <em>Ln Age</em>?</p></body><input shuffle="true" id="fd6fb0a6d38646109791c397a089769d" labels="false"><choice value="A">Numerical</choice><choice value="B">Categorical</choice><choice value="C">Quantitative</choice><choice value="D">Qualitative</choice><choice value="E">Continuous</choice><choice value="F">Discrete</choice><choice value="G">Ordinal</choice><choice value="H">Nominal</choice><choice value="I">Binary</choice></input><part id="f75315f1d42a4686966f0bb40b6579de"><response match="A,C,E" score="10"><feedback><p id="fc31da99749045898b5d45115af37b94">Correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="C,E" score="7"><feedback><p id="b0fd54bffd9e4a388bd98a5ba46d7412">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="E,A" score="7"><feedback><p id="f3ab273eb27b49a1a0d35abc9ec4addc">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="C,A" score="7"><feedback><p id="fa802a52fae14a13adefc05dcc420747">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="A" score="4"><feedback><p id="b9707eb06f60433b84da7f9891cd1b6b">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="C" score="4"><feedback><p id="cfd8fc0ad9054cb8b06345ecd296146e">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="E" score="4"><feedback><p id="e70f64dc335c432f825857543cb961c1">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="*" name="AUTOGEN_*" score="0"><feedback><p id="c5d9ab1d47d74ef1b1e4dc80a57e4691">Incorrect. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response></part></multiple_choice></page><page id="f92ed53e4b64427f8e1aa038ab4adf2e"><title>Assessment Page Title</title><content available="always"><p id="b991befa686e4978863961e78eacbc63">The table below shows variable <em>age</em> was log-transformed and <em>educational attainment</em> was created based on the number of years of education. Use this table to answer questions 6 and 7.</p><table id="bf46c46018fb480399da9aa892ef73e2" summary="" rowstyle="plain"><cite id="ifb1dab9817b1466aa1cb1e5610325ee3" /><caption><p id="c7aa8e8314ad4435bff26062ef9e9088" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="c03eb0118d374361a1796a2165b32b13">ID</p></td><td colspan="1" rowspan="1" align="left"><p id="ed4a1788f6aa41acac8784a2ffd478f7">Age</p></td><td colspan="1" rowspan="1" align="left"><p id="a9501bd0b01c4506b57b7106d16eec76">Ln Age</p></td><td colspan="1" rowspan="1" align="left"><p id="f02650f2a5974231a0301446c0e6801f">Years of education</p></td><td colspan="1" rowspan="1" align="left"><p id="f841a904e8284eb4bc49c50bfd903ff9">Educational attainment</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="c8a090470b414fdfb5031fd8aae1385a">1</p></td><td colspan="1" rowspan="1" align="left"><p id="dd33919fce3a45b0ae8788cefaf66dc2">25</p></td><td colspan="1" rowspan="1" align="left"><p id="abb93bdaf8b44a428004f0000c820041">3.22</p></td><td colspan="1" rowspan="1" align="left"><p id="fa39b3ca976d43d3a443896f3640b405">9</p></td><td colspan="1" rowspan="1" align="left"><p id="cf312f0cc2884b5c9b9e89c689d4edeb">High school</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="b2f334222fd2441f8afd134681357e6b">2</p></td><td colspan="1" rowspan="1" align="left"><p id="c7ad6d22e0d248d0a735ff25b2b682ce">35</p></td><td colspan="1" rowspan="1" align="left"><p id="ad4e1b5aa51042cbb6c8a9fa02db4ec6">3.56</p></td><td colspan="1" rowspan="1" align="left"><p id="a73322d1c401490296142e7dcb5e6049">18</p></td><td colspan="1" rowspan="1" align="left"><p id="e564e5642b464cd589f333926ce21d45">Master\xe2\x80\x99s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="b1df52a4387146cf9a2ab1c969e6e927">3</p></td><td colspan="1" rowspan="1" align="left"><p id="fcba17af1db24530a8dc5aff33eb0d57">44</p></td><td colspan="1" rowspan="1" align="left"><p id="c7cd1e8674324e25a180cdcc21f585c5">3.78</p></td><td colspan="1" rowspan="1" align="left"><p id="f2b0c79a344244e5b691264bb0fbc4d6">17</p></td><td colspan="1" rowspan="1" align="left"><p id="b0fb2c22dc53427cad54adcbd830135f">Master\xe2\x80\x99s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="e7dcede8cf0846a09a3452895c0437f6">4</p></td><td colspan="1" rowspan="1" align="left"><p id="c9bf014abef44f9fbc2da1ea6313696a">28</p></td><td colspan="1" rowspan="1" align="left"><p id="d20c273c1b114702be83c356e758f818">3.33</p></td><td colspan="1" rowspan="1" align="left"><p id="da73d9497b134dca8924c11de1360c62">12</p></td><td colspan="1" rowspan="1" align="left"><p id="f33da0782a1a4db1ae0eb1829791b290">High school</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ba4ae405450e4956b00fee83ca188a7a">5</p></td><td colspan="1" rowspan="1" align="left"><p id="a0a4b22a232f40f5955a93f9b68bd8c4">35</p></td><td colspan="1" rowspan="1" align="left"><p id="ce3756c9ade74e07b5896358ed995d49">3.56</p></td><td colspan="1" rowspan="1" align="left"><p id="f498dd59afcc49bf8e5f2cb697c70d05">14</p></td><td colspan="1" rowspan="1" align="left"><p id="dfbf0bbb5be34d73acc029a576b39a93">Bachelor&apos;s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ee0a412322f1468bacf70e370c7d53a7">6</p></td><td colspan="1" rowspan="1" align="left"><p id="efcc5acc62f54b68aa4a1939668fe4d3">42</p></td><td colspan="1" rowspan="1" align="left"><p id="c970760d06454fd9a0dde7cc4df9e469">3.74</p></td><td colspan="1" rowspan="1" align="left"><p id="f23d4de61fd245cea4fe80d07ddd8fec">16</p></td><td colspan="1" rowspan="1" align="left"><p id="e136495ca8dc43da884742202ae87266">Bachelor&apos;s degree</p></td></tr><tr><td colspan="1" rowspan="1" align="left"><p id="ec780626300845cda59a2b828d3ad3de">7</p></td><td colspan="1" rowspan="1" align="left"><p id="e0c155f074cf4a50ad5097f83813b59c">36</p></td><td colspan="1" rowspan="1" align="left"><p id="b8198027352447a8ab829d357626f01b">3.58</p></td><td colspan="1" rowspan="1" align="left"><p id="e14a9053e15a411aa4098e6ed114927e">11</p></td><td colspan="1" rowspan="1" align="left"><p id="ba86d7d1488246d78cefc477d5c10321">High school</p></td></tr></table></content><multiple_choice id="f678bff9bd3244f890b6a779ae467d16" grading="automatic" select="multiple"><body><p id="e8e6806ca5454f32a69869da5d529a5a">Which of the following keyword(s) best describe the type of variable <em>Educational Attainment</em>?</p></body><input shuffle="true" id="bbf721d1177a443e81734868855edd89" labels="false"><choice value="A">Numerical</choice><choice value="B">Categorical</choice><choice value="C">Quantitative</choice><choice value="D">Qualitative</choice><choice value="E">Continuous</choice><choice value="F">Discrete</choice><choice value="G">Ordinal</choice><choice value="H">Nominal</choice><choice value="I">Binary</choice></input><part id="defde142c0d5498c9ded94a49c65dfb4"><response match="B,D,G" score="10"><feedback><p id="e4230b82dc2743019b51ac3bf62158a0">Correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="B,D" score="7"><feedback><p id="ee1a82e3f2e54391be7572716d06d573">Partially correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="B,G" score="7"><feedback><p id="ccdae0e35b594f2cb1bde456be9946cd">Partially correct. After log transforming the numerical, quantitative, and continuous variable age, the characteristics of the variable Ln Age are still numerical, quantitative, and continuous since log transformation is in fact rescaling the original scale by a specific factor. The distributions of Age and Ln Age may be different.</p></feedback></response><response match="G,D" score="7"><feedback><p id="eec6c6c60f464381a2fc5119dcc3fca3">Partially correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="B" score="4"><feedback><p id="fc29ad3568fa4e84830f757722b187bf">Partially correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="D" score="4"><feedback><p id="d2b40ec215db4974a6d925397e697a30">Partially correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="G" score="4"><feedback><p id="f19f8d0963f442f8a3460158f1b8267f">Partially correct. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response><response match="*" name="AUTOGEN_*" score="0"><feedback><p id="a601a753722a48a0853b1a1b99da3f79">Incorrect. After categorizing the numeric, quantitative, and continuous variable years of education, the characteristics of the variable educational attainment have become categorical, qualitative, and ordinal since a category represents a range of values and the categories have a ranked order.</p></feedback></response></part></multiple_choice></page><page id="e1a937477dd9449e9064cba4f11c3ea8"><title>Assessment Page Title</title><content available="always"><p id="d48b7e6c59544c1897adb70cdea2edd3">Say we have two models, and on some datasets, the first model has an accuracy rate of 0.990 while the second has an accuracy rate of 0.996. Assuming you have 1000 data points to classify and an \\(\\alpha\\) level of 0.05, is the second model statistically better than the first at classification?</p></content><fill_in_the_blank id="aa35c83eb8b1429db18b03e893b8e417" grading="automatic"><body><p id="b12a3110b1f34436b9018c9cc0fd9267">Answer: <input_ref input="c5e522111e314951a3e9245e15e87c21" />. As we have two models tested on the same data, we should use the <input_ref input="ac9cfc92e7d94fed910a8c2ee1a63db6" />. Calculating the test metric, we have a value of <input_ref input="c0489b5fbaaa4615ab6f605d6b883420" />. As the associated p-value is <input_ref input="ab8142a9dc4c49c6a36b82ca54d20694" />, we <input_ref input="dfae166fb77f4f3ab3b27f7d716a4ad8" />.</p></body><input shuffle="true" id="fc9d01f7d82e4fabbb34dab4be4c07eb"><choice value="f738aae4fffb4007905360e3ffc2b75b">f738aae4fffb4007905360e3ffc2b75b</choice></input><input shuffle="true" id="c5e522111e314951a3e9245e15e87c21"><choice value="b1e4844848c44fd9adf61778b9710cb3">Yes, the first model is statistically likely to be more accurate than the second model</choice><choice value="eb0d68e70974401cb1817f1c2f2a10f1">No, the first model is not likely to be more accurate than the second model</choice></input><input shuffle="true" id="ac9cfc92e7d94fed910a8c2ee1a63db6"><choice value="c91422d39c8949ab85196d2bdb44a521">McNemar Test</choice><choice value="e811fb9712274726848752acc9ae90ec">Friedman Test</choice><choice value="f0b8218a129d4ec1a641a9ffb0899072">Welch\xe2\x80\x99s t-Test</choice></input><input shuffle="true" id="c0489b5fbaaa4615ab6f605d6b883420"><choice value="d1eefb7b9bdf4da985faf72a084bcbf5">10.89</choice><choice value="c908c86ed2504c6a800a6f9ec8f1635c">1.786</choice><choice value="b0fdac67eb2945efbf30af7c7917975d">10.98</choice><choice value="b3418ed95e4947a8b907055495f1b35b">1.876</choice></input><input shuffle="true" id="ab8142a9dc4c49c6a36b82ca54d20694"><choice value="f75634f2d5a8495c90efb54ea4102fe9">greater than the value of alpha</choice><choice value="f6b1c00884844a89b9d98e947c129fb7">less than the value of alpha</choice></input><input shuffle="true" id="dfae166fb77f4f3ab3b27f7d716a4ad8"><choice value="f5cb5be8459a431292003038d2db280a">reject the null hypothesis</choice><choice value="db29ea2d71a64b7facfae568733e09ce">fail to reject the null hypothesis</choice><choice value="e7c3cc3f9fe14c33b35b441a42df75e5">accept the alternative hypothesis</choice><choice value="b6a13fda6e364a45a2d99d536c0aff63">fail to accept the alternative hypothesis</choice></input><part id="fedf880705a84b9d8afcf735760010b6"><response match="f738aae4fffb4007905360e3ffc2b75b" input="fc9d01f7d82e4fabbb34dab4be4c07eb"><feedback><p id="c388e1f9276b44cdaf86365e2d7fc454" /></feedback></response><hint><p id="ae6dff4b7a0446178999e89f2a35ae0a">Instead of following a t-distribution, this metric instead follows a Chi-Squared distribution with one degree of freedom.</p></hint></part><part id="c4999dead6ba4a6bbf3878b0b1b406ee"><response match="b1e4844848c44fd9adf61778b9710cb3" score="0" input="c5e522111e314951a3e9245e15e87c21"><feedback><p id="debc152d81654b8b9fd3ed9af21383b9">Incorrect.</p></feedback></response><response match="eb0d68e70974401cb1817f1c2f2a10f1" score="2" input="c5e522111e314951a3e9245e15e87c21"><feedback><p id="d442352ee3fe47519ce480ebea4a8f7f">Correct.</p></feedback></response></part><part id="e1b25fad725944acb1d13533749ee707"><response match="c91422d39c8949ab85196d2bdb44a521" score="2" input="ac9cfc92e7d94fed910a8c2ee1a63db6"><feedback><p id="fc1b9fbc8a5b434486bc3453ef2035df">Correct.</p></feedback></response><response match="e811fb9712274726848752acc9ae90ec" score="0" input="ac9cfc92e7d94fed910a8c2ee1a63db6"><feedback><p id="e182271ab73748a387e269fbca9ed391">Incorrect.</p></feedback></response><response match="f0b8218a129d4ec1a641a9ffb0899072" score="0" input="ac9cfc92e7d94fed910a8c2ee1a63db6"><feedback><p id="bcaeb2a6d537429592cf11f5ca1d6e45">Incorrect.</p></feedback></response></part><part id="b36cdf2ca1e24a75a2ef38c9638883b1"><response match="d1eefb7b9bdf4da985faf72a084bcbf5" score="0" input="c0489b5fbaaa4615ab6f605d6b883420"><feedback><p id="f495dc5fcf5a415294dc425cfac2ac19">Incorrect.</p></feedback></response><response match="c908c86ed2504c6a800a6f9ec8f1635c" score="2" input="c0489b5fbaaa4615ab6f605d6b883420"><feedback><p id="f0504d0883b24f9da4c7bbd9ed673d1e">Correct.</p></feedback></response><response match="b0fdac67eb2945efbf30af7c7917975d" score="0" input="c0489b5fbaaa4615ab6f605d6b883420"><feedback><p id="b2ba46d476cc49c7879d2020e60be1d3">Incorrect.</p></feedback></response><response match="b3418ed95e4947a8b907055495f1b35b" score="0" input="c0489b5fbaaa4615ab6f605d6b883420"><feedback><p id="da0c24987faa4d8abaac675adcc83cb3">Incorrect.</p></feedback></response></part><part id="de0ca642027b441eb69271dd75e53879"><response match="f75634f2d5a8495c90efb54ea4102fe9" score="2" input="ab8142a9dc4c49c6a36b82ca54d20694"><feedback><p id="e74a328176aa4e0e88f25483bd24c631">Correct.</p></feedback></response><response match="f6b1c00884844a89b9d98e947c129fb7" score="0" input="ab8142a9dc4c49c6a36b82ca54d20694"><feedback><p id="b98d9da253d940d1a1ce2fc9900ce5e2">Incorrect.</p></feedback></response></part><part id="ba9c1ead19a544338776c991e3a19548"><response match="f5cb5be8459a431292003038d2db280a" score="0" input="dfae166fb77f4f3ab3b27f7d716a4ad8"><feedback><p id="d9ae78471fbb471c8f812a609ef5d31a">Incorrect.</p></feedback></response><response match="db29ea2d71a64b7facfae568733e09ce" score="2" input="dfae166fb77f4f3ab3b27f7d716a4ad8"><feedback><p id="beadf3e9180b4fffbb4aa8d49609439a">Correct.</p></feedback></response><response match="e7c3cc3f9fe14c33b35b441a42df75e5" score="0" input="dfae166fb77f4f3ab3b27f7d716a4ad8"><feedback><p id="e7613ec330434dd1b12d535343a31384">Incorrect.</p></feedback></response><response match="b6a13fda6e364a45a2d99d536c0aff63" score="0" input="dfae166fb77f4f3ab3b27f7d716a4ad8"><feedback><p id="dae27ed0a0314ad19c2a25983c99c885">Incorrect.</p></feedback></response></part></fill_in_the_blank></page><page id="cbfc5b302d7f445c855f9a07f36f35bb"><title>Assessment Page Title</title><multiple_choice id="da82156bba1b413eb62a8c7a16b4bb45" grading="automatic" select="single"><body><p id="ee17c8ee08ac46deb3c12ac1ff6b1a51">Given a dataset of house rent prediction with the following features:</p><ul id="c9da1aed96aa4ea797a8bfdaa1a5d788"><li><p id="c16b175c08014dedae181c43784aaa4d">Area (numerical): measured in square feet.</p></li><li><p id="b04ffcb576534271b1a30d4d7813fb06">Type (categorical): either 1B1B or House.</p></li><li><p id="bb93064709c4496c9847e8384d604485">Neighborhood (categorical): either Oakland, Squirrel Hill, Shadyside, Downtown, or Bloomfield.</p></li><li><p id="ad8e8770842e4f20a10810d6ccf12aa7">Age (numerical): measured in the number of months.</p></li><li><p id="d684e73df4a545178fdb02662c1a0938">Lease duration (numerical): measured in the number of months and may span several years.</p></li></ul><p id="a1e35f87ba0d4df7841b425571f3aba1">We perform one-hot encoding on the categorical features and drop the redundant binary features so that the resulting features are all linearly independent (this technique is called dummy variable encoding). What is the total dimension of the output vector, including the original numerical features?</p></body><input shuffle="true" id="db37fc1679b54863b06f280873a0b7aa" labels="false"><choice value="a68689b728a4490996f21086b9295a9e">5</choice><choice value="bb02eb4bc4994839883f303670892172">11</choice><choice value="e1ca5e75f7b14bc7b880c66612fbe966">9</choice><choice value="e911cb8b257e4d8daed0e9076ef5bcb2">8</choice><choice value="ffe6d2dca8c64e29942d0d39d430966f">13</choice></input><part id="a98299ded83d4b33948200916cef401e"><response match="a68689b728a4490996f21086b9295a9e" score="0"><feedback><p id="d6d464d604bd478aabd97723eee8cfa8">Incorrect. The Type feature with 2 categories is transformed into 1 binary feature. The Neighborhood feature with 5 categories is transformed into 4 binary features. Thus the total number of features is 1 (from Type) + 4 (from Neighborhood) + 3 (from Area, Age, and Lease duration) = 8</p></feedback></response><response match="bb02eb4bc4994839883f303670892172" score="0"><feedback><p id="b9080f81e0dc472797b5dfe8ad0ab859">Incorrect. The Type feature with 2 categories is transformed into 1 binary feature. The Neighborhood feature with 5 categories is transformed into 4 binary features. Thus the total number of features is 1 (from Type) + 4 (from Neighborhood) + 3 (from Area, Age, and Lease duration) = 8</p></feedback></response><response match="e1ca5e75f7b14bc7b880c66612fbe966" score="0"><feedback><p id="f1399680224149b685902363f20b9539">Incorrect. The Type feature with 2 categories is transformed into 1 binary feature. The Neighborhood feature with 5 categories is transformed into 4 binary features. Thus the total number of features is 1 (from Type) + 4 (from Neighborhood) + 3 (from Area, Age, and Lease duration) = 8</p></feedback></response><response match="e911cb8b257e4d8daed0e9076ef5bcb2" score="10"><feedback><p id="c6993ec355d7478294c647befc10b20b">Correct. The Type feature with 2 categories is transformed into 1 binary feature. The Neighborhood feature with 5 categories is transformed into 4 binary features. Thus the total number of features is 1 (from Type) + 4 (from Neighborhood) + 3 (from Area, Age, and Lease duration) = 8</p></feedback></response><response match="ffe6d2dca8c64e29942d0d39d430966f" score="0"><feedback><p id="eeaaf9b95a1e41f2b1d34d3362835722">Incorrect. The Type feature with 2 categories is transformed into 1 binary feature. The Neighborhood feature with 5 categories is transformed into 4 binary features. Thus the total number of features is 1 (from Type) + 4 (from Neighborhood) + 3 (from Area, Age, and Lease duration) = 8</p></feedback></response></part></multiple_choice></page><page id="c4b9ff2bc3af42ecbb51e1fd8aac9d83"><title>Assessment Page Title</title><multiple_choice id="ce5d39c261714b698e962aac6f3b9bc4" grading="automatic" select="multiple"><body><p id="d8c14d1aa0ba46a7be98a01d61a45c60">Which of the following statements is (are) true about dimensionality reduction?</p></body><input shuffle="true" id="cd7b4a30b76b4c4b9d40cad925195569" labels="false"><choice value="A">Dimensionality reduction methods typically rely on a target variable or label to help calibrate the effectiveness of the optimized result.</choice><choice value="B">When a dataset is sparse and high-dimensional (e.g., a document set with the presence/absence of each possible word being a feature) there is little value in performing dimensionality reduction to just 2 dimensions, because a lot of valuable information about the documents is lost as a result of this extreme projection.</choice><choice value="C">After fitting a decision tree to a labeled dataset that has 20 features, you compute the importance scores of all features and create a new dataset by selecting the top 5 most important features from the original dataset. This feature selection is an example of dimensionality reduction.</choice><choice value="D">You have a dataset X with numeric features (columns) A, B, and C. You compute a new feature that uses all three, namely D = A x B + C. You then create a new dataset X2 that contains only feature D as a column. However, this creation of X2 is not considered a form of dimensionality reduction, because it relies on all the features in the original dataset X.</choice><choice value="E">Dimensionality reduction is valuable for both visualization and data pre-processing to improve the efficiency/accuracy of downstream learning methods.</choice></input><part id="ae47f79125e64bfab4d2f1f476889759"><response match="D,C,B,A,E" score="0"><feedback><p id="a3f559bd6a964dc7b676b20201d8b0f0">Incorrect. Not all statements listed are correct about dimensionality reduction.</p></feedback></response><response match="A" score="0"><feedback><p id="d70fac56885045bd8bfeeb611f510240">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p></feedback></response><response match="B" score="0"><feedback><p id="c18a8de649c945a496c68897218e9efa">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p></feedback></response><response match="C" score="5"><feedback><p id="e231e3e7ed3440228f15c967d6c5aab7">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="ec834b86984e488aa9a42615cfd62b12">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D" score="0"><feedback><p id="bd59820266f1474ba66c17e40ee2beb2">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p></feedback></response><response match="E" score="5"><feedback><p id="df4c98546a0e4774a06f9280f173d7e9">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="e622a129ee174bd2986faf896ba9d75c">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="A,B" score="0"><feedback><p id="ea8ca56fb8714d43ac9d4d29f23387f6">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="d53b262229b8443a85e6b248f2883f17">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p></feedback></response><response match="A,C" score="3"><feedback><p id="baca53498c794d5fa310f8c23d213a4d">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="df969079e7fa4883903491250a2024a8">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="e9cc8795e8594cb5bb336b8f97fdd01a">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,A" score="0"><feedback><p id="f5115ef4e11d448b8c7ed47b5f11167a">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="a9efa632e4ae4367ae827ccf7fd773ce">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p></feedback></response><response match="A,E" score="3"><feedback><p id="e0d4432b6c7941ffbabbce0d64a27956">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="e217c9d7e5d74e349a2ecfd01e8b2685">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="a8c2bb9419854aeb995a64e7cabc8b83">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="B,C" score="3"><feedback><p id="c189a3956c114e61b130b8e259017b52">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="afcb2aeda28a4905944ecb94d2a765aa">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="d6c2b8876b2f4190aaec696284b0eff3">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,B" score="0"><feedback><p id="ca0faa69474f43138976fa42013b46b9">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="a21f5693f2a44871a905672ad528a6e3">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p></feedback></response><response match="B,E" score="3"><feedback><p id="ed59c9aed1764faf8517ebf2235df9b0">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="ba5ec9c21fab4b0392a3771b596cf916">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="e796dbd34ca04244911de70ba012ff75">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,C" score="3"><feedback><p id="e3264dbad51d443cb88f490e28b219d5">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="ee21011c3fcc45a99a7536a0df8a8265">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="f0361e31787649e8aca70814ede1c475">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="C,E" score="10"><feedback><p id="c7d65691e586409daa30a2ab1ad3d2e7">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="faf6bf9f4f1e4ce19f2a43177f35b4d2">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,E" score="3"><feedback><p id="ecffd7a5639a4c7b926d54f3abc04be0">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="f702ec8ea1974985a0c7fa2ef7b25bde">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="e587ae5dfabe48ae977335dfa1c9935b">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="A,B,C" score="1"><feedback><p id="fd81d9eba13d4022a48fb33d55bcde9d">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="b6cbfdbc3bd9448591f678493e574c80">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="cfabe67ad5f84a30b111ca166b6cdf21">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="f7da69a4f0f74afeb797ed1408f164b2">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,A,B" score="0"><feedback><p id="b3520194a88c441d8e33d03d9daa82f6">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="f3994d30e154488f84f7ec8d092301ee">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="c867f74326ad4b95876e10ec588a6db5">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p></feedback></response><response match="E,A,B" score="0"><feedback><p id="f42ac7d0b71c46be97cf24916f899a6b">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="b19165376ba540c9a8848cfb7305f3bd">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="cce8d3ebb9f44fe9b8f1a8a9af14969d">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="e23fe78d67504c10bac07db785b2552e">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,A,C" score="1"><feedback><p id="d85f5cbf97f34c2db2132b3cbf965c87">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="b1ec9220e2b14e908b3c439a7100b6d2">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="e7b6050bf916407099d77a836d9b76dd">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="d1f3410ae3a943ee97d3e5b280f11b5d">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="E,A,C" score="8"><feedback><p id="f7859a71924441fe9fc9f213b1a5cdca">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="d964dfe4355c4198a81485b83e8ecf43">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="cf9c9f03f66442bebe3ce428d22d698d">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,B,C" score="1"><feedback><p id="e422b827c1ec44a186b357b39b09e68c">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="ddb67f5cd32a44cb890199a60e09ee9c">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="ff20f92725274724813bed553d9e65a5">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="cefbb16623f34e25a34d426c091bc2e4">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="E,B,C" score="8"><feedback><p id="a4a0b7e6a15a4da487f9a936501b89f9">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="c08f0319246a4913b67d5d9ee113fbee">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="e301a1ec2bd243be829fdfe5140130e3">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,E,B" score="1"><feedback><p id="f1625901bc8d4993a2a9fa3380f6c115">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="b0f77803d57b4f6d97a5aad3d1db597f">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="a409d8dc615e403cb242d42135d8be98">Correct. Suppose the sample used in the randomized control trial is assumed to be representative of the population of interest. In that case, we can assume that the result of this study applies to the entire intended population of the study. </p><p id="f3240ecc4a7f498c8010dcef275570f5">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,E,C" score="8"><feedback><p id="b2cc74ac10f9480a85f6b0c22e1aeb4b">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="ad60b154e86c4c00b64fdd66003ffdab">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="a0eec1abcffd4310a1a832b571353367">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,A,B,C" score="0"><feedback><p id="bc3a1dbe4add4064b39398f1c663813c">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="f346901418a849e5ac0e445a1c85daeb">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="cc89a95c395e47a88ed75c16e0aa3ed1">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="bcf2c396940e47f3835227a1cf4d7856">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="d5baa1dddf68467bb34d875c7e440d70">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="E,A,B,C" score="6"><feedback><p id="a43e9d94f6d34d949f7a91b6eaddf41d">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="bd878e9abf9a4a6c8b656e69423c7ab0">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="fa3ca35f244941afb31bb5ab27e0ed84">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="f78e1a7607b145fe864d7b34e7d39fdc">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,E,A,B" score="0"><feedback><p id="b95a7ddaf14e4f5f95afa57e386a9d48">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="a5a53e26594f46ffb6c488c0df2d8a11">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="dc1961a69d7740c8b14dba8473dc6f98">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="fcc790e6a3a640dcab33655556212305">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p><p id="b0670c1392ad4869b172e325cbee177e">However, this is not the only correct statement about dimensionality reduction.</p></feedback></response><response match="D,E,A,C" score="6"><feedback><p id="ef2d68b80ada43529cb0c2afb89d745c">Incorrect. Many dimensionality reduction techniques do not utilize or require a target variable/label at all, e.g., PCA.</p><p id="b184306799384109941c0e5106660c4f">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="ed3f395a01124b02a77225ec751a8ca3">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="d0749da5888e4262a9b2e9fe86b62249">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="D,E,B,C" score="6"><feedback><p id="b54a21724b2b4bb19704b18d0e46a6b3">Incorrect. Reducing to two dimensions can often be viable for extremely sparse datasets. Different areas of the 2D plane are able to represent different segments of the sparse feature space, and if the data are significantly sparse, this can be sufficient.</p><p id="dffd61d1cc1b449a901d35f76354c594">Incorrect. The technique described here involves reducing a set of three features down to only one feature; it is, therefore, an example of dimensionality reduction.</p><p id="f4b88785c8f144b8934b68451b8a2992">Correct. This is an example of feature selection, which is one type of dimensionality reduction.</p><p id="dbe9258d01f7473688012ca7982e8884">Correct. Dimensionality reduction is useful for visualization purposes because it allows us to plot high-dimensional data in (typically) two or three dimensions, where plotting libraries can visualize the data and reveal patterns, clusters, or other interesting features. It is also useful in reducing the dimensionality of the data, allowing downstream algorithms to run faster and with smaller memory requirements.</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="f5205c84a19e4524aade19d0df299c71" /></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="ca0b9f23f39a4f5dba8c230bfe77dbc9" /></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="e02390062c384da996ab70971cb8003f" /></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="dcc9147269714294827613a09856fdeb" /></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="b305f5af719b48cb9f78cdfe11d07502" /></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="b1a7ff92952d4b4181bb6eac1eef6969" /></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="e98e5ececf9c4a2db22dc57ba0bb0505" /></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="d914999af9434fa7a18f0926645da81f" /></feedback></response><response match="A,C,E" name="AUTOGEN_{A,C,E}" score="0"><feedback><p id="c351f907d802420fa4e97b1c8bdc5ef5" /></feedback></response><response match="A,D" name="AUTOGEN_{A,D}" score="0"><feedback><p id="c39e222c0a604112a36f03cff20d9c89" /></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="dbf4e2f7aa3f4936802a7eb454063940" /></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="c4181dfaa78747ff9da8976c18cf0146" /></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="a787e537cf7c40a5887dc65c3804dfb9" /></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="da024203929a4aa48c4e9d33e485cb68" /></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="bbdaeec6d4b04f9cbbe1c9597ee66ce7" /></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="f074df12d5a64c319b0ef90854df3e2c" /></feedback></response><response match="C,D" name="AUTOGEN_{C,D}" score="0"><feedback><p id="eb7b7cf7a6b5458c8d2923e8c0469bcb" /></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="a68bfe0243b24de884450ca03aa65def" /></feedback></response></part></multiple_choice></page><page id="d9f47b5ea4f449b68d10c60ecff68f2f"><title>Assessment Page Title</title><multiple_choice id="c466f2d08c1a44d396cd30d28191e01c" grading="automatic" select="multiple"><body><p id="ee09f8458c464c8a82dd6c561fe2ad57">It&apos;s typically important to transform the input variables to PCA so that they have zero mean and unit variance (this is called standardizing the variables). Select all that is correct when explaining why standardization is needed.</p></body><input shuffle="true" id="d4c76bea0d3847e79c842942c944ee78" labels="false"><choice value="A">If some variables have a large variance and others have a small variance, since PCA seeks to maximize overall variance, if you do <em>not</em> standardize the inputs, the directions of the principal components found by PCA will be heavily weighted towards the variable(s) with the largest variances.</choice><choice value="B">We usually want the results of PCA to be dependent of the units of measurement of the variables.</choice><choice value="C">Transforming the data by column-centering (subtracting the mean of each column from all the entries in that column, so that it has zero mean) allows us to perform PCA directly by doing Singular Value Decomposition.</choice><choice value="D">When the units of all variables are the same, normalizing feature variances is not advised, because it results in shrinkage of features containing strong signals and inflation of features with no signal.</choice></input><part id="dd3c05e68c4a4301899e6958d7785a57"><response match="A,C,D" score="10"><feedback><p id="a53af71402314be8b55d0291ebbf5e76">Correct. </p></feedback></response><response match="A,C" score="7"><feedback><p id="d9194f357d824570a9fcb72d36208cdd">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A,D" score="7"><feedback><p id="b30fe5c1a60141b1a0451f851e36e356">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="C,D" score="7"><feedback><p id="aa7d822f4fd94aa18b2cc5978aa7a666">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="C" score="4"><feedback><p id="b629bc528a084738b180991c13ac40d5">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="D" score="4"><feedback><p id="c9c31692609e4343aafccc9410bb9087">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A" score="4"><feedback><p id="b93d12293ba741b3ae88ad46f252b94e">Partially correct. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A,B" name="AUTOGEN_{A,B}" score="0"><feedback><p id="abb44c2d0c3f44c38ceceeafca911e60">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="d3c2a67235874e53a89377851cb122c9">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="aebe7fed68fc4934a13de6cd727cf101">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="f625a14997d34d0fa552a4bd939ca410">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="B" name="AUTOGEN_{B}" score="0"><feedback><p id="daababcb4633422d9b758ad6426e4e49">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="B,C" name="AUTOGEN_{B,C}" score="0"><feedback><p id="d85f56907a8144bf97bc2b964ea5868e">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="a720fbe2406e43dfa907f93f5fad20a7">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="e7bb59efcf034f2d8cb4dc7f2689b6e1">Incorrect. We usually want the results of PCA to be <em>independent</em> of the units of measurement of the variables.</p></feedback></response></part></multiple_choice></page><page id="b26efacb73bd49938acde1d1b6e9e0b7"><title>Assessment Page Title</title><multiple_choice id="ccca0119f12f4c28859f9fb7319714ea" grading="automatic" select="multiple"><body><p id="dfa3f24d0f164e0a9233bb6c8ccc0e77">Which of the following statements is (are) true about Errors in Hypothesis Testing?</p></body><input shuffle="true" id="cd2b688754484da1b40d4e735001851d" labels="false"><choice value="A">A Type I error occurs when we conclude there is no significant effect even though one exists.</choice><choice value="B">When the main outcome variable is a continuous measure, increasing the standard deviation will reduce the chance of making a Type II error.</choice><choice value="C">A Type II error is when we accept the null hypothesis (\\(H_0\\)) even though it is not true.</choice><choice value="D">A Pregnancy test gave a negative result for a woman who is, in fact, pregnant is an example of a Type II error.</choice><choice value="E">Probabilities for Type II error are called \xe2\x8d\xba (alpha).</choice></input><part id="fa785fbb112d4c2d82bc2c16fbb836a4"><response match="C,D" score="10"><feedback><p id="f3b9394685714fc5a082a4c0c04784c6">Correct.</p></feedback></response><response match="C" score="5"><feedback><p id="bcec5536bd3447e3bcac003dd33221da">Partially correct. </p><p id="c1f7179686094150a26605d2d02ebe16">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d654d168b95d479a88dd050678b49626">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="c306865385224edca947f674186193b1">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="D" score="5"><feedback><p id="a2a08d6507d94c92a80a88dfa1549501">Partially correct. </p><p id="a0cb18c3aa2b4a0089ed94c26595d195">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="ff77df9bb9f84005b1245afde7e0388d">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fa017570c93741e89b9b688384ee5483">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A" name="AUTOGEN_{A}" score="0"><feedback><p id="f557ab8c71c8460fa370becca15a3cdc">Incorrect. </p><p id="f5e520ba2b6142f9bb64ca526b0a18e3">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e7595921758b4f4395d87362ea39f940">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="a467b04cf00d4e65a0c2db28f2e03919">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B" name="AUTOGEN_{A,B}" score="0"><feedback><p id="e81f3e83a8ac4f06a9654d86b08da9f4">Incorrect. </p><p id="db59f37d543f4f24badcbdcf1b95d506">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="a385f539a85044899ec27985ea6de140">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="bf28d664052d4d6b8ea5c40451deea45">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="b54e1680f7d54749871669fece716ac8">Incorrect. </p><p id="ac36342218134ad2b938f6fdbe2be7b0">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="a764bccde92849738326f16639373203">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="bf356ae782894d23a6ae461b7f1ff67f">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="c9ab8bfce2d94eb19668ce8bc4de865c">Incorrect. </p><p id="ee170609c58b452cbf7769d16390855a">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e2858b9781ff48418cc8003b03be1d07">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="e48694175c8043c59e7f0a47fe74221b">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="b378e52978924cf19bfccc55e36655c7">Incorrect. </p><p id="ef1057f3d3e1419da0730bfd8f26baed">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e6f0577de97e4346b6cf3230b5b061b5">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="cce851d3c5ac42e8802f75296f3e484d">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="b3b6b52902744bea9a9c5393960752f4">Incorrect. </p><p id="bcf8d79ce0a140ae8d53e4d723358a57">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e8b78550925a4b55a66364fed3253ba9">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="f8fa4a425b96452181a7f4de6acc2579">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="ebe0dc65e69d456e9e08cde56def785f">Incorrect. </p><p id="a2c166e93964442a871b3bab80bc0944">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="faf681f8c3c341678d1e888bb3b5d2bc">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="aaf34c5300de46fdb4e96e466cd972e9">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="d1c89129d8c94913a22a1680ecdeb716">Incorrect. </p><p id="aa50970bcc6c42edbbe00f8b06995f82">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d08d20156f084becb6f122996d297fe5">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fb59fbc0a4fe4c21aa776bd69e6b5809">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="d9e9c9574fee491098bd50264b7e90e4">Incorrect. </p><p id="cb4083b4884a4d438182eadebaa0b72b">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="f55134468ff14e3f93cdd8f83661d114">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="bd3865342e2142369c8ea356885db10e">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,C" name="AUTOGEN_{A,C}" score="0"><feedback><p id="ce923e1bbd4a44d08c86b89345660cc8">Incorrect. </p><p id="cb5ed77af5844020b612ea9e21ccf996">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="eb9124e755164573aa7b5cf2f3b4af47">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="a33d3f3728704c318c4795069d4008fd">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="aca63f6bb0e74d408b1686a9e042d79c">Incorrect. </p><p id="a889723d07c04b25b11b33a94c32aac2">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="c2712ef279eb411b8af21b9620750342">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fd6ded0fda6a4548b71d847ccb3b1dc5">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="dee6fe7013b441c3a8d5f25604998680">Incorrect. </p><p id="ad728e801e15468499ddcbfa6db99121">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d8536e887331454b8a185eeb55a65d48">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="f79708a4764e4a72a1fe257256663f47">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,C,E" name="AUTOGEN_{A,C,E}" score="0"><feedback><p id="e1fa82c4b8cb46a3a3baadcd2303ef4e">Incorrect. </p><p id="c76d7dd8ed954973b8d56923c93c61ab">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="b73cba02a64141b2bf8da900911e8c7d">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fa376804ca5e4a43a36b03a395348757">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,D" name="AUTOGEN_{A,D}" score="0"><feedback><p id="e8e2b840247e44c19d7363abd2a88c40">Incorrect. </p><p id="a80db001d2604fe583a6fa7e1d27c9b9">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="fa997ea6f9e940f3823747719ff3e806">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="b6e71020b436447d8846bfdeaf6d3727">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="ec72e8b568164c02b44ff9d9b58906ee">Incorrect. </p><p id="b979d3d1c1cd4b139c83d361f89a2999">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="b5616ec100b84434879ae8f4b057a385">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="de3d6ccafb9f4c578129e970d0da8fac">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="A,E" name="AUTOGEN_{A,E}" score="0"><feedback><p id="cbed88d072f04be5a44f79db1c4ca572">Incorrect. </p><p id="c9ceddfb14b841e0824bacd3787c0c57">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e0b4083c06fe4f61b72142e8cf73dff0">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="e1861bc2963440c89f31c4db97189be8">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B" name="AUTOGEN_{B}" score="0"><feedback><p id="d9573b5c1720418a8e51ff090780f1ff">Incorrect. </p><p id="ffecbbf09e8049569c9ebbcfa9cd93c7">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="be5d9401cebf49e2b05b2e0092a060f7">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fd58748036784f7ca91eb98174fb1748">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,C" name="AUTOGEN_{B,C}" score="0"><feedback><p id="d9c95323245b4185bad482c629b52d87">Incorrect. </p><p id="bc48db8ec239460d975eb49d7b9ab937">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d745bf9c2e3b410d92d751a1f82dbf86">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="d352885d1342434ab7b2979cc99e610b">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="be045d45048745c8a841f9a7f67e6708">Incorrect. </p><p id="e9f6579cccf14d1a94670145316cbf72">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="b117e3148cbe49bf936436ce924294e7">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="b2c815c589d04dce963551cd941f315b">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="b19e5fabb2d44159b8b3bf2b62e15294">Incorrect. </p><p id="fa7975c89c0a425bb6deb1d43d9acf04">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="fbdec89389ba4cf28975c3612efacbcf">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="d382fe84bf4a448494b85281e7706823">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="ea9777494e374268be8235b29d918497">Incorrect. </p><p id="aa1663ca2b7b4c45ab28ba5ede832e04">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e19d642969b14ed2917de510b9218865">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="d97a294825bb4ea49d55f35c206b8edd">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="e6717f4bf7874582bf23b1c7f2d27c80">Incorrect. </p><p id="fbddb1a999b9416a81abb6fda1cff983">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="e8027d1d45f645349601eb4e084921ed">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="c28b08fad2884b398dd75cc3af087fcd">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="e302252a156c40a995da6a80ee43f372">Incorrect. </p><p id="aad5b06829264d12bff39fb6d158d569">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d8a2ec7dda6f4d1797793491cd54cda4">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="d503055fcf17464ab8ddad6079212f58">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="B,E" name="AUTOGEN_{B,E}" score="0"><feedback><p id="f7421fcea5bc4ef9bb663cc846e02da9">Incorrect. </p><p id="c53d61c1403c4994a12082efac99b811">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="fce055bab03349009e65c3f9ad537dac">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="edba2fcce01c4a9fab3fbc583053e7bf">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="d852ada6b86246aeb7f8b6f36766efe7">Incorrect. </p><p id="c846f97f90934c78bbd87ac823017ae8">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="dfe30633abe4413d97dc916ee3940ec9">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="fbbf66037c5642d98c2bb41816980c26">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="C,E" name="AUTOGEN_{C,E}" score="0"><feedback><p id="ba63fa2fcca5423182b75dea9efa7a0b">Incorrect. </p><p id="a3266929b10f41c29d2ab0d9d473c513">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="c7408071fc2e430788e3b490caff536b">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="a1cb6bfd4c9442b5b4cc8443ec3196cb">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="D,E" name="AUTOGEN_{D,E}" score="0"><feedback><p id="a4f6bbd8ddc04715a7f89c03db839fd6">Incorrect. </p><p id="b3eb32c69b854223b5a02b5e95a02a51">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d264e2eea0114daaadf438eb8092ee57">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="b7aaca7087554a8caf378afed2ff7e11">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response><response match="E" name="AUTOGEN_{E}" score="0"><feedback><p id="d2a8384166284d42a08eeb74c79ee21f">Incorrect. </p><p id="dae549b569f1463ea7f04dcf29bb54fa">A Type I error represents a false positive. So we conclude a significant effect even though no true effect exists.</p><p id="d2c872a9259641409df5cbbbdc8cb030">If the standard deviation is increased, it means the amount of variation (size of error) is greater. We want the minimum amount of variation, so the smaller the standard deviation, the better. The variance is the standard deviation squared.</p><p id="faf171067743440a80b6583e173a7463">Probabilities for Type II error are called \xce\xb2 (beta).</p></feedback></response></part></multiple_choice></page><page id="c77644e6214b49b9ae5bbf4140f78cd7"><title>Assessment Page Title</title><content available="always"><p id="f136f4e056a8443bb61080a7880a1581">For questions 13-15, imagine you are working on a large-scale randomized controlled trial examining the effect of a drug, comparing the results between a control group and a test group of people with an undisclosed illness. </p></content><multiple_choice id="bee1eafd282b4954b1386499493336ee" grading="automatic" select="single"><body><p id="acfea8f9a3cc4d30b14602f7ab5a905d">What is are potential null and alternative hypothesis for this scenario?</p></body><input shuffle="true" id="ddf3c38128654c2ea944e096c1a18c3b" labels="false"><choice value="f24ab7a988ee452ca9a18734cf3e6471">The null hypothesis is that there is no difference between the effect of the drug on both groups, and the alternative hypothesis is that there is a difference between the effect of the drug on both groups.</choice><choice value="d65d5882bad8485ab09d02ec6363cfa9">The null hypothesis is that there is a difference between the effect of the drug on both groups, while the alternative hypothesis is that there is no difference between the effect of the drug on both groups.</choice><choice value="ced1ad6f1028473eafc838c17b6cbf3b">The null hypothesis is that there is no difference between the demographics and lifestyles of the two groups, whereas the alternative hypothesis is that there is a difference between the demographics and lifestyles of the two groups, and thus that the trial is invalidated.</choice><choice value="f87969b58e7b41cf97ef247e0f9ed008">The null hypothesis is that there is no causal difference between the effect of the drug on both groups, and the alternative hypothesis is that there is a causal difference between the effect of the drug on both groups.</choice></input><part id="a7f7d32faa13428285f712c8418dbf79"><response match="f24ab7a988ee452ca9a18734cf3e6471" score="10"><feedback><p id="ff0059780c8f4665b0c3a70b6b6803ea">Correct.</p></feedback></response><response match="d65d5882bad8485ab09d02ec6363cfa9" score="0"><feedback><p id="c9cbea3c33eb4af89951e0c497840bba">Incorrect. As you\xe2\x80\x99re working on trying to see if the drug has an effect, performing this particular test can only disprove that your drug has an effect. </p></feedback></response><response match="ced1ad6f1028473eafc838c17b6cbf3b" score="0"><feedback><p id="f5fbb481c91c47929c066b8f2e7ac147">Incorrect. As you\xe2\x80\x99re studying the effect of a drug on a randomized-controlled trial, you\xe2\x80\x99re looking to statistically determine if the effect you found is significant, rather than if the trial was run properly.</p></feedback></response><response match="f87969b58e7b41cf97ef247e0f9ed008" score="0"><feedback><p id="ca613a7b57ee4db6bd7ecc59a1e179ef">Incorrect. Statistical tests cannot determine causality.</p></feedback></response></part></multiple_choice></page><page id="ac2f8b87411d4a2fb228b22438bd58e7"><title>Assessment Page Title</title><content available="always"><p id="c83867e3703d426c83b0aacbac1d2276">For questions 13-15, imagine you are working on a large-scale randomized controlled trial examining the effect of a drug, comparing the results between a control group and a test group of people with an undisclosed illness.</p></content><multiple_choice id="b64e88dc0e544c8d9fd21c72ea84634b" grading="automatic" select="single"><body><p id="ef2b1923a9294fd2a675cfb024f24015">Without the drug, the baseline survival rate of this illness is 95%. With this additional information, what kind(s) of t-test should you run, if you want to determine if the drug is effective in saving patients?</p></body><input shuffle="true" id="d23a6faafd0648709bef99ba8a560476" labels="false"><choice value="f923dbe87be74b01a86fa71d9f7343a7">A one-tailed t-test.</choice><choice value="d5e2d72cc5c44f3d87b8b2d8c8804c6e">A two-tailed t-test.</choice><choice value="a0678147bbca4237afec01c01ac3370f">A Friedman test.</choice><choice value="f2bb454601174379b317cd73b47dc4ae">All of the above.</choice><choice value="a8ae11c6ee3f48839dc544fa4e0378f7">None of the above.</choice></input><part id="da9e28aedd554eb4a8cc1938c274d9ae"><response match="f923dbe87be74b01a86fa71d9f7343a7" score="10"><feedback><p id="c03b3d3af93946969da3f14337ea5667">Correct.</p></feedback></response><response match="d5e2d72cc5c44f3d87b8b2d8c8804c6e" score="0"><feedback><p id="d0b55c574b6a4f2890f23c78911551a5">Incorrect. A two-tailed t-test would only tell you if there is a difference between having the drug or not in survival rate. It wouldn\xe2\x80\x99t tell you if the drug is decreasing survival changes.</p></feedback></response><response match="a0678147bbca4237afec01c01ac3370f" score="0"><feedback><p id="cccb434b7df84e44a96c87f7e071e414">Incorrect. As we only have two such choices, we do not need to use this test for this particular scenario.</p></feedback></response><response match="f2bb454601174379b317cd73b47dc4ae" score="0"><feedback><p id="aa8fa3c7476f45e4a3fae466449f3de4">Incorrect. The single-tailed t-test would tell us everything we needed to know about our experiment, that the other two tests would tell us about.</p></feedback></response><response match="a8ae11c6ee3f48839dc544fa4e0378f7" score="0"><feedback><p id="c0723ed36f6a420784b84a49f81e5a48">Incorrect. We should run a one-tailed t-test.</p></feedback></response></part></multiple_choice></page><page id="e2876644215e46cc96c1d29fb16ff7a3"><title>Assessment Page Title</title><content available="always"><p id="fc35b417ee8a4835969e549ac4374f71">For questions 13-15, imagine you are working on a large-scale randomized controlled trial examining the effect of a drug, comparing the results between a control group and a test group of people with an undisclosed illness.</p></content><multiple_choice id="e5e782243a024af08fe48a26ffa62374" grading="automatic" select="single"><body><p id="a2c10e3483284501a0aabc04c79ce184">After performing the t-test, you find out that your p-value is 0.001, and your alpha-value is 0.05. What can you conclude about this test?</p></body><input shuffle="true" id="e5d6dc6e10a24b6e8aaed80ca9aaf09d" labels="false"><choice value="c90ac6f471c8464baf5c333a83dd8391">As the p-value is less than the alpha, we have a statistically significant result. We can successfully reject the null hypothesis.</choice><choice value="c8050366d781487289250388bc249e15">As the p-value is less than the alpha, we have a statistically significant result. We can successfully accept the alternative hypothesis.</choice><choice value="fc45cc8b83d94149b0b3e19d34ccf56b">As the p-value is less than the alpha, we do not have a statistically significant result. We can accept the null hypothesis.</choice><choice value="a26e887dcc3b4295b9b9888f08a79a9b">As the p-value is less than the alpha, we do not have a statistically significant result. We, therefore, fail to reject the null hypothesis.</choice></input><part id="edbb450c82c146df87ac89350968d8ff"><response match="c90ac6f471c8464baf5c333a83dd8391" score="10"><feedback><p id="f3f1dd9d09e0473db2bddac22faa071e">Correct.</p></feedback></response><response match="c8050366d781487289250388bc249e15" score="0"><feedback><p id="ce7dac8be4024bbf8ac9c99bb00aeb18">Incorrect. Generally, we do say the words \xe2\x80\x9caccept the alternative hypothesis\xe2\x80\x9d in a statistical test, but instead say \xe2\x80\x9creject the null hypothesis\xe2\x80\x9d to convey that, for this experiment and data, it\xe2\x80\x99s unlikely that the null hypothesis remains true.</p></feedback></response><response match="fc45cc8b83d94149b0b3e19d34ccf56b" score="0"><feedback><p id="e384af5510c7492890eebb16866ee00b">Incorrect. When alpha is greater than our p-value, we have a statistically significant result.</p></feedback></response><response match="a26e887dcc3b4295b9b9888f08a79a9b" score="0"><feedback><p id="cd57214c9a1d43afa1a48bef0895028d">Incorrect. When alpha is greater than our p-value, we have a statistically significant result.</p></feedback></response></part></multiple_choice></page><page id="d14482c5da0844e7b93710a22092eafe"><title>Assessment Page Title</title><multiple_choice id="b6b3584b78d54bf3a37077ea3a889065" grading="automatic" select="multiple"><body><p id="da844212272944a7b88298c915f51ba2">The average male height (AMH) in the United States is 5\xe2\x80\x999\xe2\x80\x9d. Company A employs 250 male employees, and company B employs 20 male employees. Select all correct statements according to the Law of Large Numbers.</p></body><input shuffle="true" id="fcf6e3752ffd43799b51e6a722abe49e" labels="false"><choice value="A">Company B has a greater probability of having an AMH greater than or equal to 6\xe2\x80\x991\xe2\x80\x9d than does company A.</choice><choice value="B">Company B has a greater probability of having an AMH less than or equal to 5\xe2\x80\x997\xe2\x80\x9d than does company A.</choice><choice value="C">The tallest male employee in company B is more likely than not taller than the tallest male employee in company A.</choice><choice value="D">The tallest male employee in company A is more likely than not taller than the tallest male employee in company B.</choice><choice value="E">Company A has a greater probability of having an AMH greater than or equal to 6\xe2\x80\x991\xe2\x80\x9d than does company B.</choice></input><part id="d0fd0549d91444cabc8edac6f6b49d06"><response match="A,D" score="10"><feedback><p id="f1a4c2d1130446599e7af90f40457771">Correct!</p></feedback></response><response match="A" score="5"><feedback><p id="daf4bea522d547f08ed6eba894995137">Partially correct. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value.</p></feedback></response><response match="D" score="5"><feedback><p id="b5a700a0069e486e92d72494afe5c851">Partially correct. Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B" name="AUTOGEN_{A,B}" score="0"><feedback><p id="dbdfd9e8958848d78937d67f2c2d535e">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="c239e53b06c84546961dacc12089ff1c">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="bbe781764daf4c48b7ad1885827a8a43">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d0b28809fad14427a4e3ef63aafae5e7">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="ab717c3f8c9f441d81a79215bbbc18ee">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="e47e28dc493c40e483d0a276d6c39134">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="edb1580702e64638b6098b72bb300e3e">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="fddc7b8bddb2407caafaf8801ccbf26b">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="f4f8c41e67a946baaeef8f9f0f9bd2d6">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="f592c59636344dada4775bb5bc52a458">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="be4282b63e8e45c4b8961633a0c7805f">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="b149a552c5de42d1bff7252d4cdecec7">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="f56ec742d14446d9b1fcc49cdce7a1e8">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="bcd0d3b13c8d4f1e830867f24b28f0da">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="f3ae2022006e40dbb719c70c4353453e">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d72db351adf34564b9d23ba058108590">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,C" name="AUTOGEN_{A,C}" score="0"><feedback><p id="bdb11c5a4af04507ba381aa3a4b62e0e">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="bbf6d08a75954038b11ad2d80b6ec242">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="aa02c076d38b4e6e99b78b3b6c5466d8">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d7722c4eb70a45e98fb8bc1a70fca7fa">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="e9a25f9f94ad4637b0cbf6a213a1953e">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="e830dae3c0e44549826d3f5910f41889">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,C,E" name="AUTOGEN_{A,C,E}" score="0"><feedback><p id="d41dcc45f78641d28d8f211c8ed5d317">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="bc3c5ac1e1ba45eaba41b894617b884f">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="a63a2041dd784391aab8c00aa3e971f4">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d01281cc38b24f38a592375755e4bd57">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="A,E" name="AUTOGEN_{A,E}" score="0"><feedback><p id="be2348dc2f5f4f6eb7d3c35926cb7ebe">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="efe1067114d543fa8c80355c22cd8ff2">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B" name="AUTOGEN_{B}" score="0"><feedback><p id="e2301c3323eb4734a9e8b8aa25e4b42d">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="c4c1eec59de8408093f4a5e8611932e3">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,C" name="AUTOGEN_{B,C}" score="0"><feedback><p id="d25f5bc943fb462e95c560e7efeeeb9b">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d0cffbfdce2949fd953f92bda591e411">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="c967395d1ebf450884d6d21aca0fc1aa">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="ab05c152a24b44d9948c224d42d8f0bd">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="e7295239e5a848b1a839fe4ecf27a260">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="f63edb84da41413992dd7a87e4d39d7a">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="d9a12f02a26340289068b7e6ec7d1792">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="babed3885356464a8da2bfe80ba52357">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="c85d915696b64099870b028b85731752">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="ecfcffbca80a4276a4dd1b009567c2d4">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="dce9bbe2791645868ff39bab85ea13ae">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="bc2c26f32b304b88a49c988f3a42b8d3">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="B,E" name="AUTOGEN_{B,E}" score="0"><feedback><p id="fde77d5c39b64869aa1381df8f6d0129">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d1e33e1dc950499da600f2b643c1a5a9">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="C" name="AUTOGEN_{C}" score="0"><feedback><p id="f52ed7376c2c43228177ea0db5cd1afb">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="c11012b6293e43489ac2b631636f5dea">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="C,D" name="AUTOGEN_{C,D}" score="0"><feedback><p id="dc2b807298094ea49aa224e60d3149dc">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="ff87601f17f84f7ba03657857fe49bd6">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="b2b611ecfc5b4daf84a8dc08a56ea087">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="ceee8490b307444fbde5b597758b7dee">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="C,E" name="AUTOGEN_{C,E}" score="0"><feedback><p id="c0ad98f4837e4d9da415434974334232">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="ce56d5d105c04a1eb58ab4866db4f91a">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="D,E" name="AUTOGEN_{D,E}" score="0"><feedback><p id="f8e6c8aca443447184535327b5ab2ba6">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="f6c50bfb3c754dd0ae8406b794f39804">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response><response match="E" name="AUTOGEN_{E}" score="0"><feedback><p id="bf1c78e83bfd41368c1950430d3b5dbb">Incorrect. Because company A has more male employees than B, the average male employee height of companies of A\xe2\x80\x99s size has less variance than the average male employee height of companies of B\xe2\x80\x99s size. Because the variance of the average is smaller, A has a smaller chance of getting an extreme average value. </p><p id="d3406c7823d5409bb7d6f0e401ffb37c">Company B has fewer male employees. Therefore, they have fewer chances of getting a tall individual male employee.</p></feedback></response></part></multiple_choice></page><page id="b96e2136f12b447b83fa2434facf8584"><title>Assessment Page Title</title><multiple_choice id="c992f2f08365483484efd88c060619db" grading="automatic" select="multiple"><body><p id="fff9855f65a7462cb0c6f6143512a3b2">Which of the following statements is true about the Measure of Centrality?</p></body><input shuffle="true" id="e325e790022845e9a56074fbe1a31a67" labels="false"><choice value="A">The median will tend to be lesser than the mean for variables with a positively skewed distribution.</choice><choice value="B">The mean, median, and mode should always be reported for normally distributed variables.</choice><choice value="C">A positively skewed variable has a long right-hand tail when drawn as a histogram.</choice><choice value="D">The mean should be reported as the measure of central tendency for data with a left-skewed distribution.</choice><choice value="E">The median should be reported as the measure of central tendency for data with a right-skewed distribution.</choice></input><part id="b823a514b191478194cf527f7d625d00"><response match="A,C,E" score="10"><feedback><p id="bd3f720feaf84dbead1ad29394dd5152">Correct.</p></feedback></response><response match="A,C" score="7"><feedback><p id="efc99a8b62814f2abceb4cb055500b29">Partially correct. </p><p id="b62f26e0a3a7431196724cb2cf1294ed">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="e2da513cbb464e048766abf1025c995b">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,E" score="7"><feedback><p id="f404b78e8da249c2b1968ef6085d927f">Partially correct. </p><p id="edcab628214b48c491ffc9c0d0b51710">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="b27e8db18a7c4c91aafa5bf9aa524fdd">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="C,E" score="7"><feedback><p id="b4ff05bbfd3f44d9b0b346eb10a79217">Partially correct. </p><p id="b0bccd87f11649a9b055a7e5231386f8">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="f9acb2dd2de34799b94040bf1301d553">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="C" score="4"><feedback><p id="a08dad9ac49e4709a9cc74b888040423">Partially correct. </p><p id="ca7f32d81b88437589b7e0a56403a5e6">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="b957ab73fccb4b72b3fc990f3c3054fc">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="E" score="4"><feedback><p id="b3f7f53f042a449b9b0cf7fd54e9a5b1">Partially correct. </p><p id="e8eb4d1a3b6449219bb2be44333fcdcb">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="f6e8a873abc941b08b510f54f1f96d29">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A" score="4"><feedback><p id="d0318a6ed1124372bd760eeee171513a">Partially correct. </p><p id="c39a63bd317740b8a557ca758344eba9">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="cbf4d728609747a296bf490149cf69e1">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B" name="AUTOGEN_{A,B}" score="0"><feedback><p id="d85aa0740ff74070816a0346efe34c01">Incorrect. </p><p id="e4d8855d4b714c5dbe2feba16de41f06">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="ba725ace0f1a4e42a15ef1eb5f95bad9">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,C" name="AUTOGEN_{A,B,C}" score="0"><feedback><p id="fd0d26cc9ecd4aba8b4eba237f92a291">Incorrect. </p><p id="d3cb54286c0741adb9dac0d03f87c436">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="d9876922b9b840c2898e1c13d1207d0d">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,C,D" name="AUTOGEN_{A,B,C,D}" score="0"><feedback><p id="cb945d4690d24e1ebad2e6275e1aaff1">Incorrect. </p><p id="d12ae7dbb77746a4adc827e9116debfc">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="ceff54f71b0d4274aacb233d4e93395f">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,C,D,E" name="AUTOGEN_{A,B,C,D,E}" score="0"><feedback><p id="ee02fab9c06e43e1bb138763e2147ebc">Incorrect. </p><p id="c45a0a3fc9e7453281953a3d225e0a26">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="a36505a2102d4b09b2be4fab2c081cd2">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,C,E" name="AUTOGEN_{A,B,C,E}" score="0"><feedback><p id="f01ffad1fd584dfb8c944e34fa1f76cf">Incorrect. </p><p id="a07a3096c46a479e8ee2ca43ac76ec68">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="aa02af1672084d7c9cbfd7c9c93555ec">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,D" name="AUTOGEN_{A,B,D}" score="0"><feedback><p id="fc3644e2d9344ae89f06dc8838c06df1">Incorrect. </p><p id="b69dfa9a03124b18b33b04351141f150">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="a693498ced204e5bb9968ee7e64b1a6d">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,D,E" name="AUTOGEN_{A,B,D,E}" score="0"><feedback><p id="d068cb33b1a34c7fa4b0cf4375bc7777">Incorrect. </p><p id="d437a48c2a254c6f813d5c32cb06966d">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="a863a1132df04505a514e43783fc0b4a">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,B,E" name="AUTOGEN_{A,B,E}" score="0"><feedback><p id="e49072712a50444db1d7a834421c510a">Incorrect. </p><p id="ea647338722d4dcc93890cd9e2668165">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="c008ea7a09f84b7db9c8e8ca404eb7ea">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,C,D" name="AUTOGEN_{A,C,D}" score="0"><feedback><p id="bfd5918cb5d34e9691c20aa8785073bf">Incorrect. </p><p id="e5e71a7ff13247549c12258b71344dcf">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="bb5e997e1b3545a09dfb587b004aa0cb">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,C,D,E" name="AUTOGEN_{A,C,D,E}" score="0"><feedback><p id="fed89c0a2e8f4268979e5cea4dc03c2c">Incorrect. </p><p id="acff36dd4f4f4ad29923810cf8abf9f3">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="facf34cb394d405c982692314e309cad">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,D" name="AUTOGEN_{A,D}" score="0"><feedback><p id="cf006ffdee7d4685b50abaa49b0ad636">Incorrect. </p><p id="e90956b5af9b4b1bb577e8c86dc1110f">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="cba287bd232e4f82982c9453e1990b32">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="A,D,E" name="AUTOGEN_{A,D,E}" score="0"><feedback><p id="d010b76bb1f34858a93683837120dbd1">Incorrect. </p><p id="ad9e6b6a75134153bc0fe6e4be188cc3">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="a03a79f34b4941c69c89189eb09f8a6a">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B" name="AUTOGEN_{B}" score="0"><feedback><p id="a9450c4190e64cbc8909d4c392b55ac7">Incorrect. </p><p id="c85113021c024b8ab9797b72f434dcaa">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="c6c00faf864c4d3ab6316b72379bd3ca">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,C" name="AUTOGEN_{B,C}" score="0"><feedback><p id="e67596ec05ee4f87b75c1680f1a2762f">Incorrect. </p><p id="fd795551bd204b10b96306645280396e">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="ba47a0c4e81f45b99e48b389754b3ac0">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,C,D" name="AUTOGEN_{B,C,D}" score="0"><feedback><p id="b4538186a3164903947e9ce18569e605">Incorrect. </p><p id="a3849ab02e284e06bad4ce40fed9c63b">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="fe5a77d53fb04bf48cd148b68bf92aaa">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,C,D,E" name="AUTOGEN_{B,C,D,E}" score="0"><feedback><p id="e29842a35e794cdcb62e34f40cb4d93e">Incorrect. </p><p id="d724577f24624f318a2e9ec29f94ed90">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="d7c3b1ccfb194f3ea0950832d8fc0795">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,C,E" name="AUTOGEN_{B,C,E}" score="0"><feedback><p id="f8fe57d64ecc42c692227fe461fdc0aa">Incorrect. </p><p id="f510f7aa6b3d4056b75a42fa54393128">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="fe074e03e3134994876236704ea1e0ee">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,D" name="AUTOGEN_{B,D}" score="0"><feedback><p id="bc579dafe15f40b3be16b027dec287b8">Incorrect. </p><p id="bf9556b8f3f7427986ed1d39d2639812">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="e5c5eb3e00ab4ea6af0dea2af848476f">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,D,E" name="AUTOGEN_{B,D,E}" score="0"><feedback><p id="c51f1946d6e64e7a95c592b3f5bc97c3">Incorrect. </p><p id="d3c236f94b1540529da5ae0e44b7d872">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="c9f65cea9eb5461bad771d91d617e647">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="B,E" name="AUTOGEN_{B,E}" score="0"><feedback><p id="c2d9294aeb224804ad39af43e27019ca">Incorrect. </p><p id="a67c8ba19266421bb1776772a21952e7">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="bc216bb1867344728f58e22df83612e5">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="C,D" name="AUTOGEN_{C,D}" score="0"><feedback><p id="b7b02b5ddbfb4062aa6d5278c8491bc3">Incorrect. </p><p id="bbfec314e763402b929f26be3f44d39c">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="b83b2ba013f04719ad03aed3beccf08e">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="C,D,E" name="AUTOGEN_{C,D,E}" score="0"><feedback><p id="b3185589b9b7471d90490403ee89de6a">Incorrect. </p><p id="c3ede50602494846a5e04a6f5a85600a">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="e98ed053e2c14a1aa95e9fe3037b4408">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="D" name="AUTOGEN_{D}" score="0"><feedback><p id="c4c816ae0d8f4b99a2b301e51be5ba80">Incorrect. </p><p id="e6ccbd73480c4008ad9863374b83e4a2">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="dc687a1d4df94a51b172e3d364ec280e">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response><response match="D,E" name="AUTOGEN_{D,E}" score="0"><feedback><p id="bfb6169271ee49fda45878726f0c55f9">Incorrect. </p><p id="d3632773af964a29860dd073eba0f814">It is not necessary to report all the measures of location. The types of data should first be identified. If it is categorical data, then use the mode. If it is continuous data, then the distribution of the variable should be assessed.</p><p id="c0eefbfb73ee4e89b2451a125aa709eb">The mean is highly affected by outliers and extreme values when the distribution is skewed; therefore, it should not be reported as the measure of central tendency for data with a skewed distribution.</p></feedback></response></part></multiple_choice></page><page id="d2e0f0db4a3042c18c3fb09b09d15b76"><title>Assessment Page Title</title><multiple_choice id="c43f9d3962ac4208ae2c821f320d9f98" grading="automatic" select="single"><body><p id="af4bdf0baf0e4a3e8e9c7a67322bb34b">Suppose you have \\(N\\) data points consisting of a \\(D\\)-dimensional dataset \\(X=\\left\\{x_{i}\\right\\}\\) for \\(i=1...N\\). You run a PCA and choose \\(k\\) principal components. Can you reconstruct any data point \\(x_{i}\\) in \\(X\\) that exactly (i.e., with zero error) from the \\(k\\) principal components?</p></body><input shuffle="true" id="cf5fb15bf5db4d4ea521cb6e9d9f5fb8" labels="false"><choice value="dfaa6c2ff14a4f558dbbfe3df311d476">No, never.</choice><choice value="f6b78baec7204bab8213bf7cb99fd441">Yes, but only if \\(k\\lt N\\).</choice><choice value="eb87acbd770946baa9a8f749c40e4fc4">Yes, but only if \\(k\\lt D\\).</choice><choice value="d0aaa56fd84c47d2a6ee9e63ab8fb9a9">Yes, but only if \\(k=D\\).</choice><choice value="c5d22f17343a44b69f4266f005390c1e">Maybe, we need more information to tell.</choice></input><part id="b8c84221f6fa458894620b43d4a03a7c"><response match="dfaa6c2ff14a4f558dbbfe3df311d476" score="0"><feedback><p id="bf7a1b9d19c64f79b5e144f9fc153551">Incorrect. You can do so but only if \\(k=D\\). Any data point \\(x_{i}\\) in X can be reconstructed from the k principal components with zero error only if the number of principal components equals the dimensionality of the dataset. In other words, when running PCA to reduce the dimensionality to k principal components, there will always be errors. The only situation of zero error is when you reconstruct all data points into equivalent principal components.</p></feedback></response><response match="f6b78baec7204bab8213bf7cb99fd441" score="0"><feedback><p id="c09cf64826c84f34831640a9f4ed419c">Incorrect. You can do so but only if \\(k=D\\). Any data point \\(x_{i}\\) in X can be reconstructed from the k principal components with zero error only if the number of principal components equals the dimensionality of the dataset. In other words, when running PCA to reduce the dimensionality to k principal components, there will always be errors. The only situation of zero error is when you reconstruct all data points into equivalent principal components.</p></feedback></response><response match="eb87acbd770946baa9a8f749c40e4fc4" score="0"><feedback><p id="db05f3ce003a475c9283f6862b67d137">Incorrect. You can do so but only if \\(k=D\\). Any data point \\(x_{i}\\) in X can be reconstructed from the k principal components with zero error only if the number of principal components equals the dimensionality of the dataset. In other words, when running PCA to reduce the dimensionality to k principal components, there will always be errors. The only situation of zero error is when you reconstruct all data points into equivalent principal components.</p></feedback></response><response match="d0aaa56fd84c47d2a6ee9e63ab8fb9a9" score="10"><feedback><p id="af413e7a932e4f208f8b737379a74c2a">Correct. Any data point \\(x_{i}\\) in X can be reconstructed from the k principal components with zero error only if the number of principal components equals the dimensionality of the dataset. In other words, when running PCA to reduce the dimensionality to k principal components, there will always be errors. The only situation of zero error is when you reconstruct all data points into equivalent principal components.</p></feedback></response><response match="c5d22f17343a44b69f4266f005390c1e" score="0"><feedback><p id="e9e10e52adaa46848de54cc8c2d46f9c">Incorrect. You can do so but only if \\(k=D\\). Any data point \\(x_{i}\\) in X can be reconstructed from the k principal components with zero error only if the number of principal components equals the dimensionality of the dataset. In other words, when running PCA to reduce the dimensionality to k principal components, there will always be errors. The only situation of zero error is when you reconstruct all data points into equivalent principal components.</p></feedback></response></part></multiple_choice></page><page id="d7e5b88e235b49bb8883c4893df49de1"><title>Assessment Page Title</title><multiple_choice id="dd4e34be681445a4b26986d85a73d49d" grading="automatic" select="single"><body><p id="d2068ceef44e42a9a05baaad1db71b6c">The following statements attempt to explain why \xe2\x80\x9ccorrelation does not imply causation.\xe2\x80\x9d Which of these is (are) true?</p><p id="e934e007b68a4f0fb6d968cda78f27b0">I. Both the divorce rate and the crime rate have an increasing trend over a 10-year period. Despite having a positive correlation, this does not imply that an increasing divorce rate causes the crime rate to increase. They would also be positively correlated with all other variables with positive time trends, such as the average selling prices of homes or the percentage of people who use smartphones.</p><p id="adecc112aff64fcbae7c32d1540bafb0">II. Some medical studies have found associations between coffee drinking and the likelihood of a heart attack. Although they thought they had found a causal relationship, taking into account other variables associated with the extent of coffee drinking, such as occupation and stress levels, the association has disappeared or weakened considerably. This is because the researchers have not thought of an alternative explanation.</p><p id="f84422526f994122aac96357d7a093cd">III. Studies dealing with human longevity found that in many nations, life length was positively associated with educational attainment. Maybe researchers believe that education is the most important variable in explaining how long a person lives. However, in some societies, perhaps the causation could go in the order direction, such as sick children not going to school or dropping out early due to their health. As education can be the cause for higher incomes and hence better healthcare, the original correlation is found to indeed be causation.</p></body><input shuffle="false" id="d7020deb68fd4454ad7983796653c995" labels="false"><choice value="e41679f2fc3e41fa98651c7071659c5f">I only.</choice><choice value="c8769948e28d43c4949eb2c9722977fc">II only.</choice><choice value="f85374b891894d61ac0cf76bdde31e2a">III only.</choice><choice value="fb287fdcb8094719a0f3d45790abfdad">I &amp; II</choice><choice value="a6969acf8d7e407492c0d16dfc38a629">II &amp; III</choice><choice value="bab572178a2e47328b9cff4c5029bcb4">I &amp; III</choice><choice value="e18ce6853bc845aa88b45f27c41af0eb">I, II, &amp; III</choice><choice value="fc58e6a45f2044a7af53008fbbe649f9">None of these statements are true.</choice></input><part id="c668b6d8b7134b5bb97e51523e2a31d9"><response match="e41679f2fc3e41fa98651c7071659c5f" score="0"><feedback><p id="c6d12d1b878249b394af2185a42ae921">Only statements 1 and 2 are true.</p><p id="a7f62776fb9a4f9bb1d0a7cec29c0371">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="eba1694c46fc472c9fd2d860d689846c">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="cfc01424796a48af829de71867186b96">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="c8769948e28d43c4949eb2c9722977fc" score="0"><feedback><p id="b42c8dd9d9d140f5a2a2ee4c806e6918">Only statements 1 and 2 are true.</p><p id="cdd36a11accc4f3e9be7a7ea00b8cbaa">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="e6bb8647e524443fb7d635db34a152f1">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="c21a40a19e9c42a48ac2728d5cfa6462">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="f85374b891894d61ac0cf76bdde31e2a" score="0"><feedback><p id="e641b200ac7d4df0973494e904140f0b">Only statements 1 and 2 are true.</p><p id="bb96d7e9be9d408d955f11b0d84677c5">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="e554612214464232b4aa75166a5e18cb">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="f313e9a47809495fad75544c1c7a32d1">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="fb287fdcb8094719a0f3d45790abfdad" score="10"><feedback><p id="d74e38ecc5f4495891fe64ddbf94c536">Correct.</p></feedback></response><response match="a6969acf8d7e407492c0d16dfc38a629" score="0"><feedback><p id="a851c6bc1ac940218a462aae92e21e4a">Only statements 1 and 2 are true.</p><p id="ae445675bd0e4d968a7db5e161ad1815">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="edaa2b84823b49558b8e801470d75462">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="ecbab12dd8b2497eaf4036dd311d868d">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="bab572178a2e47328b9cff4c5029bcb4" score="0"><feedback><p id="d760e1000dc44d399da88e5b4be5bad5">Only statements 1 and 2 are true.</p><p id="ca622c51bcb74e3a8305e9072bb41bcf">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="b7d3025be84c434b8b4564487e1fe8db">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="ab625a60e6714d60836aa4a44ed421dd">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="e18ce6853bc845aa88b45f27c41af0eb" score="0"><feedback><p id="fe4b6f300cd449ae825fa3d545e92b4f">Only statements 1 and 2 are true.</p><p id="ba241aa17b12411aa57a38168c398661">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="dd03457ab4da4a1fb791d049aeb362d7">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="c1766671e2ce451cb899540c02f38817">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response><response match="fc58e6a45f2044a7af53008fbbe649f9" score="0"><feedback><p id="cad0c9ac3c16494eade01e437bca450f">Only statements 1 and 2 are true.</p><p id="d1a6e13906b14b7a89ff92fe5c9db034">This is the time order criterion of causality. It is difficult to study cause and effect when two variables do not have a time order but are measured together over time. The variables may be associated merely because they both have a time trend.</p><p id="b30018e518f443089ed9769e8cf89cf8">Suppose we have an association between two variables and proper time order to satisfy a causal relationship; it is still insufficient to imply causality because there may be an alternative explanation for the association.</p><p id="cfcda4fa3f6b4bbfa62a8fa1b5ecfad7">The correlation does not imply causation. This is an example of a chain of causation in which \xe2\x80\x9cincome\xe2\x80\x9d is a mediator variable. The association between education and life length can disappear after controlling for income. If this happens, education does not directly affect life length, but it is an indirect cause through income.</p></feedback></response></part></multiple_choice></page><page id="e62c6e348b24496d82f968f66084ad99"><title>Assessment Page Title</title><multiple_choice id="baab447c024e4876b0faa8dc9f9415c9" grading="automatic" select="single"><body><p id="cde9ed3f5c83419e8fc2513e5b1b7f2d">Which one of the following is a cumulative probability?</p></body><input shuffle="true" id="e66c33028f2e415a89d1e11c54f31080" labels="false"><choice value="c5c50c824e2e494abe3804dd85ac28c8">The probability that there are exactly 6 people with Type A blood in a sample of 14 people. </choice><choice value="b753817f979d47fb861064d334af61b7">The probability of getting exactly 3 heads in 8 flips a coin.</choice><choice value="e8d6ed79f0f848b495c98d02930aa30a">The probability that the accumulated annual rainfall in a certain city next year, rounded to the nearest inch, will be 12 inches.</choice><choice value="d5633e6362994ab993325b6702bd8c17">The probability that a randomly selected person is 167 cm tall or less.</choice><choice value="f09349cd4e4845808dba6e15175860b0">The probability that it will snow on the second Thursday of November.</choice></input><part id="e6afd8f272d7425b8607d56c3b203c28"><response match="c5c50c824e2e494abe3804dd85ac28c8" score="0"><feedback><p id="af4f58fd10fc45eaaee240b251cd1c1b">Incorrect. The probability that a randomly selected person is 167 cm tall or less is a cumulative probability. The keyword is \xe2\x80\x9crandomly selected.\xe2\x80\x9d Cumulative probabilities refer to the probability that a random variable is less than or equal to a specified value. From the text, the commuting times on various days that the student records is a cumulative probability. </p></feedback></response><response match="b753817f979d47fb861064d334af61b7" score="0"><feedback><p id="d50e4d8cc6074b3d9dce5bd5a5865c76">Incorrect. The probability that a randomly selected person is 167 cm tall or less is a cumulative probability. The keyword is \xe2\x80\x9crandomly selected.\xe2\x80\x9d Cumulative probabilities refer to the probability that a random variable is less than or equal to a specified value. From the text, the commuting times on various days that the student records is a cumulative probability. </p></feedback></response><response match="e8d6ed79f0f848b495c98d02930aa30a" score="0"><feedback><p id="f78bd5b3e79349d0bb743253d32f40ca">Incorrect. The probability that a randomly selected person is 167 cm tall or less is a cumulative probability. The keyword is \xe2\x80\x9crandomly selected.\xe2\x80\x9d Cumulative probabilities refer to the probability that a random variable is less than or equal to a specified value. From the text, the commuting times on various days that the student records is a cumulative probability. </p></feedback></response><response match="d5633e6362994ab993325b6702bd8c17" score="10"><feedback><p id="b9d911ddb1ec4b5eb9df4bd2ee454821">Correct.</p></feedback></response><response match="f09349cd4e4845808dba6e15175860b0" score="0"><feedback><p id="d60887317fdd404497c61998cdfe8453">Incorrect. The probability that a randomly selected person is 167 cm tall or less is a cumulative probability. The keyword is \xe2\x80\x9crandomly selected.\xe2\x80\x9d Cumulative probabilities refer to the probability that a random variable is less than or equal to a specified value. From the text, the commuting times on various days that the student records is a cumulative probability. </p></feedback></response></part></multiple_choice></page></assessment>\n'