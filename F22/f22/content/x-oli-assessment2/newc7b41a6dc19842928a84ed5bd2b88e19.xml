b'<?xml version="1.0" encoding="UTF-8"?>\n<!DOCTYPE assessment PUBLIC "-//Carnegie Mellon University//DTD Assessment MathML 2.4//EN" "http://oli.web.cmu.edu/dtd/oli_assessment_mathml_2_4.dtd"><assessment xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" id="newc7b41a6dc19842928a84ed5bd2b88e19" recommended_attempts="3" max_attempts="3"><title>Quiz 9</title><page id="c9e7dade8fb341e48707b862aa6685bf"><multiple_choice id="c444a439db624bcb9e49f107a822c06e" grading="automatic" select="single"><body><p id="f7b3a1383b134156a8283d2481d89365">Which statement below <em>BEST</em> describes the agglomerative clustering method.</p></body><input shuffle="true" id="a8c62bc4a660428999ac8caa67ba9042" labels="false"><choice value="e3a912211cb241a1907affdd8616a7ef">A bottom-up approach that allows for each observation to be assigned to its own cluster at the start of the cluster analysis. </choice><choice value="ba467ad346d14bd4895efe48d9606d0d">A top-down approach that allows for each observation to be assigned to its own cluster at the start of the cluster analysis process.</choice><choice value="aff32d417e034f96992a5bcde5c29e19">An approach that can be done with either the top down or bottom up approach but requires that each observation is assigned to its own cluster at the start of the cluster analysis process.</choice><choice value="c6de2291a51a482992424d0a0b85636f">Each observation is assigned to a cluster and the number of clusters are pre-defined at the start of the cluster analysis process. </choice></input><part id="ba0746fdeb6b4fa393231beddbe6d7f7"><response match="e3a912211cb241a1907affdd8616a7ef" score="10"><feedback><p id="d138b0380dc54b929261ee076cece1fe">Correct: The agglomerative approach starts by having each observation in its own cluster and using pairwise computations, it clusters observations.</p></feedback></response><response match="ba467ad346d14bd4895efe48d9606d0d" score="0"><feedback><p id="b789db9eb915466ba412dbcbbc56c6ed">Incorrect: This is the divisive approach and not the agglomerative approach.</p></feedback></response><response match="aff32d417e034f96992a5bcde5c29e19" score="0"><feedback><p id="a867e8cb04ab4c67b982a8fd4c87c770">Incorrect: The agglomerative approach is a bottom up approach.</p></feedback></response><response match="c6de2291a51a482992424d0a0b85636f" score="0"><feedback><p id="e93d0abd2f5340d4b68d8e90a5f97d10">Incorrect: This definition is quite similar to the <em style="italic">k</em> means clustering technique.</p></feedback></response></part></multiple_choice></page><page id="cff0e0ec6dcf46ff8a65e8c4cdcac42f"><multiple_choice id="ac16eb95035144ca9a751b93ccbf2847" grading="automatic" select="single"><body><p id="b2fc1dd7a89d4932b639d1686063a363">Assume, you want to cluster 7 observations into 3 clusters using K-Means clustering algorithm. After the first iteration, clusters C1, C2, C3 have the following observations:\r</p><p id="f17a104189f2424fac098e5f329344ae">C1: {(2,2), (4,4), (6,6)}\r</p><p id="ee83ccd5884f412295f95f50927855d6">C2: {(0,4), (4,0)}\r</p><p id="a752c5e3de3c4132b5137f63180b68a2">C3: {(5,5), (9,9)}\r</p><p id="a7d56e6c3f8d429d869317f544662bfa">What will be the cluster centroids if you want to proceed to the second iteration?\r</p></body><input shuffle="true" id="e88beba814db45538fb14c71bd45b83a" labels="false"><choice value="e92055bf9c4549c184b9986c993da54a">C1: (4,4), C2: (2,2), C3: (7,7)</choice><choice value="e9096fcabd98437582fb02af9d2cf627">C1: (6,6), C2: (4,4), C3: (9,9)</choice><choice value="fe62a7729c8144e89e45bdba6357ab2d">C1: (2,2), C2: (0,0), C3: (5,5)</choice><choice value="fdc54984baa84160891af3d075d71855">None of the options.</choice></input><part id="d71b9b8877b84a11b22b2659dc4cad97"><response match="e92055bf9c4549c184b9986c993da54a" score="10"><feedback><p id="bdcb8ed922be4194acf65e94d4376474">Correct: Finding centroid for data points in cluster C1 = ((2+4+6)/3, (2+4+6)/3) = (4, 4)\r</p><p id="c53924f68ed4402c8dba4f126c32d732">Finding centroid for data points in cluster C2 = ((0+4)/2, (4+0)/2) = (2, 2)\r</p><p id="fb662e185d3a4fe989a31d68ef1d0d2d">Finding centroid for data points in cluster C3 = ((5+9)/2, (5+9)/2) = (7, 7)\r</p><p id="b7b0a56d28554043ae537be9adb06e35">Hence, C1: (4,4),  C2: (2,2), C3: (7,7)\r</p><p id="ab899fd4b9e0473e87b145597dc9ee15" /></feedback></response><response match="e9096fcabd98437582fb02af9d2cf627" score="0"><feedback><p id="b5601bbcf0304a2aab46089ffcc1a638">Incorrect:Finding centroid for data points in cluster C1 = ((2+4+6)/3, (2+4+6)/3) = (4, 4)\r</p><p id="a2976436a24f43c49b603f274836d137">Finding centroid for data points in cluster C2 = ((0+4)/2, (4+0)/2) = (2, 2)\r</p><p id="f9429e77f09648be91c102a732a247b2">Finding centroid for data points in cluster C3 = ((5+9)/2, (5+9)/2) = (7, 7)\r</p><p id="aef968116507414d8dc64dc603b1895f">Hence, C1: (4,4),  C2: (2,2), C3: (7,7)\r</p><p id="d3218bc60b6541e68307c0539a318d85" /></feedback></response><response match="fe62a7729c8144e89e45bdba6357ab2d" score="0"><feedback><p id="d5d519e927a84515b7049e7397d527f1">Incorrect:Finding centroid for data points in cluster C1 = ((2+4+6)/3, (2+4+6)/3) = (4, 4)\r</p><p id="f24a2b9ca4d248fcace9199c10908296">Finding centroid for data points in cluster C2 = ((0+4)/2, (4+0)/2) = (2, 2)\r</p><p id="f2d8234461504148b8a4c2f8ebc5a387">Finding centroid for data points in cluster C3 = ((5+9)/2, (5+9)/2) = (7, 7)\r</p><p id="a941803880e94810987d6665092c0a67">Hence, C1: (4,4),  C2: (2,2), C3: (7,7)\r</p><p id="fb57ba1d59154fb69db3406aa0e482aa" /></feedback></response><response match="fdc54984baa84160891af3d075d71855" score="0"><feedback><p id="df6c1965a99140d8b6775be02a85a43f">Incorrect:Finding centroid for data points in cluster C1 = ((2+4+6)/3, (2+4+6)/3) = (4, 4)\r</p><p id="f27aebe090a245b7a45dd6476511895b">Finding centroid for data points in cluster C2 = ((0+4)/2, (4+0)/2) = (2, 2)\r</p><p id="b7be50c45282493b98690de3aa4822f7">Finding centroid for data points in cluster C3 = ((5+9)/2, (5+9)/2) = (7, 7)\r</p><p id="e68e0997da6542f68eb674b378d5451b">Hence, C1: (4,4),  C2: (2,2), C3: (7,7)\r</p><p id="c1c7e5c2b9014d2487cf5319de694ce8" /></feedback></response></part></multiple_choice></page><page id="bb11b20b4ac14be7856548973fea112c"><multiple_choice id="a59717ece02143888e5e17fb30845435" grading="automatic" select="single"><body><p id="e62a0134d39e4317a69ae17902a4cb52">This linkage method states that the distance between two clusters, is how\r much the sum of squares will increase when those clusters are merged, it is also considered to be an alternative to the single linkage method:</p></body><input shuffle="true" id="ba91e304a80d40d4b1ce5e1b6a1b37cd" labels="false"><choice value="cc2632c24ddc4aa4865ca326d6f12893">Ward&apos;s Method.</choice><choice value="ceb0785dcac24845b1149e9fe2e22d55">Centroid Linkage.</choice><choice value="cfb51c0065684cf8ac2a25d74b317a48">Complete Linkage.</choice><choice value="ae7d6023981c48839a84212eaa513e04">Average Linkage.</choice></input><part id="a959a02ad0c0402f99ad700a5a35972a"><response match="cc2632c24ddc4aa4865ca326d6f12893" score="10"><feedback><p id="af4e7ac98ff544d798dfb897e216f368">Correct: This method will assess the variance of clusters and it is quite suitable for quantitative variables.</p></feedback></response><response match="ceb0785dcac24845b1149e9fe2e22d55" score="0"><feedback><p id="f2909b6c73c7431caf38cf12a461e28d">Incorrect: This method uses the centroid to determine the average distance between clusters.</p></feedback></response><response match="cfb51c0065684cf8ac2a25d74b317a48" score="0"><feedback><p id="d680c8ec2f124492b9812dc5ccc28ca4">Incorrect: This method involves clustering based on maximum distance.</p></feedback></response><response match="ae7d6023981c48839a84212eaa513e04" score="0"><feedback><p id="e1aa02d5bbad459c92e7a7a4e9380c71">Incorrect: This method is similar to the complete  linkage but the clusters are formed and the distance is measured  based on the average distance between observations in the cluster to other observations in another cluster.</p></feedback></response></part></multiple_choice></page><page id="ecccc888c57e4eb79e40b152898cf9f8"><multiple_choice id="e99ef792c9ca44709e6025a4ced3f8ed" grading="automatic" select="single"><body><p id="b33c04bd2e7a46bf92853c9c570fbf00">The output below (6 cities) shows the distance measurements for a dataset that has been clustered using <em style="italic">k</em> = 2. Cluster A and B centroids were computed and the measurements you see are the distance of each observation from each of the centroids. Which option below is the right grouping in cluster A and cluster B:</p><image id="fa66394c4c47494ba6332e6fb5ac021c" src="../webcontent/Cluster_Analysis1.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="cc0ddc8006ac476bb3ec925769e306c3"><em style="italic">Six &quot;Cities&quot; belonging to Clusters A and B</em></p></caption><popout enable="false"></popout></image></body><input shuffle="true" id="af17425e4fe640e2b0e0bc1e60a16994" labels="false"><choice value="c20a717f1c1d48c0ac29415452595741"><p id="b15f0a2e8f9f466da2b181f44bd33f34">A(Beijing, Dakar)\r</p><p id="c7a6d1a648c94002ae28163dd6268036">B(Paris, Abuja, Chennai, Seoul)\r</p></choice><choice value="bb0f58942cb3496bb7f4ed187567121f"><p id="d3a66cde4a7c41ca9b93666bf156e6c4">A(Dakar, Chennai)\r</p><p id="e57704b58aeb453388bda2fca49aadad">B(Paris, Abuja, Dakar, Seoul, Beijing)\r</p></choice><choice value="f7fa27aa39f54a4f9d10c631ab7d0a24"><p id="b9418c19ea8b41c18c8b412d1e5cbaa4">A(Beijing, Paris, Abuja)\r</p><p id="fe5c60d309fc4ccea762f3fa0ac6179e">B(Dakar, Chennai, Seoul)\r</p></choice><choice value="e1b2c8e9b70346ba8b9b4b909e27f5ad"><p id="c4c49fb170394af78083a0fab6851b7e">A(Paris, Abuja, Chennai, Seoul)\r</p><p id="e2c598a1c85d4f9da7a7a58b37a88f3d">B(Beijing, Dakar)\r</p></choice></input><part id="b4ac36b03f894a278795149523759b15"><response match="c20a717f1c1d48c0ac29415452595741" score="10"><feedback><p id="d1690aeeba9d4163bc77e3deb6683dbc">Correct: This is the right grouping!</p></feedback></response><response match="bb0f58942cb3496bb7f4ed187567121f" score="0"><feedback><p id="b230e685123341258f767fe0bb8f5af8">Incorrect: Compare both distance measures and cluster a city in the group where it has the lowest value.</p></feedback></response><response match="f7fa27aa39f54a4f9d10c631ab7d0a24" score="0"><feedback><p id="afb23d9becb64b68bdcba67faf295f4e">Incorrect: Compare both distance measures and cluster a city in the group where it has the lowest value.</p></feedback></response><response match="e1b2c8e9b70346ba8b9b4b909e27f5ad" score="0"><feedback><p id="e0fce240703746e38c6cc635f6b37103">Incorrect: Compare both distance measures and cluster a city in the group where it has the lowest value.</p></feedback></response></part></multiple_choice></page><page id="df2739a6d5a84604b0c71040e0bc62df"><multiple_choice id="e3dedd2742954d1497744555a9e40b1f" grading="automatic" select="single"><body><p id="bfd50b0a852f4425bfa71c17db2ef2d4">When performing cluster analysis especially the <em style="italic">k-</em>Means method, you can plot the sum of squared distances or the dispersion, as a function of the clusters to evaluate and select the optimal <em style="italic">k</em>. This value for the optimal <em style="italic">k </em>is typically located at the optimization point. This approach is called:</p></body><input shuffle="true" id="bef733b85d914db08d4a0bac9f3eb0c5" labels="false"><choice value="b63fa994e09c47c2bc61722e6710f31c">Elbow Method.</choice><choice value="abc499f617a7458886706a0c33382892">Silhouette Approach.</choice><choice value="d0fc7b1e1c1a430ca9783aec926de6ca">ROC Curve Approach.</choice><choice value="d9c7a1ba63ae4deeb7dc44b5f44eaa26">Box Plot Approach.</choice></input><part id="af55f4305cc64472b8aa7e1cfd9fc4db"><response match="b63fa994e09c47c2bc61722e6710f31c" score="10"><feedback><p id="a925cbe4354048208b46b46a60f795af">Correct: This is the best graphical approach as it shows the decline of cluster heterogeneity  as more clusters are formed.</p></feedback></response><response match="abc499f617a7458886706a0c33382892" score="0"><feedback><p id="f979561195204114a2a5309aefa747a4">Incorrect: This method measures the quality of the clustering  and determines how well a data point fits to its cluster.</p></feedback></response><response match="d0fc7b1e1c1a430ca9783aec926de6ca" score="0"><feedback><p id="e1f09d80d174460a983800073bb1bd62">Incorrect: This is not a straightforward metric to use in determining the optimal <em style="italic">k </em>value.</p></feedback></response><response match="d9c7a1ba63ae4deeb7dc44b5f44eaa26" score="0"><feedback><p id="ee833307c1994e75977c9a9ab1ea0091">Incorrect: This can allow you to see outlier data but it is not considered the best way to identify the optimal k compared to the other options.</p></feedback></response></part></multiple_choice></page><page id="e9cca1d39640461c97e621fb66c8cb74"><multiple_choice id="c2436b2d6f71419f9a1c01c8902ee896" grading="automatic" select="single"><body><p id="f18c2e0ba01e4058a61b14bf6a7f3088">In the figure attached, if you draw a horizontal line on y-axis for y=2. What will be the number of clusters formed?</p><image id="d3576a9e67774bd1bf7f82ebe054dc4e" src="../webcontent/Dendrogram2.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="d8ba8bcdc0e0418b96381922e512996c" /></caption><popout enable="false"></popout></image></body><input shuffle="true" id="aa4fcbdf6a824ae2a5e2bc4a0f2f2e35" labels="false"><choice value="b1a6c8bdf1c34cf4a0291a5d66d3d6f8">2</choice><choice value="ceeb2c70f372421a8a6a316f8fd01f40">3</choice><choice value="a3c93a91108548508c4bedbfd749de31">4</choice><choice value="ef5e5694745e4e4eaf6ff99250d5412f">6</choice></input><part id="af09512a6d094e9ea45d24990efe921f"><response match="b1a6c8bdf1c34cf4a0291a5d66d3d6f8" score="10"><feedback><p id="f10abc88d4e1489e824b8bcd449ce195">Correct: Since the number of vertical lines intersecting the red horizontal line at y=2 in the dendrogram are 2, therefore, two clusters will be formed. Observations that are joined together below the line are in clusters.</p></feedback></response><response match="ceeb2c70f372421a8a6a316f8fd01f40" score="0"><feedback><p id="e875b941b2ba45f3905711079b1985a5">Incorrect: Since the number of vertical lines intersecting the red horizontal line at y=2 in the dendrogram are 2, therefore, two clusters will be formed. Observations that are joined together below the line are in clusters.</p></feedback></response><response match="a3c93a91108548508c4bedbfd749de31" score="0"><feedback><p id="f7fc362d74834a7bb2dafcef1ec38b4b">Incorrect: Since the number of vertical lines intersecting the red horizontal line at y=2 in the dendrogram are 2, therefore, two clusters will be formed. Observations that are joined together below the line are in clusters.</p></feedback></response><response match="ef5e5694745e4e4eaf6ff99250d5412f" score="0"><feedback><p id="baaa2dd43143433493cb30c218733d87">Incorrect: Since the number of vertical lines intersecting the red horizontal line at y=2 in the dendrogram are 2, therefore, two clusters will be formed. Observations that are joined together below the line are in clusters.</p></feedback></response></part></multiple_choice></page><page id="b0086dd833144777aa8796705f055d17"><multiple_choice id="b3190e8068574ff2bf97829f5bd2dbee" grading="automatic" select="single"><body><p id="bc49336fd07d44939de6d4eaf42b0bcf">The idea behind using the within-clusters sum of squares measurement for <em style="italic">k</em>-means clustering is that:</p></body><input shuffle="true" id="f7a9c92aac6e49fe94e828c508fb9d74" labels="false"><choice value="d11277bd1ffa4484ad2302d8c9ad0178">A good clustering is one for which the within-cluster sum of squares variance is as small as possible.</choice><choice value="f044faedb0f548dda57c2a073da100cf">A good clustering is one for which the  within-cluster sum of squares is as large as possible.</choice><choice value="d46e2422bd8f403a9f99b0c66bc2db08">A good clustering is not dependent on the within-cluster sum of squares variance, it makes no difference if the  within-cluster sum of squares variance is small or large.</choice><choice value="c223cba8f50c44d891ba222447f63be5">A good clustering is one for which the within-cluster sum of squares variance is equal to the value of <em style="italic">k.</em> </choice></input><part id="de0b32cd988d4815ab805e245f45769a"><response match="d11277bd1ffa4484ad2302d8c9ad0178" score="10"><feedback><p id="a3b8146a81e4463a9b0aad51dceec584">Correct: The WCSS should be minimized to ensure there is as little dispersion as possible.</p></feedback></response><response match="f044faedb0f548dda57c2a073da100cf" score="0"><feedback><p id="c1487f1b3df745b5abb90901806d53a7">Incorrect: This would mean there is a wider spread and this could mean erroneous clustering.</p></feedback></response><response match="d46e2422bd8f403a9f99b0c66bc2db08" score="0"><feedback><p id="c4646f38d2714737993eb8bbe383b357">Incorrect: This would mean there could be wider spread and this will mean erroneous clustering.</p></feedback></response><response match="c223cba8f50c44d891ba222447f63be5" score="0"><feedback><p id="e7bf6d90b7bf4694bbf3093b99a6c55b">Incorrect: The value of <em style="italic">k</em> will more than likely not equal the WSS.</p></feedback></response></part></multiple_choice></page><page id="a126604b8e3c4b3ea176535199596466"><multiple_choice id="cbcc301ab0b347cfb244d2e0d975407c" grading="automatic" select="single"><body><image id="ff460fb34ab54975a64ee1fe5238e59a" src="../webcontent/Cluster2.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="be0ec58cbb3046d887b0efb48ca85759" /></caption><popout enable="false"></popout></image><p id="a861d3914a35406a8d3180e871a558cd">According to the figure above, the distance between each cluster is measured as L(a, b) = max(D(x<sub>ai, </sub>x<sub>bj</sub>)) using this method:</p></body><input shuffle="true" id="ccd8360202ef4553b7d2fb729141d3c7" labels="false"><choice value="ba34a7ad183442cf961f103c9f6ebdf3">Complete Linkage.</choice><choice value="f8d508ef34da4178bc702ad3966b6a12">Single Linkage.</choice><choice value="fe8e6dd22d6649e9acc9d185cf38f9d8">Average Linkage.</choice><choice value="ea109653c1984935ab897011730a8a80">Centroid Linkage.</choice></input><part id="cd15bfe0df3748a5b24354ce8b81530e"><response match="ba34a7ad183442cf961f103c9f6ebdf3" score="10"><feedback><p id="a0bb0123b7954b409a31c367ca33ef57">Correct:This linkage method involves merging two clusters with the maximum distance until there is only one cluster left.</p></feedback></response><response match="f8d508ef34da4178bc702ad3966b6a12" score="0"><feedback><p id="c9f80b3a03904a568a4a4080c1643df4">Incorrect:This linkage method involves merging two clusters with the minimum distance until there is only one cluster left.</p></feedback></response><response match="fe8e6dd22d6649e9acc9d185cf38f9d8" score="0"><feedback><p id="e9a23392db40422ab4c7ae581df67811">Incorrect: This linkage method involves merging two clusters with the lowest average distance until there is only one cluster left.</p></feedback></response><response match="ea109653c1984935ab897011730a8a80" score="0"><feedback><p id="a333739b958642b0a9cc960a5b7ddf26">Incorrect: This linkage method involves merging two clusters with the lowest centroid distance until there is only one cluster left.</p></feedback></response></part></multiple_choice></page><page id="a9e8cb2f1b9e4420bb36464cd58d5d30"><content available="always"><p id="ee0db660ae3b42b695c0ca6ae7305e90">Nike is interested in grouping its catalog shoppers based on their past transactions and shopping history. The popular shoe brand would like to target specific advertisements for each identified group. Those groups should contain shoppers who are <em>similar</em>. Please use this information to answer questions 9 and 10.</p></content><multiple_choice id="cbd42fd789be4d129929b7872f28018c" grading="automatic" select="single"><body><p id="e5ba074959ad490eb6ce8844a6f32541">Given the information, which statement(s) below would support completing this task:</p></body><input shuffle="true" id="c248d77c1c1f45d9a8a120c7a8b8650e" labels="false"><choice value="e2b481d877d946f8867d2ddac5649e21">You must consider what dissimilarity measures should apply based on the type of data.</choice><choice value="b5e8ebd6eec246b2a3e1513021d7ddf1">You must consider whether the variables in your shopper history and transaction dataset should be scaled.</choice><choice value="ea23804ad68e4162ab20d8a0d39d3e10">You must also determine what type of linkage method would be used.</choice><choice value="bd9eab012aec47a5901915cd6f882278">All the statements provided are correct.</choice></input><part id="a6302b968f38457cb08d4538aaec2ca2"><response match="e2b481d877d946f8867d2ddac5649e21" score="0"><feedback><p id="e308215a154e4f1394540de7a51cba9a">Incorrect: This statement is correct but there are other options that are valid as well.</p></feedback></response><response match="b5e8ebd6eec246b2a3e1513021d7ddf1" score="0"><feedback><p id="cc899497f0a6404bad9a9a0ea7bf054b">Incorrect: This statement is correct but there are other options that are valid as well.</p></feedback></response><response match="ea23804ad68e4162ab20d8a0d39d3e10" score="0"><feedback><p id="d8901c79d24b4f8c9f7cba1e39c960fa">Incorrect: This statement is correct but there are other options that are valid as well.</p></feedback></response><response match="bd9eab012aec47a5901915cd6f882278" score="10"><feedback><p id="b3484fe106374855a05d3ad5b7f6e0e1">Correct: All statements listed are correct.</p></feedback></response></part></multiple_choice></page><page id="e94a74e9f97948d89b4f7b9a05c5a15e"><content available="always"><p id="d252b66714774dc0b5241e86d33d4854">Nike is interested in grouping its catalog shoppers based on their past transactions and shopping history. The popular shoe brand would like to target specific advertisements for each identified group. Those groups should contain shoppers who are <em>similar</em>. Please use this information to answer questions 9 and 10.</p></content><multiple_choice id="a037d84bd68c4c39b805926e9530384c" grading="automatic" select="single"><body><p id="e6867c5c8b24425091ccb634a1f7e4f0">Assume that you performed a <em style="italic">k</em>-means cluster analysis on the dataset and you have applied the elbow method. Based on the figure below, what is your optimal <em style="italic">k</em>:</p><image id="b0cfb04411e54b7b914b6de989805900" src="../webcontent/Elbow.jpg" alt="" style="inline" vertical-align="middle" height="298" width="400"><caption><p id="a63f7d827f584d3f8a75eb59368dc784"><em style="italic">Elbow Chart</em></p></caption><popout enable="false"></popout></image></body><input shuffle="true" id="aa80fc389816449cbaa5171ea343da8d" labels="false"><choice value="c99245d9c4014cffa92c16ffad1a6e2d"><em style="italic">k</em> = 5 is the optimal number of clusters. It is located at the optimization point.</choice><choice value="c05bd272757d426188a705ad2229a157"><em style="italic">k</em> = 3 is the optimal number of clusters. It is located at the first &quot;knee&quot; of the plot.</choice><choice value="b1737b14db774045ba350179596c4981"><em style="italic">k</em> = 2 is the optimal number of clusters. The WCSS is not minimized at this point.</choice><choice value="eac126b29941449285e1f6b932f6325f"><em style="italic">k</em> = 10 is the optimal number of clusters. The WCSS is at its lowest.</choice></input><part id="b81225eacfff41e4b82b76ce29be4f11"><response match="c99245d9c4014cffa92c16ffad1a6e2d" score="10"><feedback><p id="dda4f7ec482e4cc9a5dfeb19d8e96306">Correct: The optimal <em style="italic">k </em>from an elbow chart is the value at the knee of the curve. This is the right value.</p></feedback></response><response match="c05bd272757d426188a705ad2229a157" score="0"><feedback><p id="ff681b8d440e479581258bd80735ffd6">Incorrect: The optimal <em style="italic">k </em>from an elbow chart is the value at the knee of the curve.</p></feedback></response><response match="b1737b14db774045ba350179596c4981" score="0"><feedback><p id="c937ac9efb0d42358de7abb8ed9d737c">Incorrect: The optimal <em style="italic">k </em>from an elbow chart is the value at the knee of the curve.</p></feedback></response><response match="eac126b29941449285e1f6b932f6325f" score="0"><feedback><p id="d15a0339fde84d928331ad19bb720eba">Incorrect: The optimal <em style="italic">k </em>from an elbow chart is the value at the knee of the curve and the WCSS should be at the lowest possible, anything after the optimization point is not significant.</p></feedback></response></part></multiple_choice></page><page id="ffbb9fd55f6147d5b3459f56016b7666"><essay id="a1528c946b434dd199a0c31c6aebad7e" grading="automatic"><body><p id="f409403121cb4abe88f62af310f63fc9">Please use this section to include justifications for questions above. If you do not have any, please enter N/A:</p></body><part id="e1c291d26a8749dd81284b84a53da806"><response match="*" score="1"><feedback><p id="b8955c6fd6414c31be0ada03a76be27b" /></feedback></response></part></essay></page></assessment>\n'