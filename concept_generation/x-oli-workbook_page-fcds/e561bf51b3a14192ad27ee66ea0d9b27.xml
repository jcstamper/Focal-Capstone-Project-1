<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="e561bf51b3a14192ad27ee66ea0d9b27"><head><title>Step 4b: Proposing Data Collection Methods</title><objref idref="c652b19601414ebebcfaed9f52cd17e0" /></head><body><p id="cb2c97bb137440d0a5f88f235ddb29ce"><em>Proposing Datasets &amp; Collection Methods</em></p><p id="c8115557c80b4693be7de91f9321cf8d">Just as the methods proposed must be suitable to achieve the analytic goal, so must the data with which the methods are combined. The most important criterion in this regard is, of course, that the data is presumed to contain patterns that are informative for the analytic objective and allows one to successfully tackle the proposed task and make progress towards solving the problem in a data-driven way. Beyond this main requirement, and depending on the project context and proposed methods, specific data sources can be more or less suitable for the project. Possible considerations include:</p><ul id="c3bd049b806c4f1b8f6ec46bd1691346"><li><p id="b9871c55b14e4be98ece75b8744704d6">Is the dataset of the appropriate size for the proposed method? How many data points and how many features does it contain?</p></li><li><p id="f4d0781a36ad4e2b80fdcd978c8d513a">What distribution do the individual phenomena in the data follow?</p></li><li><p id="a37c3c634a7841eb9b932879fc7663bc">Is the dataset raw or readily processable? What preprocessing is necessary and how will it influence the relevant patterns?</p></li><li><p id="aa884de6f4fa484fadc95d1e923bcfd5">Is the data complete or are some parts of it missing?</p></li><li><p id="b8d77c62ffb64db6a3931907b7ca5d67">Is the dataset clean or noisy? Does measurement error play a role?</p></li><li><p id="fbea53969d9d41a69ce2e3a111d6bdee">Are there access or disclosure restrictions to the data? Is it confidential, private, sensitive, partially redacted, or classified? Is it subject to licensing restrictions?</p></li></ul><p id="b535024d202043acb2940ea6f30f20b2">Well-studied benchmark datasets are available to the data science community for many tasks. While prior work on a dataset is a good indicator of its utility for a task, it cannot replace the process of familiarizing yourself with it before commencing serious experimentation work. It is good practice to investigate the suitability of the proposed dataset for the task and method before moving on with the project, unless the exploration of the dataset itself is understood as part of the analytic goal. This is typically done through research and preliminary data surveys, possibly in collaboration with domain experts.</p><p id="be311100d826432c9433c209c9f4e4a1">While statistical analysis and machine learning are of course core pillars of data science, effective collection, curation, and interaction with data are equally important and regularly the subject of analytic objectives, and even entire projects. As such the core method and data component of an analytic objective need not necessarily always be about training a model on available data, but can also be about collecting data to enable subsequent analysis.</p><p id="bae6c27b958e4a6bb2c40abaac299d02">When proposing data collection as part of an analytical objective, the collection methods must be scrutinized as to whether they are likely to succeed in producing a valuable dataset resource. Data collection, especially involving human annotators, is its own research field. Relevant considerations include:</p><p id="ce3fd7f457024455bbc0b18230f02ad4" /><ul id="c9ec17bb3fd34df08f099469fac24d63"><li><p id="ba3614d0df1f4d28ad00bcbe77547bbc">How well will the collection represent/approximate/cover the desired distribution of phenomena relevant to the problem?</p></li><li><p id="d503e857d6044299ad5796aa400d53a2">Does the collection require human annotators? Can it be done using crowdworkers?</p></li><li><p id="b35f9c979b4e47cf8a44a784687815b9">What qualifications do the human annotators need to possess? How can they be effectively trained for the task?</p></li><li><p id="de7e785630394c9d9bd1dda6dab2c1c9">Do the human annotators need to be examined/tested before and/or after collection?</p></li><li><p id="dd2a68917e60468b97535cae81223d77">How should the annotation task be designed to ensure productive and correct annotation? How will agreement between annotators be measured?</p></li><li><p id="a1c110581a4f4c3a9e6c812eaddccb05">How much data should be gathered to enable progress towards the analytic objective? How much data can be gathered given the budget?</p></li><li><p id="dbc20a54d8c649fbb172044fdbdbf8e9">Once the data has been gathered, what cleaning and curation needs to happen?</p></li><li><p id="b8ac54481e8740959088520c84f63641">Are there any approvals/permissions that need to be obtained before the collection can proceed (e.g. human subject research)?</p></li></ul><p id="f4a332bd981d45f695bdccbf81bb3884">This course includes an introduction to data collection methods. For purposes of this unit, the main thing to take away is that collecting good datasets requires an amount of skill, care, and attention to detail comparable to those needed for doing good data analysis. Like core machine learning efforts, data collection projects are conducted with specific analytic objectives in mind and hence can be framed and assessed using the same template.</p><p id="ce1b2d012c54411295975a88602c2a6b" /><wb:inline idref="newba56ce20216f4c03a4a9eb239158ab13" purpose="didigetthis" /></body></workbook_page>
