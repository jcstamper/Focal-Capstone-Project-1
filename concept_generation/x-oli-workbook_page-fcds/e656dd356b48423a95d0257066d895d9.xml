<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="e656dd356b48423a95d0257066d895d9"><head><title>Addressing Bias in Data</title><objref idref="af967de6a1204dc5a2fb2a617f9b4874" /></head><body><table id="c3566582c3e84c95829be702aad5b3d6" summary="" rowstyle="plain"><cite id="ib7cb909496ec4e32b26a1dced89c4abf" /><caption><p id="be3b754994754c449d05b24153af9c6d" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="b4bf23d9baba4ae59a09af86fb045ac0"><em>Reading: </em><link href="https://projecteuclid.org/download/pdf_1/euclid.ba/1340370566" target="new" internal="false">Avoiding Bias from Feature Selection</link>.</p></td></tr></table><p id="c33934cb85f14d469d4f29b5b175df8c"><em>Bias in Data</em></p><p id="f18d3706e1764ed499352cd21a9c0c77">When understanding and preparing data for the modeling process, there is a possibility that bias will be introduced into your dataset. This bias can be conscious or unconscious and the bias will affect the performance of your model but most importantly, your analytic solution and the decisions made after implementation of that solution. You are encouraged to explore research about bias and its implications to Artificial Intelligence <sup>1</sup>. Areas of interest include Algorithmic Bias, Computer Ethics and Roboethics. Ethical bias is a growing area of research that you will come across throughout your reading and career. </p><p id="cc2101a5c1c048afbfbd51912c2db125"><em>Feature Engineering and Bias</em></p><p id="d94a22a0e61945b8be71aef0728c0b7c">Feature engineering can be performed before the model building process, i.e. during the data wrangling and exploratory data analysis phase or it can be performed during model building. Later in this course, we will discuss cross validation but we must note here that feature engineering can be done during the cross validation process. <em style="italic">Cross Validation </em>is a model validation technique used to assess how a model will generalize to a new data set. At this time, feature engineering is done during the cross validation loop. </p><p id="a23eabdf0f9242489f71dc97fb055e61">Feature engineering at any stage can introduce bias to the data. While you manipulate the data, you can unintentionally create a relationship between features that do not otherwise exist. The features that are selected or created during the feature engineering process can shape the insights that are gotten from the model.</p><p id="e10be4cf28b44e6ea1df3c4c156f7b80">These are some examples of the types of bias that can be introduced during the &quot;data understanding&quot; phase of the data science project lifecycle. </p><p id="e923c82688ac491d85deb335efbda826"><em style="italic">Sample Bias. </em>When conducting a study, it is important to collect data from a representative sample of the population. A study measuring completion rate of graduate students in the United States with a sample of students from one socioeconomic background, race or gender will undermine the external validity of that study. This means the results of the study can not be truly generalized to the entire population of graduate students in the United States. </p><p id="c991ce36e8494e28b6b0323ea0b0f5ce"><em style="italic">Confirmation Bias. </em>Your prior knowledge, beliefs, and values can play a role in the data that is used to build your analytic solution, this is because as humans, we are prone to use our personal beliefs and experiences to guide us through daily life and decision making. This type of bias occurs when we favor evidence that confirms our personal beliefs, values and hypotheses. </p><p id="be6383a386e4497faf10cb885a522c97"><em style="italic">Information Bias. </em> Also known as measurement bias, occurs when data is collected, measured or interpreted wrongly. Misclassification of observations is an example of information bias, for example an observation with attributes similar to the stereotypical female student is recorded as female when that observation is male. Another example is misclassification of patients, consider the COVID-19 pandemic; groups under the age of 45 are seen as low risk; so during a screening exercise, those in that age group might not be screened and therefore classified as negative. The data collected has misclassification bias and is not accurate. One way to control information bias is to implement <link href="http://www.emgo.nl/kc/blinding/" target="new" internal="false"><em style="italic">blinding</em></link><em style="italic">. </em></p><p id="e5e59754c5b9472481ef51525ad50cd2"><em style="italic">Confounding Bias. </em>Addressed in medical research, confounding bias is &quot;the distortion of the association between an exposure and health outcome by another variable called a confounder&quot;<sup>1</sup>. </p><p id="c6ed85105adc495085ae1b9c44a527c1">A responsible data scientist should understand how bias occurs and actively seek out ways to reduce it; bias creeps in at various stages during the data science process but it is easily introduced in the data collection, and feature selection process. </p><table id="fffc0dae5a63453fa9e5bfd6f44215c8" summary="" rowstyle="plain"><cite id="ifbdef64deef048508156e2bca1d44743" /><caption><p id="cbe05a033fec4c04b9d35ab47ec15ed8" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="f0bbb03a166b413fb7b71ba69b29e543"><em>Reading: </em><link href="http://www.datascienceassn.org/code-of-conduct.html" target="new" internal="false">Data Science Code of Professional Conduct: Checking for Bias.</link></p><p id="f48064a9dd734d25b918b23c58555b60"><em>Reading: </em><link href="https://catalogofbias.org/biases/" target="new" internal="false">Catalog of Bias</link></p></td></tr></table><wb:inline idref="newb1d8bcdf6e2e4627aedb331bb8ea5cec" purpose="didigetthis" /></body><bib:file><bib:entry id="d3e5811fbda8492381892ec381e93b74"><bib:inbook><bib:author>Bostrom, N &amp; Yudkowsky, E.</bib:author><bib:title>Cambridge Handbook of Artificial Intelligence</bib:title><bib:chapter>The Ethics of Artificial Intelligence.</bib:chapter><bib:pages>21</bib:pages><bib:publisher> Cambridge University Press.</bib:publisher><bib:year>2011</bib:year></bib:inbook></bib:entry><bib:entry id="e7b4ba17a12f4e0487b62d62d7a1c417"><bib:inproceedings><bib:author>C. R. Turner, A. Fuggetta, L. Lavazza and A. L. Wolf</bib:author><bib:title>Feature engineering [software development]</bib:title><bib:booktitle>Proceedings Ninth International Workshop on Software Specification and Design</bib:booktitle><bib:year></bib:year><bib:pages>162-164</bib:pages></bib:inproceedings></bib:entry></bib:file></workbook_page>
