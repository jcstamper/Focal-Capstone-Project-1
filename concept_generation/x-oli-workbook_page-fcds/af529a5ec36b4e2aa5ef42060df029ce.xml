<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="af529a5ec36b4e2aa5ef42060df029ce"><head><title>Cluster Analysis</title><objref idref="d651478ba3e84c03851885b895caea97" /></head><body><p id="b356ad59ea4840519fd2f1d6e76866a7">When we want to study the hidden structure of data and identify different groups within that structure, we use the <em style="italic">Cluster Analysis </em>technique. Once groups are constructed, it is safe to assume that data points within each group have similar features and are very dissimilar to data points in other groups. Cluster analysis is looking to define structure within a dataset.</p><p id="a3ad9877756044978a29c559f2ff83c6">There are different types of clustering techniques. We will briefly define at this point and fully explore in an upcoming module.</p><p id="a9122718e0874101948e4c6f25e3e724"><em style="italic">K-means clustering</em> is a widely used clustering technique that computes the distance between data points in a group and the center of the group. The number of clusters (k) is decided before the process begins and kmeans clustering can only be applied to numerical variables. This is because it solely uses <em style="italic">euclidean distance </em>as a similarity measure to form clusters.</p><p id="cc3410166ca440d689095410bf1cf9c2"> It is not uncommon to begin by randomly selecting a number of observations from your data as the initial cluster center, the remaining observations will then be assigned to the nearest cluster center. The algorithm will continue to assign and reassign observations to their closest clusters by calculating the cluster centroids (this is the middle of a cluster). The reassignment is done to minimize dispersion within clusters. </p><p id="a561287400a44e55a25e9d2d92400c94"><em style="italic">Hierarchical clustering </em>connects data points to form clusters based on their distance and is also known as a connectivity-based clustering. Each data point is considered its own cluster at the start of the process and then the algorithm groups clusters based on similarity until true clusters are formed. This is known as <em style="italic">Agglomerative clustering. </em>There is another approach of hierarchical clustering that puts all data points in one cluster and then separated them based on dissimilarity until different clusters are formed. This is called <em style="italic">Divisive Clusters. Hierarchical</em> Clusters are formed and represented using a <em style="italic">dendrogram (</em>shown below). The y-axis of a dendrogram marks the distance were clusters merge, and data points are placed on the x-axis. </p><image id="c1a608373e0d40ec8930f2bc4331dd2a" src="../webcontent/Dendogram.jpg" alt="" style="inline" vertical-align="middle"><caption><p id="b55d233bd83a4c2e9f36a51dafdf65dc"><em style="italic">Example of a Dendrogram. Source-Mathlab</em></p></caption><popout enable="false"></popout></image><p id="dd76ae600dc54203b0a3519d7c87be2f">Similar to regression and classification techniques, clustering output should be evaluated. Evaluation methods differ based on the kind of clustering technique used to meet your analytic objective. Module 14 will focus on the different types of clustering techniques and the evaluation techniques that apply to each technique.</p><table id="bf0e16ebeb284fd680ecb44490849a35" summary="" rowstyle="plain"><cite id="i5386c9d33ad643c5bcd191af7be965db" /><caption><p id="bc453c7cb2084be9b3e0abd586a08ba8" /></caption><tr><td colspan="1" rowspan="1" align="left"><p id="c651c52ab2c34194ace5fd694d575250"><em>Reading: </em><link href="https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html" target="new" internal="false">Evaluating Clustering Results</link></p></td></tr></table><wb:inline idref="newcdf3a193454243439cd6ed17ec90699e" purpose="didigetthis" /></body></workbook_page>
