<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="ff70848f356c40d1a1c1bd183d2d194a"><head><title>Overview</title><objref idref="f884b110ee3f48bfaf5a73e27e20b647" /></head><body><p id="d8a8ff9e5d9d4856a7aa335160cf45b5">Human intuition and expert knowledge is not enough to decide if a model has performed well and can meet our analytic objectives. This is why we employ the use of some metrics to evaluate our algorithms for error, accuracy and predictive performance. This part of the process is an important part of building a useful model. You do not use the same metric for all problems, classification problems have different metrics to prediction problems, and when you arrive at the clustering metrics, you might see some similarities to classification metrics. </p><p id="f294ea8b96e747ba9811d2ae5a7b93e7">The metrics in this module are not exhaustive. As you take more machine learning courses, you will learn about more metrics in greater detail. Depending on the problem, your output will determine the type of algorithm that is used and that drives the type of metric to use in evaluating performance. An on the hand example is for classification problems, when you have probability output or you have class outputs. Regression problems are quite consistent with outputs as they are typically continuous. </p></body></workbook_page>
