<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workbook_page PUBLIC "-//Carnegie Mellon University//DTD Workbook Page MathML 3.8//EN" "http://oli.web.cmu.edu/dtd/oli_workbook_page_mathml_3_8.dtd"><workbook_page xmlns:bib="http://bibtexml.sf.net/" xmlns:cmd="http://oli.web.cmu.edu/content/metadata/2.1/" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pref="http://oli.web.cmu.edu/preferences/" xmlns:theme="http://oli.web.cmu.edu/presentation/" xmlns:wb="http://oli.web.cmu.edu/activity/workbook/" id="e836784715544d8ab29d72da3687b322"><head><title>Feature Vectors</title><objref idref="bb8cd74aab6c47c39d8c9786d3b7eb30" /><objref idref="f8acdd6e7a154626944c30aba1b5d211" /></head><body><p id="bc50f2728e2e4104812869853dd9e281"><em>Raw Data to Features</em></p><p id="ef9e812bb0974a26acbcb9160e56a130">So far, we have discussed data as a entity in the data science process and how it is transformed during the cleansing/wrangling process, used for exploratory data analysis and used to draw conclusions with inferential statistics. Now we will focus on the parts of data that can be useful in the model building process, parts of data that will assist in performing the tasks that you have defined in earlier stages of the data  science process; those tasks that are done to meet our analytic objective. Developing your analytic solution will involve the use of statistical modeling, we must understand that those models consist of formulae that only relates numerical quantities to each other<sup>1</sup>. How then can we build a solution that ranks customer preferences or identifies segments of a customer base that might benefit from a service? How can a mathematical model understand variables that are not numeric? </p><p id="acb6f58cbcdc471ab24c07332f50e261"><em>Features</em><em style="italic"> </em></p><p id="ddee51d2c5e04889a6cf3d098b837e95">A <em style="italic">feature</em> is a numeric representation of a part of the raw data. The wikipedia definition of a feature best describes it as, &quot;...<em style="italic">an individual measurable property or characteristic of an observation&quot;.</em> Features are the parts of an observation that are represented in a way that a machine learning model can use. Consider an image classification task, to properly represent the features of your image, they are processed into a numerical format that allows the mathematical model to use it. </p><p id="d5d4faa182a44f869775d8a375d00ead">When raw data is transformed into features, a data scientist must consider the right features that are useful for the data science task. A good feature is one that is appropriate to the statistical modeling technique and data science task. Features should also provide information, i.e. if you are performing a predictive task, your features should have predictive values. </p><p id="d0969507db204a02a8a6f26a05e2ad3c">Transforming or processing features from data is an important task in the data science project life cycle, but often glossed over. The price for badly selected features is a costly one that rears its head when you are training your model. As shown in the figure below, features will directly affect the models that you develop and the insights gleaned from your models. The snowball effect of badly selected features will end up leading decision makers down a wrong path. As efficiency and accuracy are key in the data science process, it is important to explore available resources that are developed to guide data scientists on feature engineering techniques for data science tasks and modeling. Note that feature engineering requires both domain and technical expertise. </p><image id="d5128f6a3ee84d53a0037f8acdc94a10" src="../webcontent/Feature_eng.jpg" alt="" style="inline" vertical-align="middle" height="338" width="750"><caption><p id="dd3d7018fe1d4d3cbfe1d2bb067c221b"><em style="italic">Feature Engineering and Analytic Solution Building. Source: Zheng &amp; Casari (2018)</em><em style="italic"><sup>1</sup></em></p></caption><popout enable="false"></popout></image><p id="b7ff41fc5679438aa9e7440e38d0ff19"><em style="italic">Feature engineering</em> is the process of extracting features from raw data and transforming those features into suitable formats for a machine learning model. Feature engineering leads to higher quality models and better insights for decision makers. When you think about the diverse machine learning techniques, data science tasks and contexts in which we apply machine learning, you will see that feature engineering can not be generalized. It is not a one size fits all process. It is dependent on your analytic objective and your data. Feature engineering requires domain knowledge and intuition. During the feature engineering process, the data scientist will remove features from the data that do not provide task specific information (e.g the feature has no predictive value), and also features that introduce redundancy. This is called <em style="italic">feature selection. </em></p><p id="e466b6194f8c4b4e8e9eab4e1e2ddfd6"><em style="italic">Numeric Data Type: </em>Even though we defined a feature as a numeric representation of data, raw data that is in numeric form should also undergo feature engineering. This is because the data must meet the assumptions of the chosen model.</p><ul id="c9ea8b32e660445e87ccbdb1f37f030c"><li><p id="c1fab9cd44ae4de4b96a5cc7a5eaed43">Scalar: Single numeric feature, e.g. mass.</p></li><li><p id="d289061844514715a590e74d20dfe447">Vector: Ordered list of scalars; also defined as an object that has both a magnitude and direction.</p></li><li><p id="dfa1426938354dd1a958f1473d5e7df8">Spaces: Vectors exist within a vector space and are also a collection of vectors that can be added or multiplied by scalars.</p></li><li><p id="fc6e5661c6764845884e02966ba052a5">In machine learning, the input to a model is represented as a numeric vector.</p></li></ul><wb:inline idref="newa082d5e651c54cf0833bcd2bfb3cea57" purpose="didigetthis" /></body></workbook_page>
